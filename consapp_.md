---
nocite: "[@*]"
references:
- author:
  - literal: Wallis, J.
  id: wallis1656arithmetica
  issued: 1656
  publisher: "Oxonii, Typis LEON: LICHFIELD Academiæ Typographi,
    Impensis THO. ROBINSON"
  title: "[Arithmetica infinitorum sive nova methodus inquirendi in
    curvilineorum quadraturam aliaque difficiliora matheseos
    problemata]{.nocase}"
  type: book
  url: "https://books.google.com/books?id=Z5w_AAAAcAAJ"
- author:
  - literal: Newton, I.
  edition: 1
  id: Newton1687
  issued: 1687
  publisher: Jussu Societatis Regiae ac typis Josephi Streater, prostant
    venales apud Sam. Smith
  publisher-place: Londini
  title: "[Philosophiae naturalis principia mathematica]{.nocase}"
  type: book
  url: "https://books.google.at/books?id=XJwx0lnKvOgC&pg=PP2&redir_esc=y#v=onepage&q&f=false"
- author:
  - literal: Taylor, B.
  id: taylor1715methodus
  issued: 1715
  publisher: "Typis Pearsonianis: Prostant apud Gul. Innys ad Insignia
    Principis in Coemeterio Paulino MDCCXV"
  publisher-place: Londini
  title: "[Methodus incrementorum directa & inversa. Auctore Brook
    Taylor, LL. D. & Regiae Societatis Secretario]{.nocase}"
  type: book
  url: "https://books.google.com/books?id=iXN1xgEACAAJ"
- abstract: Si p sit numerus casuum quibus eventus aliquis contingere
    possit, &amp; q numerus casuum quibus possit non-contingere;
  author:
  - literal: de Moivre, A.
  container-title: Philosophical Transactions of the Royal Society of
    London
  doi: 10.1098/rstl.1710.0018
  id: DeMoivre1711
  issue: 329
  issued: 1711
  page: 213-264
  title: "[De mensura sortis, seu, de probabilitate eventuum in ludis a
    casu fortuito pendentibus]{.nocase}"
  type: article-journal
  url: "https://royalsocietypublishing.org/doi/abs/10.1098/rstl.1710.0018"
  volume: 27
- author:
  - literal: Bernoulli, J.
  id: Bernoulli1713
  issued: 1713
  publisher: Impensis Thurnisiorum, Fratrum
  publisher-place: Basileae
  title: "[Ars conjectandi, opus posthumum. Accedit Tractatus de
    seriebus infinitis, et epistola gallicé scripta de ludo pilae
    reticularis]{.nocase}"
  type: book
  url: "https://www.e-rara.ch/zut/doi/10.3931/e-rara-9001"
- author:
  - literal: de Montmort, P. R.
  edition: 2
  id: de1713essay
  issued: 1713
  publisher: A Paris, Chez Laurent Le Conte; Quay des Augustins, à la
    Ville de Montpiller
  title: "[Essay D'analyse Sur Les Jeux De Hazard]{.nocase}"
  type: book
  url: "https://books.google.fr/books?id=DIM_AAAAcAAJ"
- author:
  - literal: Bernoulli, D.
  id: Bernoulli1729
  issued: 1729-10
  publisher-place: St.-Petersbourg ce 6. octobre 1729
  title: "[Lettre XLVII. D. Bernoulli a Goldbach]{.nocase}"
  url: "https://commons.m.wikimedia.org/wiki/File:DanielBernoulliLetterToGoldbach-1729-10-06.jpg"
- author:
  - literal: de Moivre, A.
  edition: 2
  id: DeMoivre1738
  issued: 1738
  publisher: H. Woodfall
  publisher-place: London
  title: "[The Doctrine of Chances: Or, A Method of Calculating the
    Probability of Events in Play]{.nocase}"
  type: book
  url: "https://books.google.com/books?id=PII\\\\\\_AAAAcAAJ"
- author:
  - literal: Fourier, J. B. J.
  id: Fourier1822
  issued: 1822
  publisher: Chez Firmin Didot, pere et fils
  publisher-place: A Paris
  title: "[Théorie analytique de la chaleur]{.nocase}"
  type: book
  url: "https://archive.org/details/bub_gb_TDQJAAAAIAAJ/mode/1up"
- author:
  - literal: Poisson, S.-D.
  id: Poisson1837
  issued: 1837
  page: 205-207
  publisher: Bachelier
  publisher-place: Paris
  title: "[Recherches sur la probabilité des jugements en matière
    criminelle et en matière civile]{.nocase}"
  type: book
  url: "https://gallica.bnf.fr/ark:/12148/bpt6k110193z/f218.image"
- author:
  - literal: Riemann, B.
  container-title: Abhandlungen der Königlichen Gesellschaft der
    Wissenschaften in Göttingen
  id: Riemann1868
  issued: 1868
  page: 87-131
  title: "[Ueber die Darstellbarkeit einer Function durch eine
    trigonometrische Reihe. (Mitgetheilt durch R. Dedekind)]{.nocase}"
  type: article-journal
  url: "http://eudml.org/doc/135759"
  volume: 13
- author:
  - literal: Helmert, F. R.
  container-title: Zeitschrift für Mathematik und Physik
  id: Helmert1876
  issued: 1876
  page: 192-219
  title: "[Ueber die Wahrscheinlichkeit der Potenzsummen der
    Beobachtungsfehler und über einige damit im Zusammenhange stehende
    Fragen]{.nocase}"
  type: article-journal
  url: "https://gdz.sub.uni-goettingen.de/id/PPN599415665_0021"
  volume: 21
- author:
  - literal: Lüroth, J.
  container-title: Astronomische Nachrichten
  doi: 10.1002/asna.18760871402
  id: Lüroth1876
  issue: 14
  issued: 1876
  page: 209-220
  title: "[Vergleichung von zwei Werthen des wahrscheinlichen
    Fehlers]{.nocase}"
  type: article-journal
  url: "https://doi.org/10.1002/asna.18760871402"
  volume: 87
- author:
  - literal: Gosset, W. S.
  container-title: Biometrika
  doi: 10.2307/2331554
  id: Gosset1908
  issue: 1
  issued: 1908
  page: 1-25
  title: The probable error of a mean
  type: article-journal
  volume: 6
- abstract: 1. Introduction.--- 1·0. The object of this paper is to
    develop methods where by the differential equations of physics may
    be applied more freely than hitherto in the approximate form of
    difference equations to problems concerning irregular bodies. Though
    very different in method, it is in purpose a continuation of a
    former paper by the author, on a "Freehand Graphic Way of
    Determining Stream Lines and Equipotentials" ('Phil. Mag.,'February,
    1908; also 'Proc. Physical Soc.,' London, vol. xxi.). And all that
    was there said, as to the need for new methods, may be taken to
    apply here also. In brief, analytical methods are the foundation of
    the whole subject, and in practice they are the most accurate when
    they will work, but in the integration of partial equations, with
    reference to irregular-shaped boundaries, their field of application
    is very limited.
  author:
  - literal: Richardson, L. F.
  container-title: "Philosophical Transactions of the Royal Society of
    London, Series A: Containing Papers of a Mathematical or Physical
    Character"
  doi: 10.1098/rsta.1911.0009
  id: 10.1098/rsta.1911.0009
  issn: 0264-3952
  issue: 459-470
  issued: 1911-01
  page: 307-357
  title: IX. The approximate arithmetical solution by finite differences
    of physical problems involving differential equations, with an
    application to the stresses in a masonry dam
  type: article-journal
  url: "https://doi.org/10.1098/rsta.1911.0009"
  volume: 210
- author:
  - literal: Fisher, R. A.
  container-title: Biometrika
  doi: 10.2307/2331838
  id: Fisher1915
  issn: 00063444
  issue: 4
  issued: 1915
  page: 507-521
  publisher: \[Oxford University Press, Biometrika Trust\]
  title: Frequency distribution of the values of the correlation
    coefficient in samples from an indefinitely large population
  type: article-journal
  url: "http://www.jstor.org/stable/2331838"
  volume: 10
- author:
  - literal: Fisher, R. A.
  container-title: Journal of the Royal Statistical Society
  doi: 10.2307/2340521
  id: Fisher1922
  issue: 1
  issued: 1922
  page: 87-94
  title: On the interpretation of [χ2]{.nocase} from contingency tables,
    and the calculation of p
  type: article-journal
  volume: 85
- author:
  - literal: Fisher, R. A.
  container-title: Proceedings International Mathematical Congress,
    Toronto
  id: Fisher1924
  issued: 1924
  page: 805-813
  title: On a distribution yielding the error functions of several
    well-known statistics
  type: article-journal
  url: "https://repository.rothamsted.ac.uk/item/8w2q9/on-a-distribution-yielding-the-error-functions-of-several-well-known-statistics"
  volume: 2
- author:
  - family: Cardano
    given: G.
  id: Cardano1545
  issued: 1545
  publisher: ANDREAE OSIANDRO viro eruditiff
  publisher-place: S. P. D
  title: ARTIS MAGNAE, SIVE DE REGVLIS ALGEBRAICIS, LIBER VNVS
  type: book
  url: "https://web.archive.org/web/20220201093634/http://www.filosofia.unimi.it/cardano/testi/operaomnia/vol_4\\_s_4.pdf"
- abstract: In der Arbeit soll versucht werden, Grundlagen zu gewinnen
    für eine quantentheoretische Mechanik, die ausschließlich auf
    Beziehungen zwischen prinzipiell beobachtbaren Größen basiert ist.
  author:
  - literal: Heisenberg, W.
  container-title: Zeitschrift für Physik
  doi: 10.1007/BF01328377
  id: Heisenberg1925
  issued: 1925
  page: 879-893
  title: "[Über quantentheoretische Umdeutung kinematischer und
    mechanischer Beziehungen]{.nocase}"
  type: article-journal
  url: "https://doi.org/10.1007/BF01328377"
  volume: 33
- abstract: "For a given function B and a non-zero real number h,
    Schoenberg's approximation defines from some data (jh, yj)jϵZd the
    function ΣjϵZd yj B(•h − j). For people not used to this kind of
    approximation, this paper intends to do a summary of the main
    definitions, properties and utilizations of Schoenberg's
    approximation: we show that the main tool to handle Schoenberg's
    approximation is the Fourier transform of B and even more its
    modified version, the transfer function of B; we give conditions for
    convergence of ΣjϵZd f(jh) B(•h − j) when h tends to zero, and we
    give various ways to define various B as combinations of translates
    of some function ϕ (usually ϕ is either some radial function, or
    obtained by a tensor product of some radial function), depending on
    the properties we want for the associated Schoenberg's
    approximation. Last, we show how multi-resolution analysis,
    subdivision techniques, and wavelets techniques, are nicely
    connected to Schoenberg's approximation."
  author:
  - literal: Rabut, C.
  container-title: Computers & Mathematics with Applications
  doi: 10.1016/0898-1221(92)90177-J
  id: RABUT1992149
  issn: 0898-1221
  issue: 12
  issued: 1992
  page: 149-175
  title: An introduction to schoenberg's approximation
  type: article-journal
  url: "https://www.sciencedirect.com/science/article/pii/089812219290177J"
  volume: 24
- author:
  - literal: Schoenberg, I. J.
  container-title: Quarterly of Applied Mathematics
  doi: 10.1090/qam/15914
  id: Schoenberg1946
  issued: 1946
  page: 45-99
  title: Contributions to the problem of approximation of equidistant
    data by analytic functions. Part a. On the problem of smoothing or
    graduation. A first class of analytic approximation formulae
  type: article-journal
  volume: 4
- author:
  - literal: Romberg, W.
  container-title: Forhandlinger / Det Kongelige Norske Videnskabers
    Selskab
  id: Romberg1955
  issue: 7
  issued: 1955
  note: "https://katalog.ub.uni-heidelberg.de/cgi-bin/titel.cgi?katkey=68187317"
  page: 30-36
  publisher: F. Bruns Bokhandel
  publisher-place: Trondheim
  title: Vereinfachte numerische integration
  type: article-journal
  url: "https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://web.eng.fiu.edu/LEVY/images/EGM5346/romberg%2520textbook%2520example.pdf&ved=2ahUKEwiSxr-u846SAxVFQvEDHd83Bj8QFnoECHMQAQ&usg=AOvVaw3vtOkKCF8WeDkOB49i_03i"
  volume: 28
- author:
  - literal: Schrausser, D. G.
  container-title: Software
  id: Schrausser81800920
  issued: 2009
  publisher: Academia
  title: ThetaWin Overview
  url: "https://www.academia.edu/81800920"
- author:
  - literal: Schrausser, D. G.
  container-title: Method
  doi: 10.13140/RG.2.2.32114.17601
  id: SchrausserRG.2.2.32114.17601
  issued: 2000-05
  publisher: ResearchGate
  title: Development of a parameter to indicate the focussation-level of
    cortical activation
  url: "https://rgdoi.net/10.13140/RG.2.2.32114.17601"
- author:
  - literal: Schrausser, D. G.
  container-title: Method
  doi: 10.13140/RG.2.2.28637.90083
  id: SchrausserEEGalgorithms
  issued: 2000
  publisher: ResearchGate
  title: "[Spectral and Coherence Analysis: Algorithms]{.nocase}"
- abstract: Graphical user interface for Theta applications within
    ConsoleApp_Distribution_Functions (Schrausser, 2024), generating
    distributions and estimators for several parameters via bootstrap
    method.
  author:
  - literal: Schrausser, D. G.
  container-title: Zenodo Software documentation
  doi: 10.5281/zenodo.17691241
  id: schrausser_2025_17691241
  issue: 11/23
  issued: 2025-11
  keyword: bootstrapping myown probability resampling software
    statistics
  page: 1
  publisher: Zenodo
  title: ThetaWin
  type: article-journal
  url: "https://doi.org/10.5281/zenodo.17691241"
  volume: 2025
- abstract: Tools for calculations, bootstrapping and permutation tests,
    also for practice purposes when learning programming languages (C,
    Basic, Fortran etc.), see e.g. Halvorson and Rygmyr (1991), Chivers
    and Sleightholme (2018), Joyce (2019), Streib (2020) or
    Gonzalez-Morris and Horton (2024).
  author:
  - literal: Schrausser, D. G.
  container-title: Zenodo Software documentation
  doi: 10.5281/zenodo.17743756
  id: schrausser_2025_17743756
  issue: 11/28
  issued: 2025-11
  keyword: bootstrapping myown permutation_test programs simulation
    software statistics
  page: 1
  publisher: Zenodo
  title: Various programs
  type: article-journal
  url: "https://doi.org/10.5281/zenodo.17743756"
  volume: 2025
- abstract: Graphical MS Windows user interface for
    ConsoleApp_DistributionFunctions.
  author:
  - literal: Schrausser, D. G.
  container-title: Zenodo Software documentation
  doi: 10.5281/zenodo.17880113
  id: schrausser_2025_17880113
  issue: 12/10
  issued: 2025-12
  keyword: myown probability software statistics
  page: 1
  publisher: Zenodo
  title: "FunktionWin: Windows interface for distribution functions"
  title-short: FunktionWin
  type: article-journal
  url: "https://doi.org/10.5281/zenodo.17880113"
  volume: 2025
- abstract: Summarizing presentation of the fundamentally most important
    distribution functions with distribution graphics and formulation.
    Examples for the calculation in SCHRAUSSER-MAT syntax, as well as an
    extensive collection of formulas with transformations according to
    parameters of interest in the appendix.
  author:
  - literal: Schrausser, D. G.
  doi: 10.31234/osf.io/rvzxa
  id: Schrausser10.31234/osf.io/rvzxa
  issued: 2024
  keyword: myown probability statistics
  publisher: PsyArXiv
  title: "Handbook: Distribution functions (verteilungs funktionen)"
  title-short: Handbook
  type: book
- author:
  - literal: Schrausser, D. G.
  doi: 10.5281/zenodo.7651660
  id: Schrausser7651660
  issued: 2023
  publisher: Zenodo
  title: "[Schrausser/FunktionWin: Windows Interface for distribution
    functions]{.nocase}"
  type: book
- author:
  - literal: Schrausser, D. G.
  doi: 10.5281/zenodo.7659263
  id: Schrausser7659263
  issued: 2023
  publisher: Zenodo
  title: "[Schrausser/ThetaWin: Distribution simulator]{.nocase}"
  type: book
- author:
  - literal: Schrausser, D. G.
  doi: 10.5281/zenodo.7664141
  id: Schrausser7664141
  issued: 2023
  publisher: Zenodo
  title: "[Schrausser/ConsoleApp_DistributionFunctions: Console
    applications for distribution functions]{.nocase}"
  type: book
- author:
  - literal: Schrausser, D. G.
  doi: 10.5281/zenodo.7655046
  id: Schrausser7655046
  issued: 2023
  publisher: Zenodo
  title: "[Schrausser/ConsoleApp_Matrix: Console applications for matrix
    calculation and tools]{.nocase}"
  type: book
- author:
  - literal: Schrausser, D. G.
  doi: 10.5281/zenodo.7655239
  id: Schrausser7655239
  issued: 2023
  publisher: Zenodo
  title: "[Schrausser/ConsoleApp_Tools: Console tool
    applications]{.nocase}"
  type: book
- author:
  - literal: Schrausser, D. G.
  doi: 10.5281/zenodo.7653790
  id: Schrausser7653790
  issued: 2023
  publisher: Zenodo
  title: "[Schrausser/ConsoleApp_String: Console applications for string
    and transformation]{.nocase}"
  type: book
- author:
  - literal: Schrausser, D. G.
  doi: 10.5281/zenodo.7655056
  id: Schrausser7655056
  issued: 2023
  publisher: Zenodo
  title: "[Schrausser/ConsoleApp_Integral: Console applications for
    integral and interpolation]{.nocase}"
  type: book
- author:
  - literal: Schrausser, D. G.
  doi: 10.5281/zenodo.10701350
  id: schrausser_2024_10701350
  issued: 2023
  publisher: Zenodo
  title: "Schrausser/ConsoleApp_EEG: 2.0"
  title-short: Schrausser/ConsoleApp_EEG
  type: book
- abstract: Mathematical and statistical applications for HP Prime.
    Algorithms are presented in context with the corresponding scope of
    application. CAS programs (1), HP Prime User functions (2) and
    functions for HP Prime Applications (3) are listed in alphabetical
    order, a comparison to corresponding SCHRAUSSER-MAT functions is
    given. In addition to the source codes of the functions, raw data
    sets are provided for correlation- as well as resampling-methods.
  author:
  - literal: Schrausser, D. G.
  doi: 10.5281/zenodo.15713317
  edition: 1
  id: schrausser_2025_15713317
  issued: 2025-06
  keyword: bootstrapping calculus complex_plane hp_prime myown
    permutation_test probability randomization_test resampling software
    statistics
  title: "HP_prime_MATH: manual"
  title-short: HP_prime_MATH
  type: book
  url: "https://doi.org/10.5281/zenodo.15713317"
- abstract: The C programming language was created in the 1970s, yet it
    is still in extensive use today and is the basis of many other
    languages. For this reason I have used C as the language for the
    solution of the numerical problems demonstrated in this book.
  author:
  - literal: Joyce, P.
  doi: 10.1007/978-1-4842-5064-8
  edition: 1
  id: Joyce2019
  isbn: 978-1-4842-5064-8
  issued: 2019
  publisher: Apress
  publisher-place: Berkeley, CA
  title: "[Numerical C: Applied Computational Programming with Case
    Studies]{.nocase}"
  type: book
- author:
  - literal: Gonzalez-Morris, G., & Horton, I.
  doi: 10.1007/979-8-8688-0149-5
  edition: 7
  id: Gonzalez2024
  isbn: 979-8-8688-0148-8
  issued: 2024
  publisher: Apress
  publisher-place: Berkeley, CA
  title: "[Beginning C: From Beginner to Pro]{.nocase}"
  type: book
- abstract: "DOSSHELL als Befehl: Mit DOSSHELL wird die Menü-Oberfläche
    von MS-DOS von der Befehlszeilen-Oberfläche aus gestartet.
    Beispiel."
  author:
  - literal: Kaier, E.
  container-title: "[Informatik: Referenzbuch. Mit den vollständigen
    Befehlslisten zu MS-DOS, Turbo Pascal, dBase und
    Multiplan]{.nocase}"
  doi: 10.1007/978-3-322-89035-1_1
  id: Kaier1990
  isbn: 978-3-322-89035-1
  issued: 1990
  page: 1-12
  publisher: Vieweg+Teubner Verlag
  publisher-place: Wiesbaden
  title: Referenz zu MS-DOS
  type: chapter
  url: "https://doi.org/10.1007/978-3-322-89035-1_1"
- abstract: Obwohl die in diesem Abschnitt verwendeten Schlüsselwörter
    MS-DOS-spezifisch sind und daher nicht der ANSI C-Norm entsprechen,
    soll an einigen Beispielen gezeigt werden, wie man in C Zugang zum
    MS-DOS-Betriebssystem erhält. Eine vollständige Darstellung ist im
    Rahmen des Buchs natürlich nicht möglich. Es wird hier auf die
    Literatur \[131 bzw. \[22\] verwiesen.
  author:
  - literal: Herrmann, D.
  container-title: "[Effektiv Programmieren in C und C++: Eine aktuelle
    Einführung mit Beispielen aus Mathematik, Naturwissenschaft und
    Technik]{.nocase}"
  doi: 10.1007/978-3-322-94365-1_16
  id: Herrmann2001
  isbn: 978-3-322-94365-1
  issued: 2001
  page: 295-318
  publisher: Vieweg+Teubner Verlag
  publisher-place: Wiesbaden
  title: System-programmierung (MS-DOS)
  type: chapter
  url: "https://doi.org/10.1007/978-3-322-94365-1_16"
- abstract: Ein wichtiger Teil der Computerphysik ist die
    Implementierung eines Programms, d. h. das Programmieren selbst. Es
    gibt zwar Simulationspakete und Umgebungen, die spezielle Probleme
    ohne Programmierung lösen können, aber erst mit der Programmierung
    besteht die Möglichkeit, eigene Probleme zu implementieren und zu
    lösen. In diesem Kapitel werden zuerst die Grundlagen der
    Programmierung im Detail erläutert. Danach folgt eine Einführung in
    die Programmiersprache C, die eine hohe Verbreitung genießt und auch
    zu großen Teilen in diesem Buch verwendet wird. Am Ende des Kapitels
    werden Hilfsmittel zur Programmierung, d.h. sog. Makefiles, Debugger
    und Versionsverwaltungen und deren Verwendung angesprochen.
  author:
  - literal: Gerlach, S.
  container-title: "[Computerphysik: Einführung, Beispiele und
    Anwendungen]{.nocase}"
  doi: 10.1007/978-3-662-59246-5_4
  id: Gerlach2019
  isbn: 978-3-662-59246-5
  issued: 2019
  page: 31-54
  publisher: Springer
  publisher-place: Berlin, Heidelberg
  title: "[Programmieren in C]{.nocase}"
  type: chapter
  url: "https://doi.org/10.1007/978-3-662-59246-5_4"
- author:
  - literal: Philippou, A. N., & Antzoulakos, D. L.
  container-title: International encyclopedia of statistical science
  doi: 10.1007/978-3-662-69359-9_71
  editor:
  - literal: Lovric, M.
  id: Philippou2025
  isbn: 978-3-662-69359-9
  issued: 2025
  page: 306-309
  publisher: Springer
  publisher-place: Berlin, Heidelberg
  title: Binomial distribution
  type: chapter
  url: "https://doi.org/10.1007/978-3-662-69359-9_71"
- author:
  - literal: Collani, E., & Dräger, K.
  collection-title: Graduate texts in mathematics
  doi: 10.1007/978-1-4612-0215-8
  edition: 1
  id: Collani2001
  issued: 2001
  publisher: Birkhäuser
  publisher-place: Boston, MA
  title: Binomial distribution handbook for scientists and engineers
  type: book
- abstract: "The increase in available probabilistic information and its
    usefulness for understanding the world has made it necessary to
    promote probabilistic literate citizens. For this, the binomial
    distribution is fundamental as one of the most important
    distributions for understanding random phenomena and effective
    decision making, and as a facilitator for the understanding of
    mathematical and probabilistic notions such as the normal
    distribution. However, to understand it effectively, it is necessary
    to consider how it has developed throughout history, that is, the
    components that gave it the form and meaning that we know today. To
    address this perspective, we identify the problem situations that
    gave origin to the binomial distribution, the operational and
    discursive practices developed to find solutions, and the conflicts
    that caused a leap in mathematical and probability heuristics,
    culminating in what is now known as the binomial distribution
    formula. As a result, we present five historical links to the
    binomial phenomenon where problem situations of increasing
    complexity were addressed: a case study using informal means (such
    as direct counting), the formalization of numerical patterns and
    constructs related to counting cases, specific probability calculus,
    the study and modeling of probability in variable or complex
    phenomena, and the use of the distribution formula as a tool to
    approaching notions such as the normal distribution. The periods and
    situations identified correspond to a required step in the design of
    binomial distribution learning from a historical epistemological
    perspective and when solving conflicts."
  author:
  - literal: García-García, J. I., Fernández Coronado, N. A., Arredondo,
      E. H., & Imilpán Rivera, I. A.
  container-title: Mathematics
  doi: 10.3390/math10152680
  id: math10152680
  issn: 2227-7390
  issue: 15
  issued: 2022
  title: "The binomial distribution: Historical origin and evolution of
    its problem situations"
  title-short: The binomial distribution
  type: article-journal
  url: "https://www.mdpi.com/2227-7390/10/15/2680"
  volume: 10
- abstract: The sum of k independent and identically distributed (0, 1)
    variables has a binomial distribution. If the variables are
    identically distributed but not independent, this may be generalized
    to a two-parameter distribution where the k variables are assumed to
    have a symmetric joint distribution with no second- or higher-order
    \"interactions\". Two distinct generalizations are obtained,
    depending on whether the \"multiplicative\" or \"additive\"
    definition of \"interaction\" for discrete variables is used. The
    multiplicative generalization gives rise to a two-parameter
    exponential family, which naturally includes the binomial as a
    special case. Whereas with a beta-binomially distributed variable
    the variance always exceeds the corresponding binomial variance, the
    \"additive\" or \"multiplicative\" generalizations allow the
    variance to be greater or less than the corresponding binomial
    quantity. The properties of these two distributions are discussed,
    and both distributions are fitted, successfully, to data given by
    Skellam (1948) on the secondary association of chromosomes in
    Brassica.
  accessed: 2026-01-12
  author:
  - literal: Altham, P. M. E.
  container-title: Journal of the Royal Statistical Society. Series C
    (Applied Statistics)
  id: f22e64ae-c859-380d-809e-72c74d13957d
  issn: 00359254, 14679876
  issue: 2
  issued: 1978
  page: 162-167
  publisher: \[Royal Statistical Society, Oxford University Press\]
  title: Two generalizations of the binomial distribution
  type: article-journal
  url: "http://www.jstor.org/stable/2346943"
  volume: 27
- accessed: 2026-01-12
  author:
  - literal: Goel, S. K., & Rodriguez, D. M.
  container-title: Mathematics Magazine
  id: fbd8e02f-8560-36a2-a00c-e74f040810fc
  issn: 0025570X, 19300980
  issue: 4
  issued: 1987
  page: 225-228
  publisher: \[Mathematical Association of America, Taylor & Francis,
    Ltd.\]
  title: A note on evaluating limits using riemann sums
  type: article-journal
  url: "http://www.jstor.org/stable/2689344"
  volume: 60
- abstract: We examine how the binomial distribution B(n, p) arises as
    the distribution Sn = ∑i=1n Xi of an arbitrary sequence of Bernoulli
    variables. It is shown that B (n, p) arises in infinitely many ways
    as the distribution of dependent and non-identical Bernoulli
    variables, and arises uniquely as that of independent Bernoulli
    variables. A number of illustrative examples are given. The cases
    B(2, p) and B(3, p) are completely analyzed to bring out some of the
    intrinsic properties of the binomial distribution. The conditions
    under which Sn follows B(n, p), given that Sn-1 is not necessarily a
    binomial variable, are investigated. Several natural
    characterizations of B(n , p), including one which relates the
    binomial distributions and the Poisson process, are also given.These
    results and characterizations lead to a better understanding of the
    nature of the binomial distribution and enhance the utility.
  accessed: 2026-01-12
  author:
  - literal: Vellaisamy, P., & Punnen, A. P.
  container-title: Journal of Applied Probability
  id: fa0257d0-e7e0-3c60-a790-1bc8b1adf0c3
  issn: 00219002
  issue: 1
  issued: 2001
  page: 36-44
  publisher: Applied Probability Trust
  title: On the nature of the binomial distribution
  type: article-journal
  url: "http://www.jstor.org/stable/3215739"
  volume: 38
- abstract: The geometric distribution applies when an experiment is run
    repeatedly until a successful outcome occurs, and the probability of
    a success is the same for all trials. The random variable could be
    defined as the number of fails till the first success, and has a
    range of integers zero and above. The random variable could also be
    labeled as the number of trials till the first success and the range
    is integers one and above. Both scenarios are described in the
    chapter. This situation occurs, for example, when a process produces
    units that need to meet acceptable engineering standards, and the
    process is repeated until an acceptable unit is produced. When the
    probability of a successful outcome is not known, sample data can be
    used to estimate the probability. Sometimes, no sample data is
    available, and a person of experience offers an approximation on the
    distribution and this data is used to estimate the probability of a
    successful outcome. The chapter also describes how the geometric
    distribution is the only discrete distribution that has a memory
    less property.
  author:
  - literal: Thomopoulos, N. T.
  container-title: "Statistical distributions: Applications and
    parameter estimates"
  doi: 10.1007/978-3-319-65112-5_15
  id: Thomopoulos2017
  isbn: 978-3-319-65112-5
  issued: 2017
  page: 127-133
  publisher: Springer International Publishing
  publisher-place: Cham
  title: Geometric
  type: chapter
  url: "https://doi.org/10.1007/978-3-319-65112-5_15"
- abstract: "Let X1, X2, ⋯, Xn be independent identically distributed
    positive integer-valued random variables with order statistics X1:n,
    X2:n, ⋯, Xn:n. We prove that if the random variable X2:n - X1:n is
    independent of the events \\[X1:n = m\\] and \\[X1:n = k\\], for fixed k
    \\> m \\> 1, then the Xi's are geometric. This is related to a
    characterization problem raised by Arnold (1980)."
  accessed: 2026-01-13
  author:
  - literal: Sreehari M.
  container-title: Journal of Applied Probability
  id: 90db79eb-3312-380e-b218-3292416a6de2
  issn: 00219002
  issue: 1
  issued: 1983
  page: 209-212
  publisher: Applied Probability Trust
  title: A characterization of the geometric distribution
  type: article-journal
  url: "http://www.jstor.org/stable/3213738"
  volume: 20
- author:
  - literal: Zijlstra, M.
  container-title: Journal of Applied Probability
  doi: 10.2307/3213595
  id: Zijlstra_1983
  issue: 4
  issued: 1983
  page: 843-850
  title: Characterizations of the geometric distribution by
    distributional properties
  type: article-journal
  volume: 20
- accessed: 2026-01-16
  author:
  - literal: Dutka, J.
  container-title: Archive for History of Exact Sciences
  id: 30097c0e-8012-3a25-bb7a-d6c982c320c6
  issn: 00039519, 14320657
  issue: 1
  issued: 1984
  page: 15-34
  publisher: Springer
  title: The early history of the hypergeometric function
  type: article-journal
  url: "http://www.jstor.org/stable/41133728"
  volume: 31
- abstract: H Inc sequitur, quod. Si ex Tabellæ prop. 184. locis vacuis
    unus quilibet numero noto suppleatur, enurt & reliqui omnes cogniti.
  author:
  - literal: Berggren, L., Borwein, J., & Borwein, P.
  container-title: "Pi: A source book"
  doi: 10.1007/978-1-4757-3240-5_11
  id: Berggren2000
  isbn: 978-1-4757-3240-5
  issued: 2000
  page: 78-80
  publisher: Springer
  publisher-place: New York, NY
  title: Wallis. Arithmetica infinitorum (1655)
  type: chapter
  url: "https://doi.org/10.1007/978-1-4757-3240-5_11"
- abstract: "Publisher Summary The Arithmetica infinitorum was a key
    text in the 17th-century transition from geometry to algebra and in
    the development of infinite series and the integral calculus. The
    text contains the infinite fraction for 4/π that is now his chief
    claim to fame; but for his contemporaries, the most significant
    feature was the introduction of new methods, new concepts, and new
    vocabulary. Wallis came to Oxford with no more than a little
    self-taught mathematics, but within a few years, produced his most
    important work, the Arithmetica infinitorum. The Arithmetica
    infinitorum stands both chronologically and mathematically at the
    mid point of the 17th century, drawing together the best ideas from
    the first half of the century, the algebraic geometry of René
    Descartes, and the theory of indivisibles of Bonaventura Cavalieri
    (1598--1647), and preparing the ground for some of the astonishing
    advances of the second half: the discovery of the general binomial
    theorem, applications of infinite series, and the integral
    calculus."
  author:
  - literal: Stedall, J.
  container-title: Landmark writings in western mathematics 1640-1940
  doi: 10.1016/B978-044450871-3/50083-8
  editor:
  - literal: Grattan-Guinness, I., Cooke, R., Corry, L., Crépel, P., &
      Guicciardini, N.
  id: STEDALL200523
  isbn: 978-0-444-50871-3
  issued: 2005
  page: 23-32
  publisher: Elsevier Science
  publisher-place: Amsterdam
  title: Chapter 2 - john wallis, arithmetica infinitorum (1965)
  type: chapter
  url: "https://www.sciencedirect.com/science/article/pii/B9780444508713500838"
- abstract: The function represented by the infinite series
    \$\$\\sum\\limits\_{n = 0}\^\\infty
    {\\frac{{{{(a)}\_n}{{(b)}\_n}}}{{{{(c)}\_n}}}\\frac{{{z\^n}}}{{n!}}}
    \$\$within its circle of convergence and all the analytic
    continuations is called the hypergeometric function 2F1(a, b;
    c;z).\*
  author:
  - literal: Magnus, W., Oberhettinger, F., & Soni, R. P.
  container-title: Formulas and theorems for the special functions of
    mathematical physics
  doi: 10.1007/978-3-662-11761-3_2
  id: Magnus1966b
  isbn: 978-3-662-11761-3
  issued: 1966
  page: 37-65
  publisher: Springer
  publisher-place: Berlin, Heidelberg
  title: The hypergeometric function
  type: chapter
  url: "https://doi.org/10.1007/978-3-662-11761-3_2"
- abstract: The Fisher Exact test was proposed by Fisher (1934) in the
    fifth edition of Statistical Methods for Research Workers. It is a
    test for independence as opposed to association in 2
    `\texttimes`{=latex} 2 contingency tables.
  author:
  - literal: Sprent, P.
  container-title: International encyclopedia of statistical science
  doi: 10.1007/978-3-662-69359-9_693
  editor:
  - literal: Lovric, M.
  id: Sprent2025
  isbn: 978-3-662-69359-9
  issued: 2025
  page: 961-962
  publisher: Springer
  publisher-place: Berlin, Heidelberg
  title: The fisher exact test
  type: chapter
  url: "https://doi.org/10.1007/978-3-662-69359-9_693"
- abstract: Abstract For a finite population of subjects of two types,
    suppose we select a random sample without replacement. The
    probability distribution of the number in the sample of one of the
    two types is the hypergeometric distribution. This article presents
    the hypergeometric distribution, summarizes its properties,
    discusses binomial and normal approximations, and presents a
    multivariate generalization.
  author:
  - literal: Shuster, J. J.
  container-title: "Wiley StatsRef: Statistics reference online"
  doi: 10.1002/9781118445112.stat04869
  id: "doi:https://doi.org/10.1002/9781118445112.stat04869"
  isbn: 9781118445112
  issued: 2014
  keyword: binomial distribution, contingency tables, exact tests,
    independence, normal distribution, sampling without replacement,
    Yates's continuity correction
  publisher: John Wiley & Sons, Ltd
  title: "Hypergeometric distribution: introduction"
  title-short: Hypergeometric distribution
  type: chapter
  url: "https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118445112.stat04869"
- abstract: Abstract Exact tests evaluate the significance of a test
    statistic by using the test statistic's empirically derived sampling
    distribution instead of a theoretical sampling distribution.
    Preference for exact tests may occur in situations in which the
    sample size is small, or when the data have distributional
    deficiencies. Two well-known exact tests, Pitman's test and Fisher's
    test, are described.
  author:
  - literal: Hershberger, S. L.
  container-title: "Wiley StatsRef: Statistics reference online"
  doi: 10.1002/9781118445112.stat06165
  id: "doi:https://doi.org/10.1002/9781118445112.stat06165"
  isbn: 9781118445112
  issued: 2014
  keyword: asymptotic theory, nonparametric statistics, sampling
    distribution, resampling procedures, the bootstrap, Pitman test,
    Fisher's exact test, contingency table, hypergeometric distribution
  publisher: John Wiley & Sons, Ltd
  title: Exact methods for categorical data
  type: chapter
  url: "https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118445112.stat06165"
- abstract: This paper reviews the problems that bedevil the selection
    of an appropriate test for the analysis of a 2 × 2 table. In
    contradiction to an earlier paper, the author now argues the case
    for the use of Fisher's exact test. It is noted that all test
    statistics for the 2 × 2 table have discrete distributions and it is
    suggested that it is irrational to prescribe an unattainable fixed
    significance level. The use of mid-P is suggested, if a formula is
    required for prescribing a variable tail probability. The problems
    of two-tail tests are discussed.
  accessed: 2026-01-12
  author:
  - literal: Upton, G. J. G.
  container-title: Journal of the Royal Statistical Society. Series A
    (Statistics in Society)
  id: 5d8fa06c-0d2a-391a-b97f-85223f1f3b0f
  issn: 09641998, 1467985X
  issue: 3
  issued: 1992
  page: 395-402
  publisher: \[Wiley, Royal Statistical Society\]
  title: Fisher's exact test
  type: article-journal
  url: "http://www.jstor.org/stable/2982890"
  volume: 155
- abstract: A relationship is derived between the posterior probability
    of negative association of rows and columns of a 2 × 2 contingency
    table and Fisher's \"exact\" probability, as given in existing
    tables for testing the hypothesis of no association of rows and
    columns. The result for the 2 × 2 table is generalized to provide
    the posterior probability that one discrete-valued random variable
    is stochastically larger than another.
  accessed: 2026-01-12
  author:
  - literal: Altham, P. M. E.
  container-title: Journal of the Royal Statistical Society. Series B
    (Methodological)
  id: 202b9adf-f7a7-32c5-94dd-9f269c7f5a86
  issn: 00359246
  issue: 2
  issued: 1969
  page: 261-269
  publisher: \[Royal Statistical Society, Oxford University Press\]
  title: Exact bayesian analysis of a 2 × 2 contingency table, and
    fisher's \"exact\" significance test
  type: article-journal
  url: "http://www.jstor.org/stable/2984209"
  volume: 31
- abstract: It is demonstrated in this paper that two major tests for 2
    × 2 talbes are highly related from a Bayesian perspective. Although
    it is well-known that Fisher's exact and Pearson's chi-square tests
    are asymptotically equivalent, the present analysis shows that a
    formal similarity also exists in small samples. The key assumption
    that leads to the resemblance is the presence of a continuous
    parameter measuring association. In particular, it is shown that
    Pearson's probability can be obtained by integrating a two-moment
    approximation to the posterior distribution of the log-odds ratio.
    Furthermore, Pearson's chi-square test gave an excellent
    approximation to the actual Bayes probability in all 2×2 tables
    examined, except for those with extremely disproportionate marginal
    frequencies.
  author:
  - literal: Camilli, G.
  container-title: Psychometrika
  doi: 10.1007/BF02301418
  id: Camilli1995
  issue: 2
  issued: 1995
  title: "The relationship between fisher's exact test and pearson's
    chi-square test: A bayesian perspective"
  title-short: The relationship between fisher's exact test and
    pearson's chi-square test
  type: article-journal
  volume: 60
- abstract: Apart from the elementary transcendental functions such as
    the exponential and trigonometric functions and their inverses, the
    Gamma function is probably the most important transcendental
    function. It was defined by Euler to interpolate the factorials at
    noninteger arguments.
  author:
  - literal: Koepf, W.
  container-title: "Hypergeometric summation: An algorithmic approach to
    summation and special function identities"
  doi: 10.1007/978-1-4471-6464-7_1
  id: Koepf2014
  isbn: 978-1-4471-6464-7
  issued: 2014
  page: 1-10
  publisher: Springer
  publisher-place: London
  title: The gamma function
  type: chapter
  url: "https://doi.org/10.1007/978-1-4471-6464-7_1"
- abstract: The function $\Gamma$(z) is a meromorphic function of z with
    simple poles at z = −n, (n = 0, 1, 2,\...) with the respective
    residue \$\$\\frac{{{{( - 1)}\^n}}}{{n!}}.\$\$.
  author:
  - literal: Magnus, W., Oberhettinger, F., & Soni, R. P.
  container-title: Formulas and theorems for the special functions of
    mathematical physics
  doi: 10.1007/978-3-662-11761-3_1
  id: Magnus1966a
  isbn: 978-3-662-11761-3
  issued: 1966
  page: 1-37
  publisher: Springer
  publisher-place: Berlin, Heidelberg
  title: The gamma function and related functions
  type: chapter
  url: "https://doi.org/10.1007/978-3-662-11761-3_1"
- abstract: In this paper we prove a complete monotonicity theorem and
    establish some upper and lower bounds for the gamma function in
    terms of digamma and polygamma functions.
  author:
  - literal: Batir, N.
  container-title: Expositiones Mathematicae
  doi: 10.1016/j.exmath.2007.10.001
  id: BATIR2008187
  issn: 0723-0869
  issue: 2
  issued: 2008
  keyword: Gamma function, Digamma function, Polygamma functions,
    Complete monotonicity, Riemann zeta-function
  page: 187-196
  title: On some properties of the gamma function
  type: article-journal
  url: "https://www.sciencedirect.com/science/article/pii/S0723086907000497"
  volume: 26
- accessed: 2026-01-12
  author:
  - literal: Rasch, G.
  container-title: Annals of Mathematics
  id: 5bcebaa1-7494-336c-85e9-de3c540e9f64
  issn: 0003486X, 19398980
  issue: 3
  issued: 1931
  page: 591-599
  publisher: \[Annals of Mathematics, Trustees of Princeton University
    on Behalf of the Annals of Mathematics, Mathematics Department,
    Princeton University\]
  title: Notes on the gamma-function
  type: article-journal
  url: "http://www.jstor.org/stable/1968254"
  volume: 32
- accessed: 2026-01-12
  author:
  - literal: Gronwall, T. H.
  container-title: Annals of Mathematics
  id: 6b95b756-79df-32e7-8452-988d85f07718
  issn: 0003486X, 19398980
  issue: 2
  issued: 1918
  page: 35-124
  publisher: \[Annals of Mathematics, Trustees of Princeton University
    on Behalf of the Annals of Mathematics, Mathematics Department,
    Princeton University\]
  title: The gamma function in the integral calculus
  type: article-journal
  url: "http://www.jstor.org/stable/1967180"
  volume: 20
- abstract: "Since its inception in 1894, the Monthly has printed 50
    articles on the Γ function or Stirling's asymptotic formula,
    including the magisterial 1959 paper by Phillip J. Davis, which won
    the 1963 Chauvenet prize, and the eye-opening 2000 paper by the
    Fields medalist Manjul Bhargava. In this article, we look back and
    comment on what has been said, and why, and try to guess what will
    be said about the Γ function in future Monthly issues. We also
    identify some gaps, which surprised us: phase plots, Riemann
    surfaces, and the functional inverse of Γ make their first
    appearance in the Monthly here. We also give a new elementary
    treatment of the asymptotics of n! and the first few terms of a new
    asymptotic formula for invΓ."
  accessed: 2026-01-12
  author:
  - literal: Borwein, J. M., & Corless, R. M.
  container-title: The American Mathematical Monthly
  id: 7c7965cf-2aff-3860-a01c-d57527fbdc42
  issn: 00029890, 19300972
  issue: 5
  issued: 2018
  page: 400-424
  publisher: \[Taylor & Francis, Ltd., Mathematical Association of
    America\]
  title: Gamma and factorial in the monthly
  type: article-journal
  url: "https://www.jstor.org/stable/48663320"
  volume: 125
- accessed: 2026-01-12
  author:
  - literal: Davis, P. J.
  container-title: The American Mathematical Monthly
  id: f70ecf4e-6c25-3732-9fda-1e8986c07b3c
  issn: 00029890, 19300972
  issue: 10
  issued: 1959
  page: 849-869
  publisher: \[Taylor & Francis, Ltd., Mathematical Association of
    America\]
  title: "Leonhard euler's integral: A historical profile of the gamma
    function: In memoriam: Milton abramowitz"
  title-short: Leonhard euler's integral
  type: article-journal
  url: "http://www.jstor.org/stable/2309786"
  volume: 66
- abstract: This chapter first describes in Sect. 15.1 the
    t-distribution introduced by Gosset (1908) and its multivariate
    extensions, in the form of the multivariate t-distribution,
    Hotelling's T2-statistic and the F-distribution, all derived from
    sampling theory of a normal (or multivariate normal) distribution
    with unknown variance (or covariance matrix). It then develops the
    asymptotic distributions of these self-normalized sample means even
    when the population has infinite second moment. Related results such
    as the law of the iterated logarithm (LIL) for these self-normalized
    statistics are also described.
  author:
  - literal: Peña, V. H., Lai, T. L., & Shao, Q.-M.
  doi: 10.1007/978-3-540-85636-8_15
  id: delaPeña2009
  isbn: 978-3-540-85636-8
  issued: 2009
  page: 207-221
  publisher: Springer
  publisher-place: Berlin, Heidelberg
  title: "[The t-Statistic and Studentized Statistics\\\",
    bookTitle=\\\"Self-Normalized Processes: Limit Theory and Statistical
    Applications]{.nocase}"
  type: chapter
  url: "https://doi.org/10.1007/978-3-540-85636-8_15"
- author:
  - literal: Grigelionis, B.
  collection-title: Springer briefs in statistics
  doi: 10.1007/978-3-642-31146-8
  edition: 1
  id: Grigelionis2012
  issued: 2012
  publisher: Springer
  publisher-place: Berlin, Heidelberg
  title: "[Student's t-Distribution and Related Stochastic
    Processes]{.nocase}"
  type: book
- abstract: In this work, we present a new generalization of the
    student's t distribution. The new distribution is obtained by the
    quotient of two independent random variables. This quotient consists
    of a standard Normal distribution divided by the power of a chi
    square distribution divided by its degrees of freedom. Thus, the new
    symmetric distribution has heavier tails than the student's t
    distribution and extensions of the slash distribution. We develop a
    procedure to use quantile regression where the response variable or
    the residuals have high kurtosis. We give the density function
    expressed by an integral, we obtain some important properties and
    some useful procedures for making inference, such as moment and
    maximum likelihood estimators. By way of illustration, we carry out
    two applications using real data, in the first we provide maximum
    likelihood estimates for the parameters of the generalized student's
    t distribution, student's t, the extended slash distribution, the
    modified slash distribution, the slash distribution generalized
    student's t test, and the double slash distribution, in the second
    we perform quantile regression to fit a model where the response
    variable presents a high kurtosis.
  author:
  - literal: Reyes, J., Rojas, M. A., & Arrué, J.
  container-title: Symmetry
  doi: 10.3390/sym13122444
  id: sym13122444
  issn: 2073-8994
  issue: 12
  issued: 2021
  title: "[A New Generalization of the Student's t Distribution with an
    Application in Quantile Regression]{.nocase}"
  type: article-journal
  url: "https://www.mdpi.com/2073-8994/13/12/2444"
  volume: 13
- abstract: In this paper we provide rather weak conditions on a
    distribution which would guarantee that the t-statistic of a random
    vector of order n follows the t-distribution with n-1 degrees of
    freedom. The results sharpen the earlier conclusions of Mauldon
    \[Characterizing properties of statistical distributions, Quart. J.
    Math. 2(7) (1956) 155--160\] and the more recent advances due to
    Bondesson \[When is the t-statistic t-distributed, Sankhyā, Ser. A
    45 (1983) 338--345\]. The basic tool involved in the derivations is
    the vertical density representation originally suggested by Troutt
    \[A theorem on the density of the density ordinate and an
    alternative interpretation of the Box--Muller method, Statistics
    22(3) (1991) 463--466; Vertical density representation and a further
    remark on the Box--Muller method, Statistics 24 (1993) 81--83\].
    Several illustrative examples are presented.
  author:
  - literal: Yang, Z., Fang, K.-T., & Kotz, S
  container-title: Journal of Multivariate Analysis
  doi: 10.1016/j.jmva.2006.11.003
  id: YANG20071293
  issn: 0047-259X
  issue: 6
  issued: 2007
  page: 1293-1304
  title: "[On the Student's t-distribution and the
    t-statistic]{.nocase}"
  type: article-journal
  url: "https://www.sciencedirect.com/science/article/pii/S0047259X06002004"
  volume: 98
- abstract: "We develop a Bayesian analysis based on two different
    Jeffreys priors for the Student-t regression model with unknown
    degrees of freedom. It is typically difficult to estimate the number
    of degrees of freedom: improper prior distributions may lead to
    improper posterior distributions, whereas proper prior distributions
    may dominate the analysis. We show that Bayesian analysis with
    either of the two considered Jeffreys priors provides a proper
    posterior distribution. Finally, we show that Bayesian estimators
    based on Jeffreys analysis compare favourably to other Bayesian
    estimators based on priors previously proposed in the literature."
  accessed: 2026-01-17
  author:
  - literal: Fonseca, T. C. O., Ferreira, M. A. R., & Migon, H. S.
  container-title: Biometrika
  id: 8bbd2dac-610f-3a49-b88b-7ff72e396d2e
  issn: 00063444, 14643510
  issue: 2
  issued: 2008
  page: 325-333
  publisher: \[Oxford University Press, Biometrika Trust\]
  title: "[Objective Bayesian Analysis for the Student-t Regression
    Model]{.nocase}"
  type: article-journal
  url: "http://www.jstor.org/stable/20441467"
  volume: 95
- abstract: The Student's t distribution is the most popular model for
    economic and financial data. In recent years, many generalizations
    of the Student's t distribution have been proposed. This paper
    provides a review of generalizations, including software available
    for them. A real data application is presented to compare some of
    the reviewed distributions.
  author:
  - literal: Li, R., & Nadarajah, S.
  container-title: Empirical Economics
  doi: 10.1007/s00181-018-1570-0
  id: Li2020
  issue: 3
  issued: 2020
  page: 1461-1490
  title: "[A review of Student's t distribution and its
    generalizations]{.nocase}"
  type: article-journal
  volume: 58
- author:
  - literal: Edelman, D.
  container-title: arXiv
  doi: 10.48550/arXiv.2508.13226
  id: edelman2025worstcasenonparametricboundsstudent
  issued: 2025-09
  title: "[Worst-case Nonparametric Bounds for the Student
    t-statistic]{.nocase}"
  type: article-journal
- author:
  - literal: Kirkby, J. L., Nguyen, D., & Nguyen, D.
  container-title: arXiv
  doi: 10.48550/arXiv.1912.01607
  id: kirkby2024momentsstudentstdistributionunified
  issued: 2024-12-17
  title: "Moments of student's t-distribution: A unified approach"
  title-short: Moments of student's t-distribution
  type: article-journal
- abstract: The distribution of $\chi$`<!-- -->`{=html}2(chi squared) is
    a continuous and asymmetrical distribution which ranges from 0 to +
    ∞ and is followed by a sum of squares of independent standardized
    normal variates. The $\chi$`<!-- -->`{=html}2distribution and its
    application to frequency tables (chapter 15) were discovered by the
    British biometrician Karl Pearson (1857--1936), who was considered
    as the "father of biometry" and was one of the founders of the
    periodical Biometrika. The $\chi$`<!-- -->`{=html}2distribution is
    exact when hypotheses must be tested or confidence intervals must be
    determined (chapter 10) concerning the parametric variance
    $\sigma$`<!-- -->`{=html}2of a continuous variate X which follows a
    normal distribution (chapter 5). Moreover, the
    $\chi$`<!-- -->`{=html}2distribution may be used as an approximation
    in many cases, including Bartlett's test of the homogeneity of
    variance (section 12.7), tests of hypotheses concerning frequency
    tables (chapter 15), tests of goodness of fit (chapters 16, 17 and
    18), the binomiality (chapter 17) and Poissonianity (chapter 18)
    tests, etc.. Paradoxically, the approximate utilizations of the
    $\chi$`<!-- -->`{=html}2distribution are perhaps better known than
    the exact ones.
  author:
  - literal: Jolicoeur, P.
  container-title: Introduction to biometry
  doi: 10.1007/978-1-4615-4777-8_8
  id: Jolicoeur1999
  isbn: 978-1-4615-4777-8
  issued: 1999
  page: 38-39
  publisher: Springer US
  publisher-place: Boston, MA
  title: The distribution of $\chi$`<!-- -->`{=html}2 (chi squared)
  type: chapter
  url: "https://doi.org/10.1007/978-1-4615-4777-8_8"
- author:
  - literal: Das, A.
  id: das2025newmethodscomputegeneralized
  issued: 2025
  title: New methods to compute the generalized chi-square distribution
  url: "https://arxiv.org/abs/2404.05062"
- author:
  - literal: Chattamvelli, R., & Shanmugam, R.
  container-title: Continuous distributions in engineering and the
    applied sciences -- part II
  doi: 10.1007/978-3-031-02435-1_7
  id: Chattamvelli2021
  isbn: 978-3-031-02435-1
  issued: 2021
  page: 227-234
  publisher: Springer International Publishing
  publisher-place: Cham
  title: F Distribution
  type: chapter
  url: "https://doi.org/10.1007/978-3-031-02435-1_7"
- abstract: Die letzte der drei wichtigsten Test-Verteilungen ist die
    F-Verteilung mit der Verteilungsfunktion Die Bedeutung der
    F-Verteilung liegt darin, daß mit zwei $\chi$`<!-- -->`{=html}2
    -verteilten Größen X2 und Y2 mit den Freiheitsgraden f1 bzw.
    f2F-verteilt ist. Die F-Verteilung hat somit zwei Freiheitsgrade.
    Sie ist eine sehr allgemeine Funktion, denn sie geht für f1 = 1, t =
    `\textsurd`{=latex}F in die t-Verteilung f1 = 1, f2 = ∞, z =
    `\textsurd`{=latex}F in die Normalverteilung über.
  author:
  - literal: Herrmann, D.
  container-title: Wahrscheinlichkeitsrechnung und statistik --- 30
    BASIC-programme
  doi: 10.1007/978-3-322-96320-8_21
  id: Herrmann1984
  isbn: 978-3-322-96320-8
  issued: 1984
  page: 40-41
  publisher: Vieweg+Teubner Verlag
  publisher-place: Wiesbaden
  title: F-Verteilung
  type: chapter
  url: "https://doi.org/10.1007/978-3-322-96320-8_21"
- abstract: Die Standardnormalverteilung ist ohne Zweifel die wichtigste
    und grundlegendste Verteilungsform in der Statistik. Sie ist von
    fundamentaler Bedeutung für die Schätzung von Parametern, aber auch
    zur Konstruktion von Teststatistiken. Nicht alle Teststatistiken
    aber können so konstruiert werden, dass sie normalverteilt sind. Die
    Teststatistiken von wichtigen statistischen Tests haben oft auch
    andere Verteilungsformen, die allerdings aus der
    Standardnormalverteilung abgeleitet werden können. Die wichtigsten
    dieser weiteren Verteilungen sind die so genannte Chi -Verteilung
    und die F-Verteilung. Die Chi2 -Verteilung wird unter anderem bei
    der Untersuchung von Zusammenhängen zwischen nominalskalierten
    Variablen eingesetzt, aber sie kann in einem wesentlich weiteren
    Sinn in vielen Fällen für den Vergleich einer theoretischen
    Verteilung mit einer empirischen Verteilung herangezogen werden. Die
    F-Verteilung spielt vor allem für den Vergleich von Varianzen eine
    herausragende Rolle. Schon bekannt ist uns außerdem die
    T-Verteilung, die im Prinzip überall dort Verwendung findet, wo auch
    die Standard-normalverteilung eingesetzt werden kann, wo aber die
    Standardabweichung der Grundgesamtheit erst mit Hilfe der
    Standardabweichung der Stichprobe geschätzt werden muss. Wir greifen
    die T-Verteilung in diesem Kapitel noch einmal kurz auf, um ihre
    Beziehung zur Standardnormalverteilung noch etwas genauer zu klären.
  author:
  - literal: Behnke, J., & Behnke, N.
  container-title: "Grundlagen der statistischen datenanalyse: Eine
    einführung für politikwissenschaftler"
  doi: 10.1007/978-3-531-90003-2_26
  id: Behnke2006
  isbn: 978-3-531-90003-2
  issued: 2006
  page: 344-355
  publisher: VS Verlag für Sozialwissenschaften
  publisher-place: Wiesbaden
  title: Verteilungen, die von der standardnormalverteilung abgeleitet
    werden können
  type: chapter
  url: "https://doi.org/10.1007/978-3-531-90003-2_26"
- abstract: "Vorgelegt seien zwei Normalverteilungen 1 und 2, die
    beispielsweise zu zwei Erzeugungsvorgängen gehören, mit unbekannten
    Varianzen $\\sigma$`<!-- -->`{=html}12und
    $\\sigma$`<!-- -->`{=html}22. Man will entscheiden, ob beide Vorgänge
    mit der gleichen Varianz für die Merkmalwerte ablaufen. Mit anderen
    Worten: Es soll die Hypothese $\\sigma$`<!-- -->`{=html}12=
    $\\sigma$`<!-- -->`{=html}22getestet werden. Verfügbar ist aus jeder
    Verteilung eine Zufallsprobe der Größe n1 bzw. n2 mit der Varianz
    s12bzw. s22. Als Prüfgröße, mit der man die Entscheidung fällt,
    wählt man das Verhältnis s12/s22der Stichprobenvarianzen."
  author:
  - literal: Stange, K.
  container-title: "Angewandte statistik: Erster teil eindimensionale
    probleme"
  doi: 10.1007/978-3-642-85602-0_11
  id: Stange1970
  isbn: 978-3-642-85602-0
  issued: 1970
  page: 357-372
  publisher: Springer
  publisher-place: Berlin, Heidelberg
  title: Die F-Verteilung
  type: chapter
  url: "https://doi.org/10.1007/978-3-642-85602-0_11"
- abstract: "Die in den Kapiteln 11, 12 und 13 behandelten statistischen
    Hypothesen waren Parameterhypothesen in dem Sinne, daß Aussagen über
    einzelne Verteilungsparameter (z.B.: geprüft werden sollten. Häufig
    hat man aber allgemeinere Aussagen über die den Daten
    zugrundeliegende Verteilung zu testen. Man möchte zum Beispiel
    wissen, ob die Annahme, daß die Daten normal-verteilt sind, haltbar
    ist, oder ob zwei Verteilungen deutlich oder kaum verschieden sind."
  author:
  - literal: Hafner, R.
  container-title: "Statistik: Für sozial- und
    wirtschaftswissenschaftler"
  doi: 10.1007/978-3-7091-3420-7_14
  id: Hafner1992
  isbn: 978-3-7091-3420-7
  issued: 1992
  page: 164-170
  publisher: Springer
  publisher-place: Vienna
  title: Der chi-quadrat-test
  type: chapter
  url: "https://doi.org/10.1007/978-3-7091-3420-7_14"
- author:
  - literal: Brereton, R. G.
  container-title: Journal of Chemometrics
  doi: 10.1002/cem.2734
  id: "https://doi.org/10.1002/cem.2734"
  issue: 11
  issued: 2015
  page: 582-586
  title: "[The F distribution and its relationship to the chi squared
    and t distributions]{.nocase}"
  type: article-journal
  url: "https://analyticalsciencejournals.onlinelibrary.wiley.com/doi/abs/10.1002/cem.2734"
  volume: 29
- abstract: Abstract The F-distribution is fundamental to much of
    statistical analysis, particularly the analysis of variance. The
    article entitled "F-Distribution" is a brief but complete
    description of this probability distribution. Its properties are
    first discussed, followed by a description of the relationship
    between the F-distribution and other common statistical
    distributions (e.g. beta, t-, chi-square, and binomial
    distributions). The article concludes with a typical application of
    this distribution to a small set of sampled observations.
  author:
  - literal: Selvin, S.
  container-title: "Wiley StatsRef: Statistics reference online"
  doi: 10.1002/9781118445112.stat05856
  id: "doi:https://doi.org/10.1002/9781118445112.stat05856"
  isbn: 9781118445112
  issued: 2014
  keyword: "-distribution, variance, probability distribution"
  publisher: John Wiley & Sons, Ltd
  title: F Distributions
  type: chapter
  url: "https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118445112.stat05856"
- abstract: An accurate normal approximation for the cumulative
    distribution function of the chi-square distribution with n degrees
    of freedom is proposed. This considers a linear combination of
    appropriate fractional powers of chi-square. Numerical results show
    that the maximum absolute error associated with the new
    transformation is substantially lower than that found for other
    power transformations of a chi-square random variable for all the
    degrees of freedom considered (1⩽n⩽1000).
  author:
  - literal: Canal, L.
  container-title: Computational Statistics & Data Analysis
  doi: 10.1016/j.csda.2004.04.001
  id: CANAL2005803
  issn: 0167-9473
  issue: 4
  issued: 2005
  keyword: Chi-square distribution, Maximum absolute error, Normal
    approximation, Power transformation
  page: 803-808
  title: A normal approximation for the chi-square distribution
  type: article-journal
  url: "https://www.sciencedirect.com/science/article/pii/S0167947304001069"
  volume: 48
- abstract: The distribution of the χ2 test under the null hypothesis is
    studied, when the parameters are estimated by the method of moments.
    A general formula, applicable also to other situations, is given.
    Three examples are studied in more detail and numerical results are
    given, indicating how unsafe it can be to use a χ2 distribution with
    a number of degrees of freedom smaller than or equal to the number
    of cells.
  accessed: 2026-01-13
  author:
  - literal: Molinari, L.
  container-title: Biometrika
  id: a71e7dcf-67b3-3b81-a0c2-17153341fab1
  issn: 00063444, 14643510
  issue: 1
  issued: 1977
  page: 115-121
  publisher: \[Oxford University Press, Biometrika Trust\]
  title: Distribution of the chi-squared test in nonstandard situations
  type: article-journal
  url: "http://www.jstor.org/stable/2335780"
  volume: 64
- abstract: A procedure for interpolating in tables of the
    F-distribution is proposed. This procedure is already known by many
    statisticians, although its original source has been forgotten. A
    table gives an upper bound for the relative error in the
    interpolation between some tabulated values. An example is given.
  accessed: 2026-01-13
  author:
  - literal: Zinger, A.
  container-title: Journal of the Royal Statistical Society. Series C
    (Applied Statistics)
  id: b3bc6554-760a-35aa-92dd-1ef8068d343e
  issn: 00359254, 14679876
  issue: 1
  issued: 1964
  page: 51-53
  publisher: \[Royal Statistical Society, Oxford University Press\]
  title: "[On Interpolation in Tables of the F-Distribution]{.nocase}"
  type: article-journal
  url: "http://www.jstor.org/stable/2985223"
  volume: 13
- accessed: 2026-01-13
  author:
  - literal: Wilson, E. B., & Hilferty, M. M.
  container-title: Proceedings of the National Academy of Sciences of
    the United States of America
  id: b71582f9-54b0-3efd-95a7-a60d1005dd3b
  issn: 00278424, 10916490
  issue: 12
  issued: 1931
  page: 684-688
  publisher: National Academy of Sciences
  title: The distribution of chi-square
  type: article-journal
  url: "http://www.jstor.org/stable/86022"
  volume: 17
- abstract: A relation is derived between the percentile points of a
    t-distribution with n degrees of freedom and those of an
    F-distribution with n and n degrees of freedom. In effect, the
    t-percentiles can be obtained by a simple transformation from the
    \"diagonal\" entries of an F-table.
  accessed: 2026-01-13
  author:
  - literal: Cacoullos, T.
  container-title: Journal of the American Statistical Association
  id: c9bb1879-be2e-3251-9489-81b3cdab8ab2
  issn: 01621459, 1537274X
  issue: 310
  issued: 1965
  page: 528-531
  publisher: \[American Statistical Association, Taylor & Francis,
    Ltd.\]
  title: "[A Relation Between t and F-Distributions]{.nocase}"
  type: article-journal
  url: "http://www.jstor.org/stable/2282687"
  volume: 60
- author:
  - literal: Saunders, I. W., & Moran, P. A. P.
  container-title: Journal of Applied Probability
  doi: 10.2307/3213414
  id: Saunders_Moran_1978
  issue: 2
  issued: 1978
  page: 426-432
  title: "[On the quantiles of the gamma and F distributions]{.nocase}"
  type: article-journal
  volume: 15
- accessed: 2026-01-13
  author:
  - literal: Patnaik, P. B.
  container-title: Biometrika
  id: e800b171-dd42-3678-b651-8375c1fde110
  issn: 00063444, 14643510
  issue: 1/2
  issued: 1949
  page: 202-232
  publisher: \[Oxford University Press, Biometrika Trust\]
  title: "[The Non-Central χ2- and F-Distribution and their
    Applications]{.nocase}"
  type: article-journal
  url: "http://www.jstor.org/stable/2332542"
  volume: 36
- abstract: One of the most interesting problems studied in Random Field
    Theory (RFT) is to approximate the distribution of the maximum of a
    random field. This problem usually appears in a general hypothesis
    testing framework, where the statistics of interest are the maximum
    of a random field of a known distribution. In this paper, we use the
    RFT approach to compare two independent correlation random fields,
    R1 and R2. Our statistics of interest are the maximum of a random
    field G, resulting from the difference between the Fisher's Z
    transformation of R1 and R2, respectively. The Fisher's Z
    transformation guarantees a Gaussian distribution at each point of G
    but, unfortunately, G is not transformed into a Gaussian random
    field. Hence, standard results of RFT for Gaussian random fields are
    not longer available for G. We show here that the distribution of
    the maximum of G can still be approximated by the distribution of
    the maximum of a Gaussian random field, provided there is some
    correction by its spatial smoothness. Indeed, we present a general
    setting to obtain this correction. This is done by allowing
    different smoothness parameters for the components of G. Finally,
    the performance of our method is illustrated by means of both
    numerical simulations and real Electroencephalography data, recorded
    during a face recognition experimental paradigm.
  author:
  - literal: Carbonell, F., Worsley, K. J., & Trujillo-Barreto, N. J.
  container-title: Statistics & Probability Letters
  doi: 10.1016/j.spl.2008.11.007
  id: CARBONELL2009780
  issn: 0167-7152
  issue: 6
  issued: 2009
  page: 780-788
  title: "[On the Fisher's Z transformation of correlation random
    fields]{.nocase}"
  type: article-journal
  url: "https://www.sciencedirect.com/science/article/pii/S0167715208005154"
  volume: 79
- accessed: 2026-01-13
  author:
  - literal: Hjelm, H. F., & Norris, R. C.
  container-title: The Journal of Experimental Education
  id: 67d2aa04-e169-3e9d-9c2d-31d37c595ef4
  issn: 00220973, 19400683
  issue: 3
  issued: 1962
  page: 269-277
  publisher: Taylor & Francis, Ltd.
  title: "[Empirical Study of the Efficacy of Fisher's
    Z-Transformation]{.nocase}"
  type: article-journal
  url: "http://www.jstor.org/stable/20156574"
  volume: 30
- author:
  - literal: Bond, C. F., & Richardson, K.
  container-title: Psychometrika
  doi: 10.1007/BF02295945
  id: Bond_Richardson_2004
  issue: 2
  issued: 2004
  page: 291-303
  title: "[Seeing the Fisher Z-transformation]{.nocase}"
  type: article-journal
  volume: 69
- author:
  - literal: Mendoza, J. L.
  container-title: Psychometrika
  doi: 10.1007/BF02294830
  id: Mendoza_1993
  issue: 4
  issued: 1993
  page: 601-615
  title: Fisher transformations for correlations corrected for selection
    and missing data
  type: article-journal
  volume: 58
- accessed: 2026-01-13
  author:
  - literal: David, F. N.
  container-title: Biometrika
  id: fcdfa5ac-5e28-3f56-8f5f-82b584b870a3
  issn: 00063444, 14643510
  issue: 3/4
  issued: 1949
  page: 394-403
  publisher: \[Oxford University Press, Biometrika Trust\]
  title: "[The Moments of the z and F Distributions]{.nocase}"
  type: article-journal
  url: "http://www.jstor.org/stable/2332676"
  volume: 36
- abstract: A new explicit quadratic radical function is found by
    numerical experiments, which is simpler and has only 70.778
  author:
  - literal: Yang, Z., Duan, Z., Wang, J., Wang, T., Song, Y., & Zhang,
      J.
  container-title: Transactions of Tianjin University
  doi: 10.1007/s12209-013-1978-8
  id: Yang2013
  issued: 2013
  page: 381-384
  title: "[Quadratic radical function better than fisher Z
    transformation]{.nocase}"
  type: article-journal
  volume: 5
- abstract: "There are many different frequency distributions in
    statistics, some of which we shall meet later in the book, but one
    in particular applies to the theory of errors. This is the normal or
    Gaussian distribution. The word 'normal' is here used in its
    original sense of 'ideal', for it was believed for a long time that
    this distribution was a reflection of a universal and fundamental
    law of nature. If certain assumptions are made it can be 'proved'
    that the accumulation of a large number of small independent random
    deviations follows a normal law, but belief in the rigour of this
    proof is no longer widespread. There is a well-known quotation on
    the subject: 'Everybody believes in the Gaussian law of errors; the
    experimenters because they think it will be proved by mathematics;
    and the mathematicians because they believe it has been established
    by observation.' However, for our present purposes we can assume
    that the Gaussian distribution is the best possible representation
    of the variation of small random errors."
  author:
  - literal: Leaver, R. H., & Thomas, T. R.
  container-title: Analysis and presentation of experimental results
  doi: 10.1007/978-1-349-01942-7_4
  id: Leaver1974
  isbn: 978-1-349-01942-7
  issued: 1974
  page: 30-37
  publisher: Macmillan Education UK
  publisher-place: London
  title: Normal distribution
  type: chapter
  url: "https://doi.org/10.1007/978-1-349-01942-7_4"
- abstract: The phrases 'it is probable that', 'it is very likely that',
    'there is virtually no chance' are often used in conversation. They
    are used to describe events which could possibly happen. They
    represent our estimates of the probability of the events happening.
    They are sometimes based on personal feelings, but more often they
    are based on relative frequency, i.e. the proportion of times such
    an event has happened previously. These subjective or intuitive
    ideas of probability are basic and fundamental in life and they give
    rise to two definitions of probability which are now discussed.
  author:
  - literal: Mulholland, H., & Jones, C. R.
  container-title: Fundamentals of statistics
  doi: 10.1007/978-1-4899-6507-3_3
  id: Mulholland1968a
  isbn: 978-1-4899-6507-3
  issued: 1968
  page: 32-58
  publisher: Springer US
  publisher-place: Boston, MA
  title: Elementary probability
  type: chapter
  url: "https://doi.org/10.1007/978-1-4899-6507-3_3"
- abstract: "The normal distribution is probably the most widely studied
    distribution in statistics because :(a)Distributions which are
    approximately normal are frequently encountered, e.g. most sets of
    random errors follow the normal distribution.(b)The normal
    distribution is important as a 'limiting distribution', i.e. it can
    be used as an approximation to other distributions (see sections 8.7
    and 8.8).(c)The normal distribution is easy to use.(d)It has been
    shown that the results obtained by assuming a non-normal population
    to be normally distributed are reasonably accurate when the
    departure from normality is not too severe.(e)The central limit
    theorem shows that the means of samples of size n from any
    population are approximately normally distributed. The approximation
    improves as n gets bigger."
  author:
  - literal: Mulholland, H., & Jones, C. R.
  container-title: Fundamentals of statistics
  doi: 10.1007/978-1-4899-6507-3_8
  id: Mulholland1968b
  isbn: 978-1-4899-6507-3
  issued: 1968
  page: 122-138
  publisher: Springer US
  publisher-place: Boston, MA
  title: The normal distribution
  type: chapter
  url: "https://doi.org/10.1007/978-1-4899-6507-3_8"
- abstract: "Bedeutung der Normalverteilung: Die Normalverteilung ist
    ein wichtiges Modell: es beschreibt die Streuung von Meßwerten um
    ihren Mittelwert. Meßfehler sind als zufällige Fehler
    \\[unvermeidbar, symmetrisch, meist klein\\] oft angenähert
    normalverteilt. Der Praktiker muß sich damit abfinden, daß es,
    streng genommen, in der Empirie keine Normalverteilung gibt.
    Indessen lassen sich viele mehr oder weniger symmetrisch-eingipflig
    verteilte Beobachtungen zumindest in ihrem mittleren Bereich als
    angenähert normalverteilt auffassen."
  author:
  - literal: Sachs, L.
  container-title: "Statistische methoden: Planung und auswertung"
  doi: 10.1007/978-3-642-77717-2_4
  id: Sachs1993
  isbn: 978-3-642-77717-2
  issued: 1993
  page: 41-54
  publisher: Springer
  publisher-place: Berlin, Heidelberg
  title: Normalverteilung
  type: chapter
  url: "https://doi.org/10.1007/978-3-642-77717-2_4"
- author:
  - literal: Saneii, S. H., & Doosti, H.
  container-title: Practical biostatistics for medical and health
    sciences
  doi: 10.1007/978-981-97-3083-4_6
  id: Saneii2024
  isbn: 978-981-97-3083-4
  issued: 2024
  page: 115-137
  publisher: Springer
  publisher-place: Singapore
  title: Normal distribution
  type: chapter
  url: "https://doi.org/10.1007/978-981-97-3083-4_6"
- author:
  - literal: Wesolowski, B., & Musselwhite Thompson, D.
  container-title: The SAGE encyclopedia of educational research,
    measurement, and evaluation
  doi: 10.4135/9781506326139.n476
  editor:
  - literal: Frey, B. B.
  id: Wesolowski2018
  issued: 2018
  publisher: University of Kansas
  publisher-place: USA
  title: Normal distribution
  type: chapter
- author:
  - literal: Benzon, B.
  container-title: St open
  doi: 10.48188/so.2.6
  id: Benzon2021
  issued: 2021-07
  page: 1-16
  title: The normal distribution, an epistemological view
  type: article-journal
  volume: 2
- abstract: Abstract It is less emphasized in scientific literature that
    centering and scaling of data may drastically change the original
    distribution of the data for small samples. The destruction of the
    original distribution depends on the source of the estimation of the
    mean (centering) and the divisor (scaling) where the latter is
    connected to the spread of data. In our comparative study we focus
    on cases, where the sample is taken from normally distributed data;
    the means and the standard deviations are population or sample
    based. We discuss six cases in transforming the data or the sample
    means. Most of them are studied previously, but some of them have
    not been theoretically investigated. The transformed data follow
    normal distribution in three cases, if the scaling is performed with
    population standard deviation. In one case, the final distribution
    is related to β-distribution with astonishing density functions for
    N = 2 Dirac-delta, N = 3 Viking helmet like and N = 4 uniform
    distributions. Another case is the well-known t-distribution. For
    one of the transformed data, we were not able to identify the
    general form. Here we obtained only numerical results for 3 ≤ N. The
    effect of the transformations was tested on experimental data
    representing more or less normally distributed variables. We found
    that transformations using the sample standard deviation were
    significantly less normally distributed-like than the original data
    for small samples, but the other transformations enhanced the normal
    distribution-like feature. The results point out that centering and
    especially scaling require consideration for small samples up to
    questioning the reality of subsequent data evaluation processes
    where normal distribution is assumed. Copyright © 2011 John Wiley &
    Sons, Ltd.
  author:
  - literal: Tóth, G.
  container-title: Journal of Chemometrics
  doi: 10.1002/cem.1382
  id: "https://doi.org/10.1002/cem.1382"
  issue: 5
  issued: 2011
  keyword: centering, scaling, studentization, standardization, normal
    distribution
  page: 247-253
  title: Destruction of normal distribution in small samples by
    centering and scaling
  type: article-journal
  url: "https://analyticalsciencejournals.onlinelibrary.wiley.com/doi/abs/10.1002/cem.1382"
  volume: 25
- author:
  - literal: Brereton, R. G.
  container-title: Journal of Chemometrics
  doi: 10.1002/cem.2655
  id: "https://doi.org/10.1002/cem.2655"
  issue: 11
  issued: 2014
  page: 789-792
  title: The normal distribution
  type: article-journal
  volume: 28
- abstract: "Let X1:3≤X2:3≤X3:3 be the order statistics of the
    independent and identically distributed random variables X1, X2, and
    X3. Using the regressional property
    E\\[(aX2:3−X1:3)2\\|X2:3=x\\]=E\\[(X3:3−aX2:3)2\\|X2:3=x\\], we
    characterize some distributions, including Student's tν
    distributions (ν\\>2) and normal distributions."
  author:
  - literal: Wang, J.
  container-title: Statistics & Probability Letters
  doi: 10.1016/j.spl.2011.03.037
  id: WANG2011903
  issn: 0167-7152
  issue: 8
  issued: 2011
  keyword: Characterization, Order statistics, Regressional property
  page: 903-906
  title: A simple characterization of student's distributions and normal
    distributions
  type: article-journal
  url: "https://www.sciencedirect.com/science/article/pii/S0167715211001283"
  volume: 81
- abstract: Publisher Summary This chapter focuses on the concept of
    normal distribution. It also describes population parameters and
    their estimators. To summarize the characteristics of a
    distribution, its moments can be used. The best known probability
    distribution is the normal distribution. Distributions can be
    non-normal and procedures or tests are needed to detect this
    departure from normality. A graphical procedure is described in the
    chapter that permits to indicate whether a distribution is normal or
    not. The graphical procedure applied is called the "rankit
    procedure." A bacteriological example provides a clue to the way to
    make non-normal distributions normal--- namely, by transformation.
    The transformation carried out in the chapter is called the
    "log-transformation." Log-normal distributions are frequently found
    in nature, particularly when the variable studied has a natural zero
    (such as weight, length, etc.). In this case, simple normality
    around the mean could include negative values.
  collection-title: Data handling in science and technology
  container-title: "Handbook of chemometrics and qualimetrics: Part a"
  doi: 10.1016/S0922-3487(97)80033-0
  editor:
  - literal: Massart, D. L., Vandeginste, B. G. M., Buydens, L. M. C.,
      De Jong, S., Lewi, P. J., & Smeyers-Verbeke, J.
  id: 199847
  issn: 0922-3487
  issued: 1998
  page: 47-72
  publisher: Elsevier
  title: Chapter 3 the normal distribution
  type: chapter
  url: "https://www.sciencedirect.com/science/article/pii/S0922348797800330"
  volume: 20
- abstract: It is usually supposed that the central limit theorem
    explains why various quantities we find in nature are approximately
    normally distributed---people's heights, examination grades,
    snowflake sizes, and so on. This sort of explanation is found in
    many textbooks across the sciences, particularly in biology,
    economics, and sociology. Contrary to this received wisdom, I argue
    that in many cases we are not justified in claiming that the central
    limit theorem explains why a particular quantity is normally
    distributed, and that in some cases, we are actually wrong.
    1 Introduction2 Normal Distributions and the Central Limit
    Theorem  2.1 Normal distributions  2.2 The central limit
    theorem  2.3 Terminology3 Explaining Normality  3.1 Loaves of
    bread  3.2 Varying variances and probability densities  3.3 Tensile
    strengths and problems with summation  3.4 Products of factors and
    log-normal distributions  3.5 Transforming factors and
    sub-factors  3.6 Transformations of quantities  3.7 Quantitative
    genetics  3.8 Inference to the best explanation4 Maximum Entropy
    Explanations5 Conclusion
  author:
  - literal: Lyon, A.
  container-title: The British Journal for the Philosophy of Science
  doi: 10.1093/bjps/axs046
  id: "doi:10.1093/bjps/axs046"
  issue: 3
  issued: 2014
  page: 621-649
  title: Why are normal distributions normal?
  type: article-journal
  volume: 65
- accessed: 2026-01-14
  author:
  - literal: Stahl, S.
  container-title: Mathematics Magazine
  id: 2e210a69-a2e7-3fa7-96e2-b30efac9ed56
  issn: 0025570X, 19300980
  issue: 2
  issued: 2006
  page: 96-113
  publisher: Mathematical Association of America
  title: The evolution of the normal distribution
  type: article-journal
  url: "http://www.jstor.org/stable/27642916"
  volume: 79
- accessed: 2026-01-14
  author:
  - literal: Breitenberger, E.
  container-title: Biometrika
  id: 8ccd5f0b-f3d0-3894-a051-95d6e3d4ed98
  issn: 00063444
  issue: 1/2
  issued: 1963
  page: 81-88
  publisher: \[Oxford University Press, Biometrika Trust\]
  title: Analogues of the normal distribution on the circle and the
    sphere
  type: article-journal
  url: "http://www.jstor.org/stable/2333749"
  volume: 50
- accessed: 2026-01-14
  author:
  - literal: Thome, H.
  container-title: Historical Social Research / Historische
    Sozialforschung. Supplement
  id: 57fba293-9d42-3fd4-9780-f77567f507d7
  issn: 09366784
  issue: 3
  issued: 1990
  page: 1-275
  publisher: GESIS - Leibniz-Institute for the Social Sciences, Center
    for Historical Social Research
  title: "GRUNDKURS STATISTIK FÜR HISTORIKER TEIL II: INDUKTIVE
    STATISTIK UND REGRESSIONSANALYSE"
  title-short: GRUNDKURS STATISTIK FÜR HISTORIKER TEIL II
  type: article-journal
  url: "http://www.jstor.org/stable/40986007"
- abstract: "We study the asymptotic covariance function of the sample
    mean and quantile, and derive a new and surprising characterization
    of the normal distribution: the asymptotic covariance between the
    sample mean and quantile is constant across all quantiles, if and
    only if the underlying distribution is normal. This is a powerful
    result and facilitates statistical inference. Utilizing this result,
    we develop a new omnibus test for normality based on the
    quantile-mean covariance process. Compared to existing normality
    tests, the proposed testing procedure has several important
    attractive features. Monte Carlo evidence shows that the proposed
    test possesses good finite sample properties. In addition to the
    formal test, we suggest a graphical procedure that is easy to
    implement and visualize in practice. Finally, we illustrate the use
    of the suggested techniques with an application to stock return
    datasets."
  accessed: 2026-01-14
  author:
  - literal: Bera, A. K., Galvao, A. F., Wang, L., & Xiao, Z.
  container-title: Econometric Theory
  id: adfd1cdd-be2e-33b1-bf94-693f4754181e
  issn: 02664666, 14694360
  issue: 5
  issued: 2016
  page: 1216-1252
  publisher: Cambridge University Press
  title: A New Characterisazion Of The Normal Distribution And Test For
    Normality
  type: article-journal
  url: "http://www.jstor.org/stable/43948011"
  volume: 32
- author:
  - literal: von Storch, H., & Zwiers, F. W.
  container-title: Statistical analysis in climate research
  doi: 10.1017/CBO9780511612336
  id: Storch_Zwiers_1999
  issued: 1999
  page: 419-420
  publisher: Cambridge University Press
  title: Normal density and cumulative distribution function
  type: chapter
- abstract: The Poisson distribution is a discontinuous distribution
    which was described by the French mathematician Siméon Denis Poisson
    (1781-2013;1840) in a book published in 1837. The Poisson
    distribution is a particular case of the binomial distribution
    (chapter 17) where the probability p becomes smaller and smaller (p
    `\textrightarrow`{=latex} 0) while the exponent k becomes larger and
    larger (k`\textrightarrow`{=latex}∞) in such a way that their
    product, the mean, $\mu$= kp, keeps a finite value (0 \< $\mu$ = kp
    \< ∞). The Poisson distribution might thus be defined by the
    following equation
  author:
  - literal: Jolicoeur, P.
  container-title: Introduction to biometry
  doi: 10.1007/978-1-4615-4777-8_19
  id: Jolicoeur1999
  isbn: 978-1-4615-4777-8
  issued: 1999
  page: 124-133
  publisher: Springer
  publisher-place: Boston, MA
  title: The poisson distribution
  type: chapter
  url: "https://doi.org/10.1007/978-1-4615-4777-8_19"
- author:
  - literal: Zhang, Y.
  container-title: Advances in Economics, Management and Political
    Sciences
  doi: 10.54254/2754-1169/2025.BJ24761
  id: Zhang2025
  issued: 2025
  title: Poisson distribution and its applications
  type: article-journal
  volume: 196
- abstract: The Poisson distribution is of great importance in theory
    and in practice. It has the added virtue of being a simple
    mathematical object. We could have introduced it at an earlier stage
    in the book, and the reader was alerted to this in
    `\textsection`{=latex}4.4. However, the belated entrance will give
    it more prominence, as well as a more thorough discussion than would
    be possible without the benefit of the last two chapters.
  author:
  - literal: Chung, K. L.
  container-title: Elementary probability theory with stochastic
    processes
  doi: 10.1007/978-1-4757-3973-2_7
  id: Chung1974
  isbn: 978-1-4757-3973-2
  issued: 1974
  page: 192-239
  publisher: Springer
  publisher-place: New York, NY
  title: Poisson and normal distributions
  type: chapter
  url: "https://doi.org/10.1007/978-1-4757-3973-2_7"
- abstract: "Social determinists have argued that the occurrence of
    independent discoveries and inventions demonstrates the
    inevitability of techno-scientific progress. Yet the frequency of
    such multiples may be adequately predicted by a probabilistic model,
    especially the Poisson model suggested by Price. A detailed inquiry
    reveals that the Poisson distribution can predict almost all the
    observed variation in the frequency distribution of multiples
    collected by Merton, and by Ogburn and Thomas. This study further
    indicates that: (a) the number of observed multiples may be greatly
    underestimated, particularly those involving few independent
    contributors; (b) discoveries and inventions are not sufficiently
    probable to avoid a large proportion of total failures, and hence
    techno-scientific advance is to a large measure indeterminate; (c)
    chance or 'luck' seems to play such a major part that the 'great
    genius' theory is no more tenable than the social deterministic
    theory."
  accessed: 2026-01-12
  author:
  - literal: Simonton, D. K.
  container-title: Social Studies of Science
  id: a2ab11c2-825b-3d03-aa88-542d1bf1629c
  issn: 03063127
  issue: 4
  issued: 1978
  page: 521-532
  publisher: Sage Publications, Ltd.
  title: "Independent discovery in science and technology: A closer look
    at the poisson distribution"
  title-short: Independent discovery in science and technology
  type: article-journal
  url: "http://www.jstor.org/stable/284821"
  volume: 8
- accessed: 2026-01-12
  author:
  - literal: Crow, E. L.
  container-title: Biometrika
  id: beaf2bb2-3f3e-3d37-837e-422ad120324f
  issn: 00063444, 14643510
  issue: 3/4
  issued: 1958
  page: 556-559
  publisher: \[Oxford University Press, Biometrika Trust\]
  title: The mean deviation of the poisson distribution
  type: article-journal
  url: "http://www.jstor.org/stable/2333201"
  volume: 45
- accessed: 2026-01-12
  author:
  - literal: Rao, C. R., & Chakravarti, I.M.
  container-title: Biometrics
  id: c5daa63c-82d0-3414-9df1-e64522b8f21e
  issn: 0006341X, 15410420
  issue: 3
  issued: 1956
  page: 264-282
  publisher: \[Wiley, International Biometric Society\]
  title: Some small sample tests of significance for a poisson
    distribution
  type: article-journal
  url: "http://www.jstor.org/stable/3001466"
  volume: 12
- author:
  - literal: Haight, F. A.
  collection-title: Operations research society of america. Publications
    in operations research
  id: haight1967handbook
  isbn: 9788391014424
  issued: 1967
  publisher: Wiley
  title: Handbook of the poisson distribution
  type: book
  url: "https://books.google.com/books?id=l8Y-AAAAIAAJ"
- author:
  - literal: Finkelshtein, D., Malyarenko, A., Mishura, Y., & Ralchenko,
      K.
  container-title: Methodology and Computing in Applied Probability
  doi: 10.1007/s11009-025-10171-9
  id: Finkelshtein2025
  issue: 2
  issued: 2025
  page: 45
  title: "Entropies of the poisson distribution as functions of
    intensity: \"Normal\" and \"anomalous\" behavior"
  title-short: Entropies of the poisson distribution as functions of
    intensity
  type: article-journal
  volume: 27
- author:
  - literal: Cohen, J.
  id: Cohen1977
  isbn: 978-0-12-179060-8
  issued: 1977
  publisher: Elsevier Academic Press
  publisher-place: Amsterdam
  title: Statistical power analysis for the behavioral science
  type: book
  url: "https://doi.org/10.1016/C2013-0-10517-X"
- author:
  - literal: Cohen, J.
  doi: 10.4324/9780203771587
  edition: 2
  id: Cohen1988
  issued: 1988
  publisher: Lawrence Erlbaum Associates
  publisher-place: Hillsdale, NJ
  title: Statistical power analysis for the behavioral science
  type: book
- author:
  - literal: Cohen, J.
  container-title: Psychological Bulletin
  id: Cohen1992
  issue: 1
  issued: 1992
  page: 155-159
  title: A power primer
  type: article-journal
  url: "https://doi.org/10.1037/0033-2909.112.1.155"
  volume: 112
- abstract: "Obwohl signifikante Ergebnisse oft gewünscht werden, sagt
    -- wie in diesem Kapitel aufgezeigt wird -- die bloße Signifikanz
    eines Tests nichts über die Stärke eines Effekts aus, und man kann
    sich berechtigt fragen: Bedeutet statistische Signifikanz auch immer
    ˝inhhaltliche Relevanz˝ bzw. ˝praktische Bedeutsamkeit˝? In diesem
    Kapitel werden diejenigen Konzepte eingeführt, die zur Beantwortung
    dieser Frage benötigt werden, und begonnen wird dabei mit einer
    systematischen Betrachtung statistischer Entscheidungen. Im
    Anschluss wird Cohen's d als Maß der Effektstärke für die bisher
    behandelten t-Tests betrachtet. Das Konzept der Effektstärke führt
    schließlich zur Power (Teststärke) eines Signifikanztests und der
    Frage nach dem optimalen Stichprobenumfang."
  author:
  - literal: Janczyk, M., & Pfister, R.
  container-title: "Inferenzstatistik verstehen: Von a wie
    signifikanztest bis z wie konfidenzintervall"
  doi: 10.1007/978-3-642-34825-9_7
  id: Janczyk2013
  isbn: 978-3-642-34825-9
  issued: 2013
  page: 77-90
  publisher: Springer
  publisher-place: Berlin, Heidelberg
  title: Fehlertypen, effektstärken und power
  type: chapter
  url: "https://doi.org/10.1007/978-3-642-34825-9_7"
- author:
  - literal: Brandmaier, A. M.
  container-title: PsyArXiv
  doi: 10.31234/osf.io/n9ta7_v1
  id: Brandmaier2025
  issued: 2025
  title: Stop calling cohen's d an effect size
  type: article-journal
- author:
  - literal: Fritz, C. O., Morris, P. E., & Richler, J. J.
  container-title: "Journal of Experimental Psychology: General"
  doi: 10.1037/a0024338
  id: Fritz2012
  issue: 1
  issued: 2012
  page: 2-18
  title: "Effect size estimates: Current use, calculations, and
    interpretation"
  title-short: Effect size estimates
  type: article-journal
  volume: 141
- abstract: "Effect sizes are the currency of psychological research.
    They quantify the results of a study to answer the research question
    and are used to calculate statistical power. The interpretation of
    effect sizes---when is an effect small, medium, or large?---has been
    guided by the recommendations Jacob Cohen gave in his pioneering
    writings starting in 1962: Either compare an effect with the effects
    found in past research or use certain conventional benchmarks. The
    present analysis shows that neither of these recommendations is
    currently applicable. From past publications without
    pre-registration, 900 effects were randomly drawn and compared with
    93 effects from publications with pre-registration, revealing a
    large difference: Effects from the former (median r = .36) were much
    larger than effects from the latter (median r = .16). That is,
    certain biases, such as publication bias or questionable research
    practices, have caused a dramatic inflation in published effects,
    making it difficult to compare an actual effect with the real
    population effects (as these are unknown). In addition, there were
    very large differences in the mean effects between psychological
    sub-disciplines and between different study designs, making it
    impossible to apply any global benchmarks. Many more pre-registered
    studies are needed in the future to derive a reliable picture of
    real population effects."
  author:
  - literal: Schäfer, T., & Schwarz, M. A.
  container-title: Frontiers in Psychology
  doi: 10.3389/fpsyg.2019.00813
  id: 10.3389/fpsyg.2019.00813
  issn: 1664-1078
  issued: 2019
  title: "The meaningfulness of effect sizes in psychological research:
    Differences between sub-disciplines and the impact of potential
    biases"
  title-short: The meaningfulness of effect sizes in psychological
    research
  type: article-journal
  url: "https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2019.00813"
  volume: Volume 10 - 2019
- abstract: Current statistical inference methods for task-fMRI suffer
    from two fundamental limitations. First, the focus is solely on
    detection of non-zero signal or signal change, a problem that is
    exacerbated for large scale studies (e.g. UK Biobank, N=40,000+)
    where the 'null hypothesis fallacy' causes even trivial effects to
    be determined as significant. Second, for any sample size, widely
    used cluster inference methods only indicate regions where a null
    hypothesis can be rejected, without providing any notion of spatial
    uncertainty about the activation. In this work, we address these
    issues by developing spatial Confidence Sets (CSs) on clusters found
    in thresholded Cohen's d effect size images. We produce an upper and
    lower CS to make confidence statements about brain regions where
    Cohen's d effect sizes have exceeded and fallen short of a non-zero
    threshold, respectively. The CSs convey information about the
    magnitude and reliability of effect sizes that is usually given
    separately in a t-statistic and effect estimate map. We expand the
    theory developed in our previous work on CSs for
  author:
  - literal: Bowring, A., Telschow, F. J. E., Schwartzman, A., &
      Nichols, T. E.
  container-title: NeuroImage
  doi: 10.1016/j.neuroimage.2020.117477
  id: BOWRING2021117477
  issn: 1053-8119
  issued: 2021
  keyword: Confidence sets, fMRI, Task fmri, Cohen's , Effect sizes
  page: 117477
  title: Confidence sets for cohen's d effect size images
  type: article-journal
  url: "https://www.sciencedirect.com/science/article/pii/S1053811920309629"
  volume: 226
- abstract: Objectives Meta-analyses typically compute a treatment
    effect size (Cohen's d), which is readily converted to another
    common measure, the binomial effect size display (BESD). BESD is the
    correlation coefficient and represents a percentage difference in
    outcome attributable to an intervention. Both d and BESD are in
    arbitrary units; neither measures the absolute change resulting from
    intervention. The method used to estimate absolute change from BESD
    assumes both a 50-50 split of the outcome and a balanced design.
    Consequently, inaccurate assumptions underpin most meta-analytic
    estimates of the gain resulting from an intervention (and of its
    cost effectiveness). This article develops an exact formula without
    these assumptions. Methods The formula is developed algebraically
    from 1) the formula for the correlation coefficient represented as a
    2-by-2 contingency table constructed from the relative size of the
    treatment and control groups and the percentage of people who would
    have the condition absent intervention, and 2) the BESD correlation
    coefficient formula showing change in success probability with
    treatment. Results Simulation reveals that BESD only approximates
    the reduction in the outcome an intervention might well achieve when
    the problem outcome occurs in 35 Conclusion It is time to retire
    BESD. Our equations can also guide effect size estimation from
    difficult articles.
  author:
  - literal: Miller, T. R., Hendrie, D., & Derzon, J.
  container-title: Value in Health
  doi: 10.1016/j.jval.2010.10.013
  id: MILLER2011144
  issn: 1098-3015
  issue: 1
  issued: 2011
  keyword: Absolute change, BESD, Effect size, Meta-analysis
  page: 144-151
  title: "Exact method for computing absolute percent change in a
    dichotomous outcome from meta-analytic effect size: Improving impact
    and cost-outcome estimates"
  title-short: Exact method for computing absolute percent change in a
    dichotomous outcome from meta-analytic effect size
  type: article-journal
  url: "https://www.sciencedirect.com/science/article/pii/S1098301510000148"
  volume: 14
- abstract: Given the long history of discussion of issues surrounding
    statistical testing and effect size indices and various attempts by
    the American Psychological Association and by the American
    Educational Research Association to encourage the reporting of
    effect size, most journals in education and psychology have
    witnessed an increase in effect size reporting since 1999. Yet,
    effect size was often reported in three indices, namely, the
    unadjusted R², Cohen's d, and η² with a simple labeling of small,
    medium, or large, according to Cohen's (1969) criteria. In this
    article, the authors present several alternatives to Cohen's d to
    help researchers conceptualize effect size beyond standardized mean
    differences for between-subject designs with two groups. The
    alternative effect size estimators are organized into a typology and
    are empirically contrasted with Cohen's d in terms of purposes,
    usages, statistical properties, interpretability, and the potential
    for meta-analysis. Several sound alternatives are identified to
    supplement the reporting of Cohen's d. The article concludes with a
    discussion of the choice of standardizers, the importance of
    assumptions, and the possibility of extending sound alternative
    effect size indices to other research contexts.
  accessed: 2026-01-14
  author:
  - literal: Peng, C.-Y. J., & Chen, L.-T.
  container-title: The Journal of Experimental Education
  id: abb9e70f-419e-3a38-8754-462a7041475a
  issn: 00220973, 19400683
  issue: 1
  issued: 2014
  page: 22-50
  publisher: Taylor & Francis, Ltd.
  title: "Beyond cohen's d: Alternative effect size measures for
    between-subject designs"
  title-short: Beyond cohen's d
  type: article-journal
  url: "https://www.jstor.org/stable/26594399"
  volume: 82
- abstract: Reporting effect size plays an integral role in educational
    and psychological research and is required by many journals.
    Certainly, the best-known measure of effect size is Cohen's d, which
    represents a substantial improvement over using p values. But
    Cohen's d is known to suffer from some fundamental concerns. The
    author's goal was to illustrate some graphical methods aimed at
    addressing those concerns. These methods can be applied in a wide
    range of situations, including situations in which the
    Wilcoxon-Mann-Whitney test is used.
  accessed: 2026-01-14
  author:
  - literal: Wilcox, R. R.
  container-title: The Journal of Experimental Education
  id: d04b907b-1c2b-329b-902f-ade87a9fd109
  issn: 00220973, 19400683
  issue: 4
  issued: 2006
  page: 353-367
  publisher: Taylor & Francis, Ltd.
  title: "Graphical methods for assessing effect size: Some alternatives
    to cohen's d"
  title-short: Graphical methods for assessing effect size
  type: article-journal
  url: "http://www.jstor.org/stable/20157436"
  volume: 74
- abstract: The size of the effect of the difference in two groups with
    respect to a variable of interest may be estimated by the classical
    Cohen's d. A recently proposed generalized estimator allows
    conditioning on further independent variables within the framework
    of a linear regression model. In this note, it is demonstrated how
    unbiased estimation of the effect size parameter together with a
    corresponding standard error may be obtained based on the
    non-central t distribution. The portrayed estimator may be
    considered as a natural generalization of the unbiased Hedges' g. In
    addition, confidence interval estimation for the unknown parameter
    is demonstrated by applying the so-called inversion confidence
    interval principle. The regarded properties collapse to already
    known ones in case of absence of any additional independent
    variables. The stated remarks are illustrated with a publicly
    available data set.
  author:
  - literal: Groß, J., & Möller, A.
  container-title: Statistical Papers
  doi: 10.1007/s00362-023-01527-9
  id: Groß2024
  issue: 6
  issued: 2024
  page: 3971-3979
  title: Some additional remarks on statistical properties of cohen's d
    in the presence of covariates
  type: article-journal
  volume: 65
- abstract: In this note, we introduce a generalized formula for Cohen's
    d under the presence of additional independent variables, providing
    a measure for the size of a possible effect concerning the size of a
    difference location effect of a variable in two groups. This is done
    by employing the so-called Frisch--Waugh--Lovell theorem in a
    partitioned linear regression model. The generalization is motivated
    by demonstrating the relationship to appropriate t and F statistics.
    Our discussion is further illustrated by inference about a publicly
    available data set.
  author:
  - literal: Groß, J., & Möller, A.
  container-title: Journal of Statistical Theory and Practice
  doi: 10.1007/s42519-023-00323-w
  id: Groß2023
  issue: 2
  issued: 2023
  page: 22
  title: A note on cohen's d from a partitioned linear regression model
  type: article-journal
  volume: 17
- abstract: "In psychological science, the \"new statistics\" refer to the
    new statistical practices that focus on effect size (ES) evaluation
    instead of conventional null-hypothesis significance testing
    (Cumming, Psychological Science, 25, 7--29, 2014). In a
    two-independent-samples scenario, Cohen's (1988) standardized mean
    difference (d) is the most popular ES, but its accuracy relies on
    two assumptions: normality and homogeneity of variances. Five other
    ESs---the unscaled robust d (dr\\*; Hogarty & Kromrey, 2001), scaled
    robust d (dr; Algina, Keselman, & Penfield, Psychological Methods,
    10, 317--328, 2005), point-biserial correlation (rpb; McGrath &
    Meyer, Psychological Methods, 11, 386--401, 2006), common-language
    ES (CL; Cliff, Psychological Bulletin, 114, 494--509, 1993), and
    nonparametric estimator for CL (Aw; Ruscio, Psychological Methods,
    13, 19--30, 2008)---may be robust to violations of these
    assumptions, but no study has systematically evaluated their
    performance. Thus, in this simulation study the performance of these
    six ESs was examined across five factors: data distribution, sample,
    base rate, variance ratio, and sample size. The results showed that
    Awand drwere generally robust to these violations, and Awslightly
    outperformed dr. Implications for the use of Awand drin real-world
    research are discussed."
  author:
  - literal: Li, J. C.-H.
  container-title: Behavior Research Methods
  doi: 10.3758/s13428-015-0667-z
  id: Li2016
  issue: 4
  issued: 2016
  page: 1560-1574
  title: Effect size measures in a two-independent-samples case with
    nonnormal and nonhomogeneous data
  type: article-journal
  volume: 48
- author:
  - literal: Efron, B.
  container-title: The Annals of Statistics
  doi: 10.1214/aos/1176344552
  id: Efron1979
  issue: 1
  issued: 1979
  page: 1-26
  publisher: Institute of Mathematical Statistics
  title: "[Bootstrap Methods: Another Look at the Jackknife]{.nocase}"
  type: article-journal
  url: "https://doi.org/10.1214/aos/117634455"
  volume: 7
- abstract: "We discuss several nonparametric methods for attaching a
    standard error to a point estimate: the jackknife, the bootstrap,
    half-sampling, subsampling, balanced repeated replications, the
    infinitesimal jackknife, influence function techniques and the delta
    method. The last three methods are shown to be identical. All the
    methods derive from the same basic idea, which is also the idea
    underlying the common parametric methods. Extended numerical
    comparisons are made for the special case of the correlation
    coefficient."
  author:
  - literal: Efron, B.
  container-title: Biometrika
  doi: 10.1093/biomet/68.3.589
  id: Efron1981
  issn: 0006-3444
  issue: 3
  issued: 1981-12
  page: 589-599
  title: "Nonparametric estimates of standard error: The jackknife, the
    bootstrap and other methods"
  title-short: Nonparametric estimates of standard error
  type: article-journal
  url: "https://doi.org/10.1093/biomet/68.3.589"
  volume: 68
- author:
  - literal: Efron, B.
  collection-title: CBMS-NSF regional conference series in applied
    mathematics, monograph 38
  doi: 10.1137/1.9781611970319
  id: Efron1982
  issued: 1982
  publisher: SIAM, Society for Industrial and Applied Mathematics
  publisher-place: Philadelphia
  title: The jackknife, the bootstrap and other resampling plans
  type: book
  url: "https://epubs.siam.org/doi/abs/10.1137/1.9781611970319"
- abstract: When testing hypotheses (or computing confidence intervals)
    with the one-sample Student's T method described in Chapter 5, the
    central limit theorem tells us that Student's T performs better as
    the sample size increases. That is, under random sampling the
    discrepancy between the nominal and actual Type I error probability
    will go to zero as the sample size goes to infinity. But
    unfortunately, for reasons outlined in Section 5.3 of Chapter 5,
    there are realistic situations where about two hundred observations
    are needed to get satisfactory control over the probability of a
    Type I error or accurate probability coverage when computing
    confidence intervals. When comparing the population means of two
    groups of individuals, using Student's T is known to be
    unsatisfactory when sample sizes are small or even moderately large.
    In fact, it might be unsatisfactory no matter how large the sample
    sizes are because under general conditions it does not converge to
    the correct answer (Cressie and Whitford, 1986). Switching to the
    test statistic W given by Equation 5.3, the central limit theorem
    now applies under general conditions, so using W means we will
    converge to the correct answer as the sample sizes increase, but in
    some cases we again need very large sample sizes to get accurate
    results. (There are simple methods for improving the performance of
    W using what are called estimated degrees of freedom, but the
    improvement remains highly unsatisfactory for a wide range of
    situations.) Consequently, there is interest in finding methods that
    beat our reliance on the central limit theorem as it applies to
    these techniques. That is, we would like to find a method that
    converges to the correct answer more quickly as the sample sizes get
    large, and such a method is described here.
  author:
  - literal: Wilcox, R. R.
  container-title: "Fundamentals of modern statistical methods:
    Substantially improving power and accuracy"
  doi: 10.1007/978-1-4757-3522-2_6
  id: Wilcox2001
  isbn: 978-1-4757-3522-2
  issued: 2001
  page: 93-115
  publisher: Springer
  publisher-place: New York, NY
  title: The bootstrap
  type: chapter
  url: "https://doi.org/10.1007/978-1-4757-3522-2_6"
- author:
  - literal: Politis, D. N.
  container-title: Statistical Science
  doi: 10.1214/ss/1063994977
  id: politis2003
  issue: 2
  issued: 2003
  page: 219-230
  title: The impact of bootstrap methods on time series analysis
  type: article-journal
  volume: 18
- abstract: In this chapter we introduce basic concepts and methods of
    statistical inference. The focus is on estimating the parameters of
    statistical distributions and testing hypotheses about them.
    Problems of testing if certain distributions fit observed data are
    also considered.
  author:
  - literal: Kenett, R., Zacks, S., & Gedeck, P.
  container-title: "Modern statistics: A computer-based approach with
    python"
  doi: 10.1007/978-3-031-07566-7_3
  id: Kenett2022
  isbn: 978-3-031-07566-7
  issued: 2022
  page: 139-223
  publisher: Springer International Publishing
  publisher-place: Cham
  title: Statistical inference and bootstrapping
  type: chapter
  url: "https://doi.org/10.1007/978-3-031-07566-7_3"
- abstract: "In this chapter, we will learn how to estimate the standard
    error of an estimate and how to construct confidence intervals for a
    parameter of interest. Both problems can be solved by the bootstrap
    method, which was inspired by the jackknife. The bootstrap,
    introduced in 1979 by Bradley Efron, is a general simulation-based
    method for measuring the uncertainty of estimates, in particular,
    for estimating their standard errors and constructing confidence
    intervals. Its beauty lies in its simplicity and universality: the
    bootstrap is fully automatic, requires no theoretical calculations,
    and is always available."
  author:
  - literal: Zuev, K. M.
  container-title: "Fundamentals of statistical inference: Foundations
    of data analysis"
  doi: 10.1007/978-3-032-03848-7_6
  id: Zuev2026
  isbn: 978-3-032-03848-7
  issued: 2026
  page: 115-129
  publisher: Springer Nature Switzerland
  publisher-place: Cham
  title: The bootstrap method
  type: chapter
  url: "https://doi.org/10.1007/978-3-032-03848-7_6"
- abstract: Typically, the traditional bootstrap methods for parameter
    inference of spatial error models suffer from high computational
    costs, so this study proposes fast cluster bootstrap methods for
    spatial error models to deal with the dilemma. The key idea is to
    calculate the sufficient statistics for each cluster before
    performing the bootstrap loop of the spatial error model, and based
    on these sufficient statistics, all quantities needed for bootstrap
    inference can be computed. Furthermore, this study performed Monte
    Carlo simulations, and the result reveals that compared with
    traditional bootstrap methods, our proposed methods can reduce the
    computational cost substantially and improve the reliability for
    obtaining the bootstrap test statistics and confidence intervals of
    the parameters for spatial error models.
  author:
  - literal: Zheng, Y., & Fan, H.
  container-title: Mathematics
  doi: 10.3390/math13182913
  id: math13182913
  issn: 2227-7390
  issue: 18
  issued: 2025
  title: Fast cluster bootstrap methods for spatial error models
  type: article-journal
  url: "https://www.mdpi.com/2227-7390/13/18/2913"
  volume: 13
- author:
  - literal: Eidous, O.
  container-title: ResearchGate
  doi: 10.13140/RG.2.2.12238.11846
  id: eidous2025
  issued: 2025-09
  title: Does the bootstrap method effectively evaluate estimators?
  type: article-journal
- author:
  - literal: Politis, D. N.
  container-title: IEEE Signal Processing Magazine
  doi: 10.1109/79.647042
  id: 647042
  issue: 1
  issued: 1998
  keyword: Statistical analysis;Sampling methods;Statistical
    distributions;Gaussian distribution;Shape;Density functional
    theory;Statistics
  page: 39-55
  title: Computer-intensive methods in statistical analysis
  type: article-journal
  volume: 15
- abstract: Sustainability is of essential interest for many
    organizations and is defined as the ability to maintain existing
    resources at a certain rate or level when encountered with barriers.
    Factors affecting sustainability are categorized as enablers
    (capacities) and barriers (challenges) that have positive and
    negative effects on sustainability, respectively. To evaluate the
    status of sustainability, organizations need a measurement method to
    account for all the aspects of the sustainability classified into
    social, economic, and environmental tiers. Previously many
    researchers have provided indexes and measure specific to the
    studied field, which is not applicable to other areas. Furthermore,
    the proposed methods fail to cover all the aspects of
    sustainability. This study investigates a statistical method to
    measure the sustainability and the application of the bootstrap
    re-sampling method in order to overcome the problem with normality
    assumption when the sample size is not large enough and thus develop
    a more realistic stochastic model. The Bootstrap re-sampling method
    enables the unbiased estimation of population parameters such as
    mean and standard deviation. The proposed method is evaluated by
    comparing its results with those found in the literature.
  author:
  - literal: Khosravi, F., Izbirak, G., & Shavarani, S. M.
  container-title: Socio-Economic Planning Sciences
  doi: 10.1016/j.seps.2020.100781
  id: KHOSRAVI2021100781
  issn: 0038-0121
  issued: 2021
  keyword: Sustainability, Bootstrap Re-Sampling, Statistical
    performance measurement, Enablers, Barriers
  note: Decision-Making for Environmental Sustainability
  page: 100781
  title: Application of bootstrap re-sampling method in statistical
    measurement of sustainability
  type: article-journal
  url: "https://www.sciencedirect.com/science/article/pii/S0038012119303416"
  volume: 75
- abstract: The bootstrap is a method for estimating the distribution of
    an estimator or test statistic by resampling one's data or a model
    estimated from the data. Under conditions that hold in a wide
    variety of econometric applications, the bootstrap provides
    approximations to distributions of statistics, coverage
    probabilities of confidence intervals, and rejection probabilities
    of hypothesis tests that are more accurate than the approximations
    of first-order asymptotic distribution theory. The reductions in the
    differences between true and nominal coverage or rejection
    probabilities can be very large. The bootstrap is a practical
    technique that is ready for use in applications. This chapter
    explains and illustrates the usefulness and limitations of the
    bootstrap in contexts of interest in econometrics. The chapter
    outlines the theory of the bootstrap, provides numerical
    illustrations of its performance, and gives simple instructions on
    how to implement the bootstrap in applications. The presentation is
    informal and expository. Its aim is to provide an intuitive
    understanding of how the bootstrap works and a feeling for its
    practical value in econometrics.
  author:
  - family: Horowitz
    given: Joel L.
  collection-title: Handbook of econometrics
  doi: 10.1016/S1573-4412(01)05005-X
  editor:
  - literal: Heckman, J. J., & Leamer, E.
  id: HOROWITZ20013159
  issn: 1573-4412
  issued: 2001
  keyword: "JEL classification:, C12, C13, C15"
  page: 3159-3228
  publisher: Elsevier
  title: Chapter 52 - the bootstrap
  type: chapter
  url: "https://www.sciencedirect.com/science/article/pii/S157344120105005X"
  volume: 5
- abstract: The contemporary development of bootstrap methods, from the
    time of Efron's early articles to the present day, is well
    documented and widely appreciated. Likewise, the relationship of
    bootstrap techniques to certain early work on permutation testing,
    the jackknife and cross-validation is well understood. Less known,
    however, are the connections of the bootstrap to research on survey
    sampling for spatial data in the first half of the last century or
    to work from the 1940s to the 1970s on subsampling and resampling.
    In a selective way, some of these early linkages will be explored,
    giving emphasis to developments with which the statistics community
    tends to be less familiar. Particular attention will be paid to the
    work of P. C. Mahalanobis, whose development in the 1930s and 1940s
    of moving-block sampling methods for spatial data has a range of
    interesting features, and to contributions of other scientists who,
    during the next 40 years, developed half-sampling, subsampling and
    resampling methods.
  accessed: 2026-01-14
  author:
  - literal: Hall, P.
  container-title: Statistical Science
  id: 5d7fe90b-50e5-3e2c-9890-dc7b7f71d323
  issn: 08834237
  issue: 2
  issued: 2003
  page: 158-167
  publisher: Institute of Mathematical Statistics
  title: A short prehistory of the bootstrap
  type: article-journal
  url: "http://www.jstor.org/stable/3182845"
  volume: 18
- abstract: The bootstrap provides a simple and powerful means of
    assessing the quality of estimators. However, in settings involving
    large data sets---which are increasingly prevalent---the calculation
    of bootstrap-based quantities can be prohibitively demanding
    computationally. Although variants such as subsampling and the m out
    of n bootstrap can be used in principle to reduce the cost of
    bootstrap computations, these methods are generally not robust to
    specification of tuning parameters (such as the number of subsampled
    data points), and they often require knowledge of the estimator's
    convergence rate, in contrast with the bootstrap. As an alternative,
    we introduce the 'bag of little bootstraps' (BLB), which is a new
    procedure which incorporates features of both the bootstrap and
    subsampling to yield a robust, computationally efficient means of
    assessing the quality of estimators. The BLB is well suited to
    modern parallel and distributed computing architectures and
    furthermore retains the generic applicability and statistical
    efficiency of the bootstrap. We demonstrate the BLB's favourable
    statistical performance via a theoretical analysis elucidating the
    procedure's properties, as well as a simulation study comparing the
    BLB with the bootstrap, the m out of n bootstrap and subsampling. In
    addition, we present results from a large-scale distributed
    implementation of the BLB demonstrating its computational
    superiority on massive data, a method for adaptively selecting the
    BLB's tuning parameters, an empirical study applying the BLB to
    several real data sets and an extension of the BLB to time series
    data.
  accessed: 2026-01-14
  author:
  - literal: Kleiner, A., Talwalkar, A., Sarkar, P., & Jordan, M. I.
  container-title: Journal of the Royal Statistical Society. Series B
    (Statistical Methodology)
  id: 71a9795f-441b-3377-aa30-ddc5824ffbf2
  issn: 13697412, 14679868
  issue: 4
  issued: 2014
  page: 795-816
  publisher: \[Royal Statistical Society, Wiley\]
  title: A scalable bootstrap for massive data
  type: article-journal
  url: "http://www.jstor.org/stable/24774569"
  volume: 76
- author:
  - literal: Pewsey, A.
  container-title: "Journal of the Royal Statistical Society Series D:
    The Statistician"
  doi: 10.2307/2348962
  id: 10.2307/2348962
  issn: 2515-7884
  issue: 1
  issued: 2018-12
  page: 215-216
  title: Exploring the limits of bootstrap
  type: article-journal
  url: "https://doi.org/10.2307/2348962"
  volume: 43
- abstract: Consistency of the bootstrap second moments does not usually
    follow from the proofs of consistency of the distribution of the
    bootstrap. Here it is shown that the convergence of the bootstrap
    distribution to a normal variate implicitly defines a consistent
    estimator for the asymptotic second moments. The estimator is based
    on the L-estimation of the scale parameter of arbitrary linear
    combinations of the bootstrap sequence and uses Classical Minimum
    Distance techniques to impose the positive semi-definiteness
    restrictions.
  accessed: 2026-01-14
  author:
  - literal: Machado, J. A. F., & Parente, P.
  container-title: The Econometrics Journal
  id: e841cec6-d2b9-36dd-bee3-92abf3c9e224
  issn: 13684221, 1368423X
  issue: 1
  issued: 2005
  page: 70-78
  publisher: \[Royal Economic Society, Wiley\]
  title: Bootstrap estimation of covariance matrices via the percentile
    method
  type: article-journal
  url: "http://www.jstor.org/stable/23114968"
  volume: 8
- abstract: We propose a unifying principle which identifies a very
    broad class of hypotheses and statistics for which a suitable
    application of the n out of n bootstrap yields asymptotically
    correct critical values and power for contiguous alternatives. We
    also show that this attractive principle can fail in situations
    which the m out of n bootstrap can deal with (Bickel, Götze and van
    Zwet, 1997) (BGvZ). We formalize the m out of n bootstrap theory for
    testing and show that under mild conditions, it provides correct
    significance level, asymptotic power under contiguous alternatives,
    and consistency. We conclude with simulation results supporting the
    asymptotics.
  accessed: 2026-01-14
  author:
  - literal: Bickel, P. J., & Ren, J.-J.
  container-title: Lecture Notes-Monograph Series
  id: ee45c30f-1813-36a2-b2a9-57ffa08fcc80
  issn: 07492170
  issued: 2001
  page: 91-112
  publisher: Institute of Mathematical Statistics
  title: The bootstrap in hypothesis testing
  type: article-journal
  url: "http://www.jstor.org/stable/4356107"
  volume: 36
- abstract: "We introduce the almost goodness-of-fit test, a procedure
    to assess whether a (parametric) model provides a good
    representation of the probability distribution generating the
    observed sample. Specifically, given a distribution function F and a
    parametric family
    $$\\mathcal {G}=\\{ G(\\varvec{\\theta }): \\varvec{\\theta } \\in \\Theta \\}$$,
    we consider the testing problem
    $$H_0: \\Vert F - G(\\varvec{\\theta }_F) \\Vert _p \\ge \\epsilon \\quad \\text {vs} \\quad H_1: \\Vert F - G(\\varvec{\\theta }_F) \\Vert _p < \\epsilon ,$$H0:‖F-G(θF)‖p≥ϵvsH1:‖F-G(θF)‖p\\<ϵ,where
    $$\\epsilon >0$$is a margin of error and
    $$G(\\varvec{\\theta }_F)$$denotes a representative of F within the
    parametric class. The approximate model is determined via an
    M-estimator of the parameters. The methodology also quantifies the
    percentage improvement of the proposed model relative to a
    non-informative (constant) benchmark. The test statistic is the
    $$\\textrm{L}^p$$-distance between the empirical distribution
    function and that of the estimated model. We present two consistent,
    easy-to-implement, and flexible bootstrap schemes to carry out the
    test. The performance of the proposal is illustrated through
    simulation studies and analysis and real-data applications."
  author:
  - literal: Baíllo, A., & Cárcamo, J.
  container-title: Statistics and Computing
  doi: 10.1007/s11222-025-10762-z
  id: Baíllo2025
  issue: 1
  issued: 2025
  page: 10
  title: Bootstrap tests for almost goodness-of-fit
  type: article-journal
  volume: 36
- abstract: Bootstrapping offers a flexible approach to estimating
    statistical power, when planning a new study based on a previous
    one. In this article, we explore both parametric and non-parametric
    bootstrap power calculations and demonstrate how to incorporate
    uncertainty about effect size in bootstrap power analysis. We use
    real examples to illustrate bootstrap power calculations in
    independent t-test and ANCOVA. Finally, we discuss the broader
    implications of bootstrap power calculation for a variety of
    research designs.
  author:
  - literal: Liu, X. S.
  container-title: Behaviormetrika
  doi: 10.1007/s41237-025-00283-4
  id: Liu2025
  issued: 2025
  title: "Bootstrap power calculation: A flexible alternative to
    conventional power analysis for prospective and replication studies"
  title-short: Bootstrap power calculation
  type: article-journal
- author:
  - literal: Grafakos, L.
  collection-title: Graduate texts in mathematics
  doi: 10.1007/978-3-031-56500-7
  edition: 1
  id: Grafakos2023
  issued: 2024
  publisher: Springer
  publisher-place: Cham
  title: Fundamentals of fourier analysis
  type: book
- author:
  - literal: Brigola, R.
  collection-title: Texts in applied mathematics
  doi: 10.1007/978-3-031-81311-5
  edition: 1
  id: Brigola2025
  issued: 2025
  publisher: Springer
  publisher-place: Cham
  title: Fourier analysis and distributions
  type: book
- author:
  - literal: Siuly, S., Li, Y., & Zhang, Y.
  collection-title: Health information science
  doi: 10.1007/978-3-319-47653-7
  edition: 1
  id: Siuly2017
  issued: 2017
  publisher: Springer
  publisher-place: Cham
  title: EEG signal analysis and classification
  type: book
- abstract: Electroencephalography (EEG) is a non-invasive measurement
    method for brain activity. Due to its safety, high resolution, and
    hypersensitivity to dynamic changes in brain neural signals, EEG has
    aroused much interest in scientific research and medical fields.
    This article reviews the types of EEG signals, multiple EEG signal
    analysis methods, and the application of relevant methods in the
    neuroscience field and for diagnosing neurological diseases. First,
    three types of EEG signals, including time-invariant EEG, accurate
    event-related EEG, and random event-related EEG, are introduced.
    Second, five main directions for the methods of EEG analysis,
    including power spectrum analysis, time--frequency analysis,
    connectivity analysis, source localization methods, and machine
    learning methods, are described in the main section, along with
    different sub-methods and effect evaluations for solving the same
    problem. Finally, the application scenarios of different EEG
    analysis methods are emphasized, and the advantages and
    disadvantages of similar methods are distinguished. This article is
    expected to assist researchers in selecting suitable EEG analysis
    methods based on their research objectives, provide references for
    subsequent research, and summarize current issues and prospects for
    the future.
  author:
  - literal: Zhang, H., Zhou, Q.-Q., Chen, H., Hu, X.-Q., Li, W.-G.,
      Bai, Y., Han, J.-X., Wang, Y., Liang, Z.-H., Chen, D., Cong,
      F.-Y., Yan, J.-Q., & Li, X.-L.
  container-title: Military Medical Research
  doi: 10.1186/s40779-023-00502-7
  id: Zhang2023
  issue: 1
  issued: 2023
  title: The applied principles of EEG analysis methods in neuroscience
    and clinical neurology
  type: article-journal
  volume: 10
- abstract: The use of mathematical models for electroencephalography
    (EEG) analysis has been going on for many years, and currently they
    are starting to find a place both in clinical practice and in
    parallel with other methods for evaluation of brain activity. The
    use and interpretation of these methods are not possible without
    knowledge of the basic mechanisms and processes that underlie the
    results obtained from their application. The advantages of the
    quantitative methods, the processes underlying their presentation,
    and the optimal parameters used, such as the number of electrodes
    and time intervals, have been evaluated. Attention has been paid to
    the advantages of the individual possibilities for EEG signal
    analysis---absolute and relative power as well as coherence. An
    analysis of these defined quantities provides an opportunity to
    enter into the intimate mechanisms underlying specific
    psychopathological phenomena.
  author:
  - literal: Panov, G.
  container-title: Computational neuroscience
  doi: 10.1007/978-1-0716-3230-7_5
  editor:
  - literal: Stoyanov, D., Draganski, B., Brambilla, P., & Lamm, C.
  id: Panov2023
  isbn: 978-1-0716-3230-7
  issued: 2023
  page: 85-91
  publisher: Springer US
  publisher-place: New York, NY
  title: "Quantitative EEG analysis: Introduction and basic principles"
  title-short: Quantitative EEG analysis
  type: chapter
  url: "https://doi.org/10.1007/978-1-0716-3230-7_5"
- abstract: Studies of hemisphere function involving the use of
    coherence analysis are reviewed. Despite the fact that many effects
    related to subject group and type of task have been reported, few
    seem to be reliable across studies. The assumptions which seem to
    underlie the use of coherence analysis are made explicit and
    discussed. Most investigators consider coherence levels to reflect
    certain 'baseline' patterns, possibly related to structural
    connectivity, upon which task and/or strategy effects may be
    superimposed. Use of a cephalic reference renders coherence effects
    virtually uninterpretable for a variety of reasons which are fully
    discussed.
  author:
  - literal: French, C. C, & Graham, J. B.
  container-title: International Journal of Psychophysiology
  doi: 10.1016/0167-8760(84)90044-8
  id: FRENCH1984241
  issn: 0167-8760
  issue: 3
  issued: 1984
  keyword: coherence---hemisphere function---psychopathology---task
    effects---sex---handedness---methodology
  page: 241-254
  title: A critical review of EEG coherence studies of hemisphere
    function
  type: article-journal
  url: "https://www.sciencedirect.com/science/article/pii/0167876084900448"
  volume: 1
- abstract: Human brain consists of millions of neurons which are
    playing an important role for controlling behavior of human body
    with respect to internal/external motor/sensory stimuli. These
    neurons will act as information carriers between human body and
    brain. Understanding cognitive behaviour of brain can be done by
    analyzing either signals or images from the brain. Human behaviour
    can be visualized in terms of motor and sensory states such as, eye
    movement, lip movement, remembrance, attention, hand clenching etc.
    These states are related with specific signal frequency which helps
    to understand functional behavior of complex brain structure.
    Electroencephalography (EEG) is an efficient modality which helps to
    acquire brain signals corresponds to various states from the scalp
    surface area. These signals are generally categorized as delta,
    theta, alpha, beta and gamma based on signal frequencies ranges from
    0.1Hz to more than 100Hz. This paper primarily focuses on EEG
    signals and its characterization with respect to various states of
    human body. It also deals with experimental setup used in EEG
    analysis.
  author:
  - literal: Kumar, J. S., & Bhuvaneswari, P.
  container-title: Procedia Engineering
  doi: 10.1016/j.proeng.2012.06.298
  id: KUMAR20122525
  issn: 1877-7058
  issued: 2012
  keyword: Electroencephalography, brain signal, modality, brain states
  note: INTERNATIONAL CONFERENCE ON MODELLING OPTIMIZATION AND COMPUTING
  page: 2525-2536
  title: Analysis of electroencephalography (EEG) signals and its
    categorization--a study
  type: article-journal
  url: "https://www.sciencedirect.com/science/article/pii/S1877705812022114"
  volume: 38
- author:
  - literal: Panitz, C., Ward, R. T., Pouliot, J., & Keil, A.
  collection-title: Cambridge handbooks in psychology
  container-title: "The cambridge handbook of research methods and
    statistics for the social and behavioral sciences: Volume 2:
    Performing research"
  doi: 10.1017/9781009000796.024
  editor:
  - literal: Edlund, J. E., & Nichols, A. L.
  id: Panitz_Ward_Pouliot_Keil_2024
  issued: 2024
  page: 519-544
  publisher: Cambridge University Press
  title: EEG and ERP
  type: chapter
- author:
  - literal: Guevara, M., Hernández-González, M., Sanz-Martin, A., &
      Amezcua, C.
  container-title: Journal of Biomedical Science and Engineering
  doi: 10.4236/jbise.2011.412096
  id: Guevara2011
  issued: 2011
  title: "EEGcorco: A computer program to simultaneously calculate and
    statistically analyze EEG coherence and correlation"
  title-short: EEGcorco
  type: article-journal
  volume: 4
- author:
  - literal: Chiarion, G., Sparacino, L., Antonacci, Y., Faes, L., &
      Mesin, L.
  container-title: Bioengineering (Basel, Switzerland)
  doi: 10.3390/bioengineering10030372
  id: Chiarion2023
  issue: 3
  issued: 2023
  title: "Connectivity analysis in EEG data: A tutorial review of the
    state of the art and emerging trends"
  title-short: Connectivity analysis in EEG data
  type: article-journal
  volume: 10
- author:
  - literal: Gerthsen, C.
  doi: 10.1007/978-3-662-30201-9
  edition: 9
  editor:
  - literal: Kneser, H. O.
  id: Gerthsen1966
  issued: 1966
  publisher: Springer
  publisher-place: Berlin, Heidelberg
  title: "Physik: Ein lehrbuch zum gebrauch neben vorlesungen"
  title-short: Physik
  type: book
- author:
  - literal: Meschede, D., ed., Feld, L., Gross, R., Müller, R.,
      Niedner-Schatteburg, G., Schäfer, G., Sokolowski, M., Vewinger,
      F., Reinhard F., Werner, R. F., & Zohm, H.
  doi: 10.1007/978-3-662-30201-9
  edition: 26
  id: Gerthsen2026
  issued: 2026
  publisher: Springer Spektrum
  publisher-place: Berlin, Heidelberg
  title: Gerthsen physik
  type: book
- abstract: We review research on the neural efficiency hypothesis of
    intelligence, stating that brighter individuals display lower (more
    efficient) brain activation while performing cognitive tasks
    \[Haier, R.J., Siegel, B.V., Nuechterlein, K.H., Hazlett, E., Wu,
    J.C., Paek, J., Browning, H.L., Buchsbaum, M.S., 1988. Cortical
    glucose metabolic rate correlates of abstract reasoning and
    attention studied with positron emission tomography. Intelligence
    12, 199--217\]. While most early studies confirmed this hypothesis
    later research has revealed contradictory evidence or has identified
    some moderating variables like sex, task type, task complexity or
    brain area. Neuroscientific training studies suggest that neural
    efficiency also seems to be a function of the amount and quality of
    learning. From integrating this evidence we conclude that neural
    efficiency might arise when individuals are confronted with tasks of
    (subjectively) low to moderate task difficulty and it is mainly
    observable for frontal brain areas. This is true for easier novel
    cognitive tasks or after sufficient practice allowing participants
    to develop appropriate (efficient) strategies to deal with the task.
    In very complex tasks more able individuals seem to invest more
    cortical resources resulting in positive correlations between brain
    usage and cognitive ability. Based on the reviewed evidence we
    propose future empirical approaches in this field.
  author:
  - literal: Neubauer, A. C., & Fink, A
  container-title: Neuroscience & Biobehavioral Reviews
  doi: 10.1016/j.neubiorev.2009.04.001
  id: NEUBAUER20091004
  issn: 0149-7634
  issue: 7
  issued: 2009
  keyword: Intelligence, Neural efficiency, Training, Task complexity,
    Neuroscience
  page: 1004-1023
  title: Intelligence and neural efficiency
  type: article-journal
  url: "https://www.sciencedirect.com/science/article/pii/S0149763409000591"
  volume: 33
- abstract: "In studying physiological correlates of human intelligence,
    new brain imaging techniques like positron emission tomography (PET)
    and electroencephalography (EEG) mapping methods focus on the level
    and topographical distribution of cortical activation. Actually,
    there is strong empirical evidence that more intelligent individuals
    display a more focused cortical activation during cognitive
    performance resulting in lower total brain activation than in less
    intelligent individuals (i.e., neural efficiency hypothesis). Former
    studies have used only single, homogeneous tasks and most of the
    studies have been performed using males. Therefore, here the
    influence of different task content and of sex on the relationship
    between intelligence and cortical activation has been tested. In a
    sample of 26 males and 25 females, we administered verbal,
    numerical, and figural versions of a well-known elementary cognitive
    task, the so-called Posner task. Our results suggest a comparatively
    low cortical activation in brighter as compared to less intelligent
    individuals but this expected neural efficiency pattern interacted
    with sex and task content: In the verbal Posner task, the females
    were more likely to produce cortical activation patterns in line
    with the neural efficiency hypothesis, whereas in the figural task,
    primarily the males displayed the expected inverse relationship
    between IQ and cortical activation."
  author:
  - literal: Neubauer, A. C., Fink, A., & Schrausser, D. G.
  container-title: Intelligence
  doi: 10.1016/S0160-2896(02)00091-0
  id: NEUBAUER2002515
  issn: 0160-2896
  issue: 6
  issued: 2002
  keyword: Intelligence, EEG sex, Elementary cognitive task, Task
    specificity
  page: 515-536
  title: "Intelligence and neural efficiency: The influence of task
    content and sex on the brain--IQ relationship"
  title-short: Intelligence and neural efficiency
  type: article-journal
  url: "https://www.sciencedirect.com/science/article/pii/S0160289602000910"
  volume: 30
- abstract: Previous studies demonstrated that intelligence is
    significantly related to an impressive array of psychological,
    social, biological and genetic factors and that working memory (WM)
    can be considered as a general cognitive resource strongly related
    with a wide variety of higher order cognitive competencies and
    intelligence. Also, evaluating the WM of subjects might allow one to
    test the neural efficiency hypothesis (NEH). WM typically involves
    functional interactions between frontal and parietal cortices. We
    recorded EEG signals to study neuronal interactions during one WM
    test in individuals who had few years of formal education (LE) as
    compared to individuals with university degrees (UE). The two groups
    of individuals differed in the scores they obtained in psychological
    tests. To quantify the synchronization between EEG channels in
    several frequency bands, we evaluated the "synchronization
    likelihood" (SL), which takes into consideration nonlinear processes
    as well as linear ones. SL was then converted into graphs to
    estimate the distance from "small-world network" (SWN) organization,
    i.e., an optimally organized network that would give rise to the
    data. In comparison to LE subjects, those with university degrees
    exhibited less prominent SWN properties in most frequency bands
    during the WM task. This finding supports the NEH and suggests that
    the connections between brain areas of well-educated subjects
    engaged in WM tasks are not as well-organized in the sense of SWN.
  author:
  - literal: Micheloyannis, S., Pachou, E., Stam, C. J., Vourkas, M.,
      Erimaki, S., & Tsirka, V.
  container-title: Neuroscience Letters
  doi: 10.1016/j.neulet.2006.04.006
  id: MICHELOYANNIS2006273
  issn: 0304-3940
  issue: 3
  issued: 2006
  keyword: Neural efficiency, Graph theory, Small-world network,
    Synchronization likelihood, Working memory
  page: 273-277
  title: Using graph theoretical analysis of multi channel EEG to
    evaluate the neural efficiency hypothesis
  type: article-journal
  url: "https://www.sciencedirect.com/science/article/pii/S030439400600382X"
  volume: 402
- abstract: "In the field of physiological study of human intelligence,
    strong evidence of a more efficient operation (i.e., less
    activation) of the brain in brighter individuals (the neural
    efficiency hypothesis) can be found. Most studies in this field have
    used single, homogeneous tasks and have not examined sex
    differences. In analyzing the extent of Event-related
    Desynchronization (ERD) in the EEG during the performance of a
    verbal and a visuo-spatial task, we recently found that males and
    females display neural efficiency primarily in the domain where they
    usually perform better (i.e., verbal in females and spatial in
    males; cf. A.C. Neubauer, A. Fink, D.G. Schrausser, Intelligence and
    neural efficiency: the influence of task content and sex on
    brain--IQ relationship. Intelligence, 30 (2002) 515--536). However,
    this interpretation was complicated by differences in the complexity
    of the two tasks. By using a verbal (semantic) and a spatial
    (rotation) task of comparable complexity in this research, we sought
    to replicate and extend our earlier findings by additionally
    considering the individual differences in intelligence structure and
    the topographical distribution over the cortex. Findings were
    similar to the previous study: Females (n = 35) display neural
    efficiency (i.e., less brain activation in brighter individuals)
    primarily during the verbal task, males (n = 31) in the spatial
    task. However, the strength of this brain activation--IQ
    relationship varies with the intelligence factor: In males, the
    highest correlations were observed for spatial IQ, in females for
    verbal IQ. Furthermore, the sexes displayed topographical
    differences of neural efficiency patterns."
  author:
  - literal: Neubauer, A. C., Grabner, R. H., Fink, A., & Neuper, C.
  container-title: Cognitive Brain Research
  doi: 10.1016/j.cogbrainres.2005.05.011
  id: NEUBAUER2005217
  issn: 0926-6410
  issue: 1
  issued: 2005
  keyword: EEG, ERD, Neural efficiency, Sex difference, Task content,
    Verbal IQ, Visuo-spatial IQ, Topographical difference
  page: 217-225
  title: "Intelligence and neural efficiency: Further evidence of the
    influence of task content and sex on the brain--IQ relationship"
  title-short: Intelligence and neural efficiency
  type: article-journal
  url: "https://www.sciencedirect.com/science/article/pii/S092664100500162X"
  volume: 25
- author:
  - literal: Schrausser, D. G., Fink, A., & Neubauer, A. C.
  container-title: 10th biennial meeting of the international society
    for the study of individual differences (ISSID)
  doi: 10.5281/zenodo.13738772
  id: schrausser_2001_13738772
  issued: 2001
  publisher: The University of Edinburgh
  publisher-place: Edinburgh, UK
  title: Intelligence and neural efficiency as determined by
    EEG-coherence
  type: paper-conference
- author:
  - literal: Meyberg, K., & Vachenauer, P.
  doi: 10.1007/978-3-642-56654-7_4
  id: Meyberg2001
  isbn: 978-3-642-56654-7
  issued: 2001
  publisher: Springer
  publisher-place: Berlin, Heidelberg
  title: "Höhere mathematik 1: Differential- und integralrechnung
    vektor- und matrizenrechnung"
  title-short: Höhere mathematik 1
  type: book
  url: "https://doi.org/10.1007/978-3-642-56654-7"
- abstract: "Mit der Integration löst man das Umkehrproblem, aus der
    Ableitung f' die ursprüngliche Funktion f zu rekonstruieren. Die
    wesentliche, zur Lösung führende Idee stammt aus dem Mittelwertsatz
    der Differentialrechnung (`\\textrightarrow`{=latex} Kap. 3,
    `\\textsection`{=latex}2): Zu jeder Zerlegung a = x0 \\< x1 \\< \\... \\<
    xn−1 \\< xn= x des Intervalls \\[a, x\\], auf dem f differenzierbar
    ist, gibt es Zwischenpunkte $\\xi$ ∈ \\[xi−1, xi\\], so daß
    gilt\\$\\$f\\\\left( {{x\\_i}} \\\\right) - f\\\\left( {{x\\_{i - 1}}}
    \\\\right) = f'\\\\left( {{\\\\xi \\_i}} \\\\right)\\\\left( {{x\\_i} - {x\\_{i -
    1}}} \\\\right)\\\\left( {i = 1,2, \\\\ldots ,n} \\\\right).\\$\\$"
  author:
  - literal: Meyberg, K., & Vachenauer, P.
  container-title: "Höhere mathematik 1: Differential- und
    integralrechnung vektor- und matrizenrechnung"
  doi: 10.1007/978-3-642-56654-7_4
  id: Meyberg2001int
  isbn: 978-3-642-56654-7
  issued: 2001
  page: 161-211
  publisher: Springer
  publisher-place: Berlin, Heidelberg
  title: Integration
  type: chapter
  url: "https://doi.org/10.1007/978-3-642-56654-7_4"
- abstract: This note contains some results obtained while ruminating
    about Riemann sums. We know that nothing here is truly new, but we
    know of no other place in which these ideas are presented in the way
    that they occurred to us. In particular, some of them are so
    elementary that we hope they will find their way into calculus
    texts.
  author:
  - literal: Guillemin, V. W., & Stroock, D. W.
  container-title: "Representations, wavelets, and frames: A celebration
    of the mathematical work of lawrence w. baggett"
  doi: 10.1007/978-0-8176-4683-7_1
  editor:
  - literal: Jorgensen, P. E. T., Merrill, K. D., & Packer, J. A.
  id: Guillemin2008
  isbn: 978-0-8176-4683-7
  issued: 2008
  page: 3-12
  publisher: Birkhäuser
  publisher-place: Boston, MA
  title: Some riemann sums are better than others
  type: chapter
  url: "https://doi.org/10.1007/978-0-8176-4683-7_1"
- abstract: "Simple integrability of a function f (defined by Haber and
    Shisha in \\[2\\]) is shown to be equivalent to the convergence of the
    infinite Riemann sum \\<m:math display='block'\\>\\<m:mrow\\>\\<m:mstyle
    displaystyle='true'\\>\\<m:munderover\\>\\<m:mo\\>&\\#x2211;\\</m:mo\\>\\<m:mrow\\>\\<m:mi\\>k\\</m:mi\\>\\<m:mo\\>=\\</m:mo\\>\\<m:mn\\>1\\</m:mn\\>\\</m:mrow\\>\\<m:mi\\>&\\#x221E;\\</m:mi\\>\\</m:munderover\\>\\<m:mrow\\>\\<m:mi\\>f\\</m:mi\\>\\<m:mrow\\>\\<m:mo\\>(\\</m:mo\\>\\<m:mrow\\>\\<m:msub\\>\\<m:mi\\>&\\#x03BE;\\</m:mi\\>\\<m:mi\\>k\\</m:mi\\>\\</m:msub\\>\\</m:mrow\\>\\<m:mo\\>)\\</m:mo\\>\\</m:mrow\\>\\<m:mrow\\>\\<m:mo\\>(\\</m:mo\\>\\<m:mrow\\>\\<m:msub\\>\\<m:mi\\>x\\</m:mi\\>\\<m:mi\\>k\\</m:mi\\>\\</m:msub\\>\\<m:mo\\>&\\#x2212;\\</m:mo\\>\\<m:msub\\>\\<m:mi\\>x\\</m:mi\\>\\<m:mrow\\>\\<m:mi\\>k\\</m:mi\\>\\<m:mo\\>&\\#x2212;\\</m:mo\\>\\<m:mn\\>1\\</m:mn\\>\\</m:mrow\\>\\</m:msub\\>\\</m:mrow\\>\\<m:mo\\>)\\</m:mo\\>\\</m:mrow\\>\\</m:mrow\\>\\</m:mstyle\\>\\</m:mrow\\>\\</m:math\\>\\$\\$\\\\sum\\\\limits\\_{k
    = 1}\\^\\\\infty {f\\\\left( {{\\\\xi \\_k}} \\\\right)\\\\left( {{x\\_k} -
    {x\\_{k - 1}}} \\\\right)} \\$\\$to the improper Riemann integral
    \\<m:math display='block'\\>\\<m:mrow\\>\\<m:mstyle
    displaystyle='true'\\>\\<m:mrow\\>\\<m:msubsup\\>\\<m:mo\\>&\\#x222B;\\</m:mo\\>\\<m:mn\\>0\\</m:mn\\>\\<m:mi\\>&\\#x221E;\\</m:mi\\>\\</m:msubsup\\>\\<m:mi\\>f\\</m:mi\\>\\</m:mrow\\>\\</m:mstyle\\>\\</m:mrow\\>\\</m:math\\>\\$\\$\\\\int\\_0\\^\\\\infty
    f \\$\\$f as the gauge of the partition \\<m:math
    display='block'\\>\\<m:mrow\\>\\<m:msubsup\\>\\<m:mrow\\>\\<m:mrow\\>\\<m:mo\\>(\\</m:mo\\>\\<m:mrow\\>\\<m:msub\\>\\<m:mi\\>x\\</m:mi\\>\\<m:mi\\>k\\</m:mi\\>\\</m:msub\\>\\</m:mrow\\>\\<m:mo\\>)\\</m:mo\\>\\</m:mrow\\>\\</m:mrow\\>\\<m:mrow\\>\\<m:mi\\>k\\</m:mi\\>\\<m:mo\\>=\\</m:mo\\>\\<m:mn\\>0\\</m:mn\\>\\</m:mrow\\>\\<m:mi\\>&\\#x221E;\\</m:mi\\>\\</m:msubsup\\>\\</m:mrow\\>\\</m:math\\>\\$\\$\\\\left(
    {{x\\_k}} \\\\right)\\_{k = 0}\\^\\\\infty \\$\\$of \\[0,∞)converges to O. An
    analogous result is obtained for dominant integrability (defined by
    Osgood and Shisha in \\[5\\]). Also certain results of Bromwich and
    Hardy \\[1\\] are recovered."
  author:
  - literal: Lewis, J. T., Osgood, C. F., & Shisha, O.
  container-title: "General inequalities 1 / allgemeine ungleichungen 1:
    Proceedings of the first international conference on general
    inequalities held in the mathematical research institute at
    oberwolfach, black forest, may 10--14, 1976 / abhandlung zur ersten
    internationalen tagung [ü]{.nocase}ber allgemeine ungleichungen im
    mathematischen forschungsinstitut oberwolfach, schwarzwald vom 10.
    Bis 14. Mai 1976"
  doi: 10.1007/978-3-0348-5563-1_25
  editor:
  - literal: Beckenbach, E. F.
  id: Lewis1978
  isbn: 978-3-0348-5563-1
  issued: 1978
  page: 233-242
  publisher: Birkhäuser
  publisher-place: Basel
  title: Infinite riemann sums, the simple integral, and the dominated
    integral
  type: chapter
  url: "https://doi.org/10.1007/978-3-0348-5563-1_25"
- abstract: In diesem Kapitel beschäftigen wir uns mit stochastischen
    Riemann-Integralen, d. h. mit gewöhnlichen Riemann-Integralen mit
    einem stochastischen Prozess als Integrand1. Mathematisch sind diese
    Gebilde relativ wenig anspruchsvoll, sie ließen sich pfadweise wie
    in der konventionellen (deterministischen) Analysis über stetige
    Funktionen definieren. Diese pfadweise Definition wird aber z. B.
    bei Ito-Integralen im übernächsten Kapitel nicht mehr möglich sein.
    Daher schlagen wir hier den auch später nützlichen Weg ein,
    Integrale als Grenzwert (im quadratischen Mittel) zu definieren. Ist
    der stochastische Integrand speziell ein Wiener-Prozess, so folgt
    das Riemann-Integral einer Normalverteilung mit Erwartungswert Null
    und bekannter Formel für die Varianz. Eine Reihe von Beispielen soll
    die Einführung erleichtern.
  author:
  - literal: Hassler, U.
  container-title: "[Stochastische Integration und
    Zeitreihenmodellierung: Eine Einführung mit Anwendungen aus
    Finanzierung und Ökonometrie]{.nocase}"
  doi: 10.1007/978-3-540-73568-7_7
  id: Hassler2007
  isbn: 978-3-540-73568-7
  issued: 2007
  page: 137-153
  publisher: Springer
  publisher-place: Berlin, Heidelberg
  title: Riemann-integrale
  type: chapter
  url: "https://doi.org/10.1007/978-3-540-73568-7_7"
- author:
  - literal: Torchinsky, A.
  collection-title: Lecture notes in mathematics
  doi: 10.1007/978-3-031-11799-2
  edition: 1
  id: Torchinsky2022
  issued: 2022
  publisher: Springer
  publisher-place: Cham
  title: A modern view of the riemann integral
  type: book
- abstract: Die Integration ist neben der Differentiation die wichtigste
    Anwendung des Grenzwertbegriffs in der Analysis. Wir definieren das
    Integral zunächst für Treppenfunktionen, wobei noch keine
    Grenzwertbetrachtungen nötig sind und der elementargeometrische
    Flächeninhalt von Rechtecken zugrundeliegt. Das Integral
    allgemeinerer Funktionen wird dann durch Approximation mittels
    Treppenfunktionen definiert. Mithilfe sog. Riemannscher Summen
    berechnen wir explizit die Integrale einiger elementarer Funktionen.
  author:
  - literal: Forster, O., & Lindemann, F.
  container-title: "[Analysis 1: Differential- und Integralrechnung
    einer Veränderlichen]{.nocase}"
  doi: 10.1007/978-3-658-40130-6_18
  id: Forster2023
  isbn: 978-3-658-40130-6
  issued: 2023
  page: 283-302
  publisher: Springer Fachmedien
  publisher-place: Wiesbaden
  title: Das riemannsche integral
  type: chapter
  url: "https://doi.org/10.1007/978-3-658-40130-6_18"
- abstract: In diesem Kapitel wollen wir nach der Differenzial- auch die
    Integralrechnung auf eine mathematisch präzisere Grundlage stellen,
    sodass wir im nächsten Kapitel -- gewissermaßen als Höhepunkt
    unserer Theorieentwicklung -- den Hauptsatz, der Differenzial- und
    Integralrechnung miteinander verbindet (vgl. 3.3), ebenso präzise
    formulieren und beweisen können.
  author:
  - literal: Büchter, A., & Henn, H.-W.
  container-title: "Elementare analysis: Von der anschauung zur theorie"
  doi: 10.1007/978-3-8274-2680-2_6
  id: Büchter2010
  isbn: 978-3-8274-2680-2
  issued: 2010
  page: 221-235
  publisher: Spektrum Akademischer Verlag
  publisher-place: Heidelberg
  title: "Grenzwerte von riemann'schen summen: Das integral"
  title-short: Grenzwerte von riemann'schen summen
  type: chapter
  url: "https://doi.org/10.1007/978-3-8274-2680-2_6"
- abstract: "It is well known that Riemann sums converge toward the
    integral of any Riemannintegrable function f on the segment \\[a,
    b\\]. In some cases this property is still valid for generalized
    integrals and can be useful to solve problems involving series and
    sums. In this note we prove (Theorem 3) that the result still holds
    for a generalized integral under the assumption that the function is
    decreasing on the interval. We give two counterexamples: the first
    one with a linear piecewise function, and a second one based on an
    integral suggested by Hardy. The last section shows recent
    applications of the Riemann sums in computer science and applied
    mathematics."
  accessed: 2026-01-12
  author:
  - literal: Truc, J.-P.
  container-title: The College Mathematics Journal
  id: e941eb5c-b072-3fd7-a80c-cfa5c7173324
  issn: 07468342, 19311346
  issue: 2
  issued: 2019
  page: pp. 123-132
  publisher: \[Mathematical Association of America, Taylor & Francis,
    Ltd.\]
  title: Riemann sums for generalized integrals
  type: article-journal
  url: "https://www.jstor.org/stable/48662056"
  volume: 50
- accessed: 2026-01-12
  author:
  - literal: Goel, S. K., & Rodriguez, D. M.
  container-title: Mathematics Magazine
  id: fbd8e02f-8560-36a2-a00c-e74f040810fc
  issn: 0025570X, 19300980
  issue: 4
  issued: 1987
  page: 225-228
  publisher: \[Mathematical Association of America, Taylor & Francis,
    Ltd.\]
  title: A note on evaluating limits using riemann sums
  type: article-journal
  url: "http://www.jstor.org/stable/2689344"
  volume: 60
- abstract: Die bei Programm 22 verwendete Romberg-Extrapolation läßt
    sich auch auf die numerische Integration anwenden.
  author:
  - literal: Herrmann, D.
  container-title: Numerische mathematik --- 40 BASIC-programme
  doi: 10.1007/978-3-322-96321-5_27
  id: Herrmann1983
  isbn: 978-3-322-96321-5
  issued: 1983
  page: 84-86
  publisher: Vieweg+Teubner Verlag
  publisher-place: Wiesbaden
  title: Romberg-integration
  type: chapter
  url: "https://doi.org/10.1007/978-3-322-96321-5_27"
- abstract: "Let (Xt) be the solution of a stochastic differential
    system. We consider the following situations: computation of Eƒ(Xt)
    by a Monte-Carlo method (for example, computation of moments of the
    solution); integration of ƒ(·) with respect to the invariant
    probability law of (Xt) (when this process is ergodic); or of the
    upper Lyapunov exponent, by simulating a single trajectory. We
    propose to perform an extrapolation between approximate values due
    to first-order schemes; we show that this algorithm (simpler to
    implement than second-order schemes) provides a second-order
    accuracy, and we give results of numerical tests."
  author:
  - literal: Talay, D., & Tubaro, L.
  container-title: Structural Safety
  doi: 10.1016/0167-4730(90)90036-O
  id: TALAY1990143
  issn: 0167-4730
  issue: 1
  issued: 1990
  keyword: Monte Carlo method, numerical analysis, probability
    distribution, random process, simulation
  page: 143-150
  title: Romberg extrapolations for numerical schemes solving stochastic
    differential equations
  type: article-journal
  url: "https://www.sciencedirect.com/science/article/pii/016747309090036O"
  volume: 8
- abstract: Summary Elementary techniques for computing a definite
    integral use the fundamental theorem of calculus. This chapter
    discusses more sophisticated techniques that yield accurate
    approximations with less computational effort. It surveys two
    methods for enhancing the accuracy of composite quadrature formulas.
    The first method, Romberg quadrature, uses approximations to the
    integral that have low-order accuracy to compute high-order
    approximations. The second approach, adaptive quadrature,
    encompasses a class of strategies for tailoring composite formulas
    to local, idiosyncratic behavior in the integrand. The chapter also
    explores the theory of Gauss quadrature. In doing so, it generalizes
    the framework based on the Legendre polynomials, to include other
    Gauss quadrature methods based on different orthogonal systems of
    polynomials. In each case, there is a specific interval of
    integration associated with the basic quadrature method. However,
    each method readily extends to more general intervals via the
    change-of-variables tactic.
  author:
  - literal: Allen, M. B., & Isaacson, E. L
  chapter-number: 7
  container-title: Numerical analysis for applied science
  doi: 10.1002/9781119245476.ch7
  id: "doi:https://doi.org/10.1002/9781119245476.ch7"
  isbn: 9781119245476
  issued: 2019
  keyword: adaptive quadrature, Gauss quadrature, Legendre polynomials,
    numerical integration, Romberg quadrature
  page: 363-401
  publisher: John Wiley & Sons, Ltd
  title: Numerical integration
  type: chapter
  url: "https://onlinelibrary.wiley.com/doi/abs/10.1002/9781119245476.ch7"
- accessed: 2026-01-11
  author:
  - literal: von Petersdorff, T.
  container-title: The American Mathematical Monthly
  id: 30c28040-c164-336f-b877-2f793977628d
  issn: 00029890, 19300972
  issue: 8
  issued: 1993
  page: 783-785
  publisher: \[Taylor & Francis, Ltd., Mathematical Association of
    America\]
  title: A short proof for romberg integration
  type: article-journal
  url: "http://www.jstor.org/stable/2324787"
  volume: 100
- abstract: Subject to rather mild assumptions on the integrand, the
    Romberg table (theT-table) and the modified Romberg table
    (theU-table) yield asymptotically upper and lower bounds for the
    value of the integral, and the convergence of the columns of the two
    tables is asymptotically monotone. This is verified for arbitrary
    sequences of step sizes satisfying the usual condition of
    convergence for Romberg integration.
  author:
  - literal: Jetter, K.
  container-title: Numerische Mathematik
  doi: 10.1007/BF01389471
  id: Jetter1984
  issue: 2
  issued: 1984
  title: Ein kurze anmerkung zur romberg-integration
  type: article-journal
  volume: 45
- abstract: Simulation methods \[particularly Efron's (1979) bootstrap\]
    are being applied more and more frequently in statistical inference.
    Given data (X1, \..., Xn) distributed according to P, which belongs
    to a hypothesized model P, the basic goal is to estimate the
    distribution LP of a function Tn(X1, \..., Xn, P). The bootstrap
    presupposes the existence of an estimate P̂(X1, \..., Xn) and
    involves estimating Lp by the distribution L\*n of Tn(X\*1, \...,
    X\*n, P̂), where (X\*1, \..., X\*n) is distributed according to P̂.
    The method is of particular interest when L\*n, though known in
    principle, can realistically only be computed by simulation. Such
    computation can be expensive if n is large and Tn is complex (e.g.,
    see the multivariate goodness-of-fit tests of Beran and Millar
    1986). Even when bootstrap application to a single data set is not
    excessively expensive, Monte Carlo studies of the bootstrap are
    another matter. We propose a method based on the classical ideas of
    Richardson extrapolation for reducing the computational cost
    inherent in bootstrap simulations and Monte Carlo studies of the
    bootstrap, by performing simulations for statistics based on two
    smaller sample sizes. We study theoretically which ratio of the two
    small sample sizes is apt to give best results. We show how our
    method works for approximating the χ2, t, and smoothed binomial
    distributions, and for setting bootstrap percentile confidence
    intervals for the variance of a normal distribution with a mean of
    0.
  accessed: 2026-01-11
  author:
  - literal: Bickel, P. J., & Yahav, J. A.
  container-title: Journal of the American Statistical Association
  id: cc7b552a-2f22-3972-bf87-40a114018835
  issn: 01621459, 1537274X
  issue: 402
  issued: 1988
  page: 387-393
  publisher: \[American Statistical Association, Taylor & Francis,
    Ltd.\]
  title: Richardson extrapolation and the bootstrap
  type: article-journal
  url: "http://www.jstor.org/stable/2288854"
  volume: 83
- author:
  - literal: Sidi, A.
  collection-title: Cambridge monographs on applied and computational
    mathematics
  container-title: "Practical extrapolation methods: Theory and
    applications"
  doi: 10.1017/CBO9780511546815
  id: Sidi_2003
  issued: 2003
  page: 19-20
  publisher: Cambridge University Press
  title: The richardson extrapolation process and its generalizations
  type: chapter
- abstract: "Richardson extrapolation is a classical technique from
    numerical analysis that can improve the approximation error of an
    estimation method by combining linearly several estimates obtained
    from different values of one of its hyperparameters without the need
    to know in details the inner structure of the original estimation
    method. The main goal of this paper is to study when Richardson
    extrapolation can be used within data science beyond the existing
    applications to step-size adaptations in stochastic gradient
    descent. We identify two situations where Richardson interpolation
    can be useful: (1) when the hyperparameter is the number of
    iterations of an existing iterative optimization algorithm with
    applications to averaged gradient descent and Frank--Wolfe
    algorithms (where we obtain asymptotically rates of \\$O(1/k\\^2)\\$ on
    polytopes, where \\$k\\$ is the number of iterations) and (2) when it
    is a regularization parameter with applications to Nesterov
    smoothing techniques for minimizing nonsmooth functions (where we
    obtain asymptotically rates close to \\$O(1/k\\^2)\\$ for nonsmooth
    functions) and kernel ridge regression. In all these cases, we show
    that extrapolation techniques come with no significant loss in
    performance but with sometimes strong gains, and we provide
    theoretical justifications based on asymptotic developments for such
    gains, as well as empirical illustrations on classical problems from
    machine learning."
  author:
  - literal: Bach, F.
  container-title: SIAM Journal on Mathematics of Data Science
  doi: 10.1137/21M1397349
  id: "doi:10.1137/21M1397349"
  issue: 4
  issued: 2021
  page: 1251-1277
  title: On the effectiveness of richardson extrapolation in data
    science
  type: article-journal
  volume: 3
- abstract: Richardson's extrapolation process is a well known method to
    improve the order of several approximation processes. Here we
    observe that for numerical differentiation, Richardson's process can
    be applied not only to improve the order of a numerical
    differentiation formula but also to find in fact the original
    formula.
  author:
  - literal: Dubeau, F.
  container-title: "Journal of Computational Physics: X"
  doi: 10.1016/j.jcpx.2019.100017
  id: DUBEAU2019100017
  issn: 2590-0552
  issued: 2019
  keyword: Numerical differentiation, Richardson's extrapolation process
  page: 100017
  title: A remark on richardson's extrapolation process and numerical
    differentiation formulae
  type: article-journal
  url: "https://www.sciencedirect.com/science/article/pii/S2590055219300332"
  volume: 2
- abstract: The application of extrapolation (or convergence
    acceleration) methods to the solution of problems in numerical
    analysis has become very widespread in recent years. One important
    area in which extrapolation methods have proved to be remarkably
    efficient is that of numerical integration. Of the methods that have
    proved to be useful in this area, the Richardson extrapolation
    process and some of its generalizations have been the subject of
    intense research. It is the purpose of this paper to survey briefly
    the recent developments relating to the generalizations of the
    Richardson extrapolation process with special emphasis on their
    application to the numerical evaluation of finite and infinite range
    integrals.
  author:
  - literal: Sidi, A.
  container-title: "Numerical integration III: Proceedings of the
    conference held at the mathematisches forschungsinstitut,
    oberwolfach, nov. 8 -- 14, 1987"
  doi: 10.1007/978-3-0348-6398-8_22
  editor:
  - literal: Brass, H., & Hämmerlin, G.
  id: Sidi1988
  isbn: 978-3-0348-6398-8
  issued: 1988
  page: 237-250
  publisher: Birkhäuser
  publisher-place: Basel
  title: Generalizations of richardson extrapolation with applications
    to numerical integration
  type: chapter
  url: "https://doi.org/10.1007/978-3-0348-6398-8_22"
- abstract: In a recent paper by H. Blum, Lin Q., and the author,\[l\],
    it has been shown that the Ritz projection method with linear finite
    elements admits an asymptotic error expansion for certain classes of
    "uniform" meshes. This provides the theoretical justification for
    the use of Richardson extrapolation or related correction processes
    for increasing the accuracy of the scheme. The proofs are entirely
    based on finite element techniques and extend to situations where no
    "discrete" maximum principle is available. This is examplarily
    demonstrated here for the second-order Lamé-Navier system in plain
    linear elasticity and for a mixed formulation of the fourth-order
    Kirchhoff plate bending model.
  author:
  - literal: Rannacher, R.
  container-title: "Numerical techniques in continuum mechanics:
    Proceedings of the second GAMM-seminar, kiel, january 17 to 19,
    1986"
  doi: 10.1007/978-3-322-85997-6_9
  editor:
  - literal: Hackbusch, W., & Witsch, K.
  id: Rannacher1987
  isbn: 978-3-322-85997-6
  issued: 1987
  page: 90-101
  publisher: Vieweg+Teubner Verlag
  publisher-place: Wiesbaden
  title: Richardson extrapolation with finite elements
  type: chapter
  url: "https://doi.org/10.1007/978-3-322-85997-6_9"
- abstract: Manche Anwendungsprobleme lassen sich auf die Berechnung
    eines bestimmten Integrals zurückführen. Ist keine Stammfunktion des
    Integranden bekannt, muss die Integrationsaufgabe näherungsweise
    gelöst werden. Verschiedene geeignete Verfahren werden vorgestellt
    und analysiert.
  author:
  - literal: Neher, M.
  container-title: "[Numerische Mathematik: Eine anschauliche modulare
    Einführung]{.nocase}"
  doi: 10.1007/978-3-662-68815-1_7
  id: Neher2024
  isbn: 978-3-662-68815-1
  issued: 2024
  page: 195-222
  publisher: Springer
  publisher-place: Berlin, Heidelberg
  title: Numerische integration
  type: chapter
  url: "https://doi.org/10.1007/978-3-662-68815-1_7"
- abstract: Manche Probleme der angewandten Mathematik führen auf die
    Berechnung von Integralen, die meistens nicht in expliziter Form
    dargestellt werden können. Die numerische Integralberechnung, die
    man kurz als Quadratur bezeichnet, spielt deshalb eine wichtige
    Rolle. Wir befassen uns im folgenden mit der genäherten Berechnung
    von bestimmten Integralen. Unbestimmte Integrale (Stammfunktionen)
    werden zweckmäßig als Anfangswertprobleme gewöhnlicher
    Differentialgleichungen behandelt (vgl. Kapitel 9). Von den
    zahlreichen Anwendungen der numerischen Quadratur nennen wir die
    Berechnung von Oberflächen, Volumina, Wahrscheinlichkeiten und
    Wirkungsquerschnitten, die Auswertung von Integraltransformationen
    und Integralen im Komplexen, die Konstruktion von konformen
    Abbildungen für Polygonbereiche nach der Formel von
    Schwarz-Christoffel \[Hen 85\], die Behandlung von
    Integralgleichungen etwa im Zusammenhang mit der Randelementmethode
    und schließlich die Methode der finiten Elemente \[Scw91\].
  author:
  - literal: Schwarz, H. R.
  container-title: Numerische mathematik
  doi: 10.1007/978-3-663-01227-6_8
  id: Schwarz1997
  isbn: 978-3-663-01227-6
  issued: 1997
  page: 375-411
  publisher: Vieweg+Teubner Verlag
  publisher-place: Wiesbaden
  title: Integralberechnung
  type: chapter
  url: "https://doi.org/10.1007/978-3-663-01227-6_8"
- abstract: Numerical Methods have attracted of research community for
    solving engineering problems. This interest is due to its
    practicality and the improvement of highspeed calculations done on
    current century processors. The increase in numerical method tools
    in engineering software, such as Matlab, is an example of the
    increased interest. In this paper, we are present a new improved
    numerical integration method, that is based on the well-known
    trapezoidal rule. The proposed method gives a great enhancement to
    the trapezoidal rule and overcomes the issue of the error value when
    dealing with some higher order functions even when solving for a
    single interval. After literature review, the proposed system is
    mathematically explained along with error analysis. Few examples are
    illustrated to prove improved accuracy of the proposed method over
    traditional trapezoidal method.
  author:
  - literal: Abdulhameed, A. F., & Memon, Q. A.
  container-title: "Journal of Physics: Conference Series"
  doi: 10.1088/1742-6596/2090/1/012104
  id: Abdulhameed_2021
  issue: 1
  issued: 2021-11
  page: 012104
  publisher: IOP Publishing
  title: An improved trapezoidal rule for numerical integration
  type: article-journal
  url: "https://doi.org/10.1088/1742-6596/2090/1/012104"
  volume: 2090
- abstract: We present new higher-order quadratures for a family of
    boundary integral operators re-derived using the approach introduced
    in Kublik et al. (2013) \[7\]. In this formulation, a boundary
    integral over a smooth, closed hypersurface is transformed into an
    equivalent volume integral defined in a sufficiently thin tubular
    neighborhood of the surface. The volumetric formulation makes it
    possible to use the simple trapezoidal rule on uniform Cartesian
    grids and relieves the need to use parameterization for developing
    quadrature. Consequently, typical point singularities in a layer
    potential extend along the surface's normal lines. We propose new
    higher-order corrections to the trapezoidal rule on the grid nodes
    around the singularities. This correction is based on local
    decompositions of the singularity and is dependent on the angle of
    approach to the singularity relative to the surface's principal
    curvature directions. The proposed decomposition, combined with the
    volumetric formulation, leads to a special quadrature error
    cancellation.
  author:
  - literal: Izzo, F., Runborg, O., & Tsai, R.
  container-title: Journal of Computational Physics
  doi: 10.1016/j.jcp.2022.111193
  id: IZZO2022111193
  issn: 0021-9991
  issued: 2022
  keyword: Level set methods, Closest point projection, Boundary
    integral formulations, Singular integrals, Trapezoidal rules
  page: 111193
  title: Corrected trapezoidal rules for singular implicit boundary
    integrals
  type: article-journal
  url: "https://www.sciencedirect.com/science/article/pii/S0021999122002558"
  volume: 461
- abstract: Publisher Summary This chapter discusses the trapezoidal
    rule integration formulas. The development of numerical integration
    formulas as such is not in the mainstream of the mathematical topics
    covered in the chapter. The modified trapezoidal rule uses
    functional values at points which lie midway between those points
    that apply for the trapezoidal rule. There is a certain class of
    transcendental functions defined by integrals which can be computed
    to high accuracy by use of these rules; with a view toward the
    applications, the chapter takes up this aspect of the subject.
    Algorithms for the evaluation of definite integrals by means of
    equally spaced data are closely related to the Euler-Maclaurin
    summation formula for which there is a vast literature. Comparison
    of the two formulations shows that the difference in accuracy is
    negligible.
  collection-title: Mathematics in science and engineering
  container-title: The special functions and their approximations
  doi: 10.1016/S0076-5392(09)60075-8
  editor:
  - literal: Luke, Y. L.
  id: luke1969214
  issn: 0076-5392
  issued: 1969
  page: 214-226
  publisher: Elsevier
  title: Chapter XV trapezoidal rule integration formulas
  type: chapter
  url: "https://www.sciencedirect.com/science/article/pii/S0076539209600758"
  volume: 53
- abstract: There are many numerical integration methods that exist with
    its own advantage and disadvantage. This study focusses on the
    Trapezoidal rule, TR. The advantage of the Trapezoidal rule is that
    it is simple to use and can be applied to a wide range of functions.
    Since the Trapezoidal rule is an approximation rule, it will yield
    an error. In this study, we aim to reduce the error of the
    Trapezoidal rule can be reduced by applying mean averaging toward
    Trapezoidal rule called as Trapezoidal rule with mean averaging,
    TRMEAN. The arithmetic mean, geometric mean, Harmonic mean, Heronian
    mean, Contra harmonic, Root-mean-square mean, and Centroidal mean
    will be implemented. Hence, we will be experimented as examples
    before concluding the results. The results of this study showed that
    the error from TRMEAN is smaller as compared to TR. The findings
    indicate that TRMEAN presents a promising improvement in accuracy
    and reliability for this task over the original TR method. However,
    further research and validation are essential to firmly establish
    these conclusions and assess their applicability to diverse datasets
    and situations.
  author:
  - literal: Bujang, N., Nasir, M. A. S., & Ijam, H. M.
  container-title: AIP Conference Proceedings
  doi: 10.1063/5.0294833
  id: Bujang10.1063/5.0294833
  issn: 0094-243X
  issue: 1
  issued: 2025-12
  page: 040010
  title: Numerical integration of function using the modified
    trapezoidal rule and mean averaging method
  type: article-journal
  url: "https://doi.org/10.1063/5.0294833"
  volume: 3338
- author:
  - literal: Jarre, F.
  container-title: arXiv
  doi: 10.48550/arXiv.2507.05083
  id: jarre2025cubicsplinefunctionsrevisited
  issued: 2025
  title: Cubic spline functions revisited
  type: article-journal
  url: "https://arxiv.org/abs/2507.05083"
- abstract: In this paper a fourth order asymptotically optimal error
    bound for a new cubic interpolating spline function, denoted by
    Q-spline, is derived for the case that only function values at given
    points are used but not any derivative information. The bound seems
    to be stronger than earlier error bounds for cubic spline
    interpolation in such setting such as the not-a-knot spline. A brief
    analysis of the conditioning of the end conditions of cubic spline
    interpolation leads to a modification of the not-a-knot spline, and
    some numerical examples suggest that the interpolation error of this
    revised not-a-knot spline generally is comparable to the near
    optimal Q-spline and lower than for the not-a-knot spline when the
    mesh size is small.
  author:
  - literal: Jarre, F.
  container-title: Journal of Computational and Applied Mathematics
  doi: 10.1016/j.cam.2025.117240
  id: JARRE2026117240
  issn: 0377-0427
  issued: 2026
  keyword: Cubic spline, Natural spline, Error estimate, Condition
    number
  page: 117240
  title: Cubic spline functions revisited
  type: article-journal
  url: "https://www.sciencedirect.com/science/article/pii/S037704272500754X"
  volume: 478
- abstract: This chapter reiterates the subject of the previous chapter.
    Instead of a rational cubic model, a polynomial cubic spline has
    been presented here for the same objective. A piecewise cubic spline
    has been introduced to preserve the shape of the data when it is
    convex, monotone or positive. The spline representation is
    interpolatory and applicable to the scalar valued data. The shape
    parameters, in the description of the cubic, have been constrained
    in such a way that they control the shape of the curve to avoid any
    noise. As far as visual smoothness is concerned, the curve scheme
    under discussion is GC1. Thus the continuity constraints have been
    relaxed from C1 to GC1.
  author:
  - literal: Sarfraz, M.
  container-title: "Interactive curve modeling: With applications to
    computer graphics, vision and image processing"
  doi: 10.1007/978-1-84628-871-5_8
  id: Sarfraz2008
  isbn: 978-1-84628-871-5
  issued: 2008
  page: 157-172
  publisher: Springer London
  publisher-place: London
  title: Visualization of shaped data by cubic spline interpolation
  type: chapter
  url: "https://doi.org/10.1007/978-1-84628-871-5_8"
- abstract: In this article, the issues of digital processing and
    restoration of electroencephalogram (EEG) signals from biomedical
    signals are considered, the location of 21 sensors in the EEG
    apparatus along the brain, the naming of the sensors, their
    connection types, the use of bipolar coupling in the detection of
    disease symptoms, interpolation of received signals, disease
    symptoms. The processes of separating parts into scales have been
    studied. During the work, the B-spline function was selected as the
    most convenient mathematical model for digital processing of EEG
    signals, and the construction of the B-spline function was
    presented. Based on the constructed mathematical model, an algorithm
    for restoring the electroencephalogram signals by dividing the
    problematic parts into scales was developed, and the absolute error
    in the restoration of EEG signals was estimated.
  author:
  - literal: Abduganiev, M., Azimov, R., & Muydinov, L.
  container-title: Intelligent human computer interaction
  doi: 10.1007/978-3-031-27199-1_3
  editor:
  - literal: Zaynidinov, H., Singh, M., Tiwary, U. S., & Singh, D.
  id: abd10.1007/978-3-031-27199-1_3
  isbn: 978-3-031-27199-1
  issued: 2023
  page: 18-26
  publisher: Springer Nature Switzerland
  publisher-place: Cham
  title: Digital processing algorithms of biomedical signals using cubic
    base splines
  type: paper-conference
- abstract: "In diesem Kapitel werden wir uns mit dem populärsten
    Kurvenschema befassen: C2-stetige kubische interpolierende Splines.
    Wir haben schon gesehen, daß Lagrange-Interpolation keine
    brauchbaren Resultate liefert. Wir haben aber andererseits gesehen,
    daß uns durch kubische B-Spline-Kurven ein mächtiges Werkzeug zum
    Modellieren an die Hand gegeben wurde; sie können auf einfache Weise
    komplexe Formen wiedergeben. Diese „Wiedergabe\" geschieht als
    Approximationsprozeß, man verändert das Kontrollpolygon solange, bis
    die gewünschte Form gefunden ist. Wir werden sehen, wie man kubische
    Splines auch zur Interpolation benutzen kann, nämlich, eine
    Splinekurve zu finden, die durch einen gegebenen Satz von Punkten
    verläuft. Kubische Spline-Interpolation ist in die CAGD-Literatur
    von J. Ferguson \\[184\\] im Jahre 1964 eingeführt worden, während die
    zugrundeliegende Mathematik in der Approximationstheorie (siehe de
    Boor \\[112\\] oder Holladay \\[266\\]) entwickelt wurde. Eine Übersicht
    über die Geschichte der Splines ist bei Schumaker \\[426\\] zu
    finden."
  author:
  - literal: Farin, G.
  container-title: "Kurven und flächen im computer aided geometric
    design: Eine praktische einführung"
  doi: 10.1007/978-3-663-10602-9_9
  id: Farin1994
  isbn: 978-3-663-10602-9
  issued: 1994
  page: 104-121
  publisher: Vieweg+Teubner Verlag
  publisher-place: Wiesbaden
  title: Kubische spline-interpolation
  type: chapter
  url: "https://doi.org/10.1007/978-3-663-10602-9_9"
- abstract: "Spline interpolation is an improvement over piecewise ---
    polynomial interpolation. It uses less information of the given
    function, yet furnishes smoother interpolates. The plan of this
    chapter is as follows: In Section6.2 we shall define the spline
    space Sm,$\\tau$($\\Delta$), and for a given function x (t) the spline
    and Lidstone --- spline interpolates Sm,$\\tau$$\\Delta$and
    LSm,2m−2$\\Delta$x(t),respectively. Here, we shall also show that to
    acquire the bounds for `\\textbardbl`{=latex} Dk(x−
    Sm,$\\tau$$\\Delta$) `\\textbardbl`{=latex}∞ and `\\textbardbl`{=latex}
    Dk(x− LSm,2m−2$\\Delta$x) `\\textbardbl`{=latex}∞ in terms of the
    derivatives of x(t) it is necessary to estimate several terms. While
    some of these terms can be estimated by the results of Chapter 5,
    other terms which require a different analysis for each m and
    $\\tau$, need to be bounded. In Sections6.3,6.4 and 6.6 respectively,
    we shall consider the cases m = 2, $\\tau$ = 2; m = 3, $\\tau$ = 4 and
    m = 3, $\\tau$ = 3. These cases correspond to cubic in the class C(2)
    \\[a, b\\], and quintic in the classes C(4)\\[a, b\\] and C(3)\\[a, b\\]
    spline interpolates. For the cases m = 3, $\\tau$ = 4 and m = 3,
    $\\tau$ = 3 in Sections 6.5 and 6.7 respectively, we shall discuss
    the construction of approximated quintic splines, and for these
    interpolates we will provide explicit error bounds in L∞ --- norm.
    For the cubic and quintic Lidstone --- spline interpolates error
    bounds in L∞ --- norm are obtained in Sections 6.8 and 6.9,
    respectively. In Section6.10 we shall extend Theorems 5.3.16 and
    5.3.17 for the spline interpolate Sm,$\\tau$$\\Delta$x(t)"
  author:
  - literal: Agarwal, R. P., & Wong, P. J. Y.
  container-title: Error inequalities in polynomial interpolation and
    their applications
  doi: 10.1007/978-94-011-2026-5_6
  id: Agarwal1993
  isbn: 978-94-011-2026-5
  issued: 1993
  page: 281-362
  publisher: Springer Netherlands
  publisher-place: Dordrecht
  title: Spline interpolation
  type: chapter
  url: "https://doi.org/10.1007/978-94-011-2026-5_6"
- abstract: An algorithm for the construction of a cubic spline curve
    with relatively good shape that interpolates specified data points
    at some knots and passes through specified regions at some other
    knots is presented. The curve constructed by the algorithm has
    minimum energy on each of its components. This algorithm has
    applications in various fields, such as the reconstruction of
    natural phenomena where data points cannot be sampled exactly, or
    computer-aided modeling where some of the fitting points cannot be
    explicitly specified.
  author:
  - literal: Cheng, F., & Barsky, B. A.
  container-title: Computer-Aided Design
  doi: 10.1016/0010-4485(91)90023-P
  id: CHENG1991700
  issn: 0010-4485
  issue: 10
  issued: 1991
  keyword: splines, interpolation, uncertain data
  page: 700-706
  title: "Interproximation: Interpolation and approximation using cubic
    spline curves"
  title-short: Interproximation
  type: article-journal
  url: "https://www.sciencedirect.com/science/article/pii/001044859190023P"
  volume: 23
- abstract: Evoked potentials and EEGs record punctuate electrical
    activity at electrode sites. To represent the overall potential
    distribution on the entire scalp it is necessary to interpolate
    between these sampled values. Surface splines are mathematical tools
    for interpolating functions of two variables. In comparison to the
    classical methods of interpolation, based on linear combination of
    the potentials of the 4 nearest electrodes, spline methods are
    smoother, give more precisely located extrema and converge faster
    toward the 'true' potential surface when the number of recording
    electrodes is increased. These advantages are at the expense of
    lengthier computation time. Résumé Les potentiels évoqués comme
    l'électroencéphalographie n'enregistrent l'activité électrique du
    scalp qu'en des points précis correspondant à l'emplacement des
    électrodes. Pour avoir une représentation globale de la distribution
    du potentiel sur le scalp, il est nécessaire d'interpoler entre ces
    points de mesure. Les surfaces splines permettent d'effectuer de
    telles interpolations bi-dimensionnelles. Par comparaison avec la
    méthode d'interpolation couramment utilisée basée sur la combinaison
    linéaire des potentiels des 4 plus proches électrodes la méthode des
    splines donne des surfaces plus régulières, les extrêmes sont mieux
    localisés et quand on augmente le nombre d'électrodes, les surfaces
    obtenues convergent plus rapidement vers la 'vraie' surface. En
    contrepartie le calcul de ces fonctions est plus long.
  author:
  - literal: Perrin, F., Pernier, J., Bertnard, O., Giard M. H., &
      Echallier, J. F.
  container-title: Electroencephalography and Clinical Neurophysiology
  doi: 10.1016/0013-4694(87)90141-6
  id: PERRIN198775
  issn: 0013-4694
  issue: 1
  issued: 1987
  keyword: interpolation, spline
  page: 75-81
  title: Mapping of scalp potentials by surface spline interpolation
  type: article-journal
  url: "https://www.sciencedirect.com/science/article/pii/0013469487901416"
  volume: 66
- abstract: This paper is a review of the main interpolation methods
    applicable to 3-dimensional EEG mapping. The use of simple
    statistical comparison methods on recorded EEG maps allowed us to
    evaluate the qualities of interpolation methods belonging to 3
    mathematical families (barycentric, polynomial, spline). A
    combination of a 3-dimensional representation of EEG maps and a
    reliable interpolation method makes it possible to obtain better
    spatial resolution than with standard planar mapping.
  author:
  - literal: Soufflet, L., Toussaint, M., Luthringer, R., Gresser, J.,
      Minot, R., & Macher, J. P.
  container-title: Electroencephalography and Clinical Neurophysiology
  doi: 10.1016/0013-4694(91)90204-H
  id: SOUFFLET1991393
  issn: 0013-4694
  issue: 5
  issued: 1991
  keyword: EEG, 3D interpolation, Image synthesis
  page: 393-402
  title: A statistical evaluation of the main interpolation methods
    applied to 3-dimensional EEG mapping
  type: article-journal
  url: "https://www.sciencedirect.com/science/article/pii/001346949190204H"
  volume: 79
- author:
  - literal: Jiang, H., & Zhao, Y.
  container-title: 2009 sixth international conference on fuzzy systems
    and knowledge discovery
  doi: 10.1109/FSKD.2009.591
  id: 5360654
  issued: 2009
  keyword: Interpolation;Spline;Isosurfaces;Boundary conditions;Software
    algorithms;Convergence;Hardware;Costs;Biomedical image
    processing;Rendering (computer graphics);Cubic
    spline;MC;interpolation
  page: 80-83
  title: The study of interpolation algorithm based on cubic spline in
    marching cubes method
  type: paper-conference
  volume: 5
- abstract: We express the interpolating cubic splines of class C2 in
    their new, explicit forms. We construct the desired forms, the
    spline's Hermitian and B-spline representations for both equidistant
    and arbitrary nodes. During this process we demonstrate an
    innovative way to compute the inverse of a special class of
    tridiagonal matrices. Afterward, we propose the corresponding
    interpolating spline based linear regression models with easily
    interpretable coefficients suitable for smoothing data of complex
    structures.
  author:
  - literal: Török, C., Hudák, J., Pristaš, V., & Antoni, L.
  container-title: Applied Mathematics and Computation
  doi: 10.1016/j.amc.2025.129411
  id: TOROK2025129411
  issn: 0096-3003
  issued: 2025
  keyword: Data smoothing, Cubic splines, Interpolation, Linear
    regression
  page: 129411
  title: Explicit forms of interpolating cubic splines and data
    smoothing
  type: article-journal
  url: "https://www.sciencedirect.com/science/article/pii/S0096300325001389"
  volume: 500
- abstract: An algorithm for computing the cubic spline interpolation
    coefficients without solving the matrix equation involved is
    presented in this paper. It requires only O(n) multiplication or
    division operations for computing the inverse of the matrix compared
    to O(n2) or larger number of operations in the Gauss elimination
    method.
  author:
  - literal: Moon, B. S.
  container-title: Applied Mathematics and Computation
  doi: 10.1016/S0096-3003(99)00178-2
  id: MOON2001251
  issn: 0096-3003
  issue: 2
  issued: 2001
  keyword: Explicit solution, Cubic spline interpolation, B-splines,
    Inverse matrix
  page: 251-255
  title: An explicit solution for the cubic spline interpolation for
    functions of a single variable
  type: article-journal
  url: "https://www.sciencedirect.com/science/article/pii/S0096300399001782"
  volume: 117
- abstract: Traditional end conditions for cubic spline interpolation
    consist of values, the first or the second derivatives of
    interpolated functions on the boundary interpolation knots. The
    not-a-knot end condition proposed by de Boor (1985) is a kind of end
    condition of cubic spline interpolation for the practical
    application without the requirements of the derivatives at the end
    knots. However, a significant disadvantage of such end condition is
    that there is a sharp decrease in the accuracy of the interpolation
    at boundary intervals. In this paper, by changing the locations of
    two spline knots in not-a-knot end condition, we propose the optimal
    arrangement of shifted spline knots for cubic spline interpolation.
    The proposed scheme leads to an approximately 3.4 times increasing
    in the accuracy of the interpolation compared to the de Boor's
    not-a-knot end condition. Furthermore, we also present the optimal
    end conditions of cubic spline interpolation to approximate the
    first and the second derivatives of interpolated functions. The
    representative examples show the effectiveness and the superiority
    of the proposed method.
  author:
  - literal: Sun, M., Lan, L., Zhu C. G., & Lei, F.
  container-title: Journal of Computational and Applied Mathematics
  doi: 10.1016/j.cam.2022.115039
  id: SUN2023115039
  issn: 0377-0427
  issued: 2023
  keyword: Cubic spline interpolation, End conditions, Not-a-knot end
    condition, Interpolation error estimation
  page: 115039
  title: Cubic spline interpolation with optimal end conditions
  type: article-journal
  url: "https://www.sciencedirect.com/science/article/pii/S0377042722006379"
  volume: 425
- abstract: Resampling of digitized electroencephalographic data allows
    changing the sampling rate with minimal distortion of the signal.
    Useful applications of the procedure include compatibility among
    diverse hardware and software and the customization of data
    analysis. The natural cubic spline interpolation procedure is
    introduced in a discursive fashion. A formal presentation is
    provided in the appendix.
  author:
  - literal: Congedo, M., Özen, C., & Sherlin, L.
  container-title: Journal of Neurotherapy
  doi: 10.1300/J184v06n04_08
  id: Congedo01092002
  issue: 4
  issued: 2002
  page: 73-80
  publisher: Routledge
  title: Notes on EEG resampling by natural cubic spline interpolation
  type: article-journal
  volume: 6
- abstract: Electroencephalogram (EEG) signal is usually suffered from
    motion artifacts, generated randomly during signal acquisition
    timings. These artifacts sturdily affect the investigation and
    therefore, diagnosis of neural diseases from EEG signal. The
    artifact removal may cause loss of important information from the
    signal. Therefore, it is required to remove the motion artifacts and
    simultaneously preserve the desired information, which makes EEG
    artifact removal a vital task. Enhanced Empirical Mode Decomposition
    (EEMD) is the most widespread method used for artifact removal, as
    it is a data-driven based feature extraction method. In this
    research work the efficiency of various EEMD with different
    interpolation based artifact removal method have been compared. The
    EEMD is used to convert input single channel EEG signal to a
    multichannel signal, and in order to remove the randomness of motion
    artifact, CCA and DWT filtering were used successively. The
    performance of different interpolation based artifact removal
    methods have evaluated and results indicate that the proposed
    algorithm is suitable for use as a supplement to algorithms
    currently in use as it offers improvements in DSNR and various other
    performance parameters.
  author:
  - literal: Roy, V., & Shukla, S.
  container-title: Wireless Personal Communications
  doi: 10.1007/s11277-017-4846-3
  id: roy2017
  issue: 4
  issued: 2017
  page: 6441-6451
  title: Effective EEG motion artifacts elimination based on comparative
    interpolation analysis
  type: article-journal
  volume: 97
- abstract: In this paper we derive necessary optimality conditions for
    an interpolating spline function which minimizes the Holladay
    approximation of the energy functional and which stays monotone if
    the given interpolation data are monotone. To this end optimal
    control theory for state-restricted optimal control problems is
    applied. The necessary conditions yield a complete characterization
    of the optimal spline. In the case of two or three interpolation
    knots, which we call thelocalcase, the optimality conditions are
    treated analytically. They reduce to polynomial equations which can
    very easily be solved numerically. These results are used for the
    construction of a numerical algorithm for the optimal monotone
    spline in the general (global) case via Newton's method. Here, the
    local optimal spline serves as a favourable initial estimation for
    the additional grid points of the optimal spline. Some numerical
    examples are presented which are constructed by FORTRAN and MATLAB
    programs.
  author:
  - literal: Fredenhagen, S., Oberle, H. J., & Opfer, G.
  container-title: Journal of Approximation Theory
  doi: 10.1006/jath.1998.3247
  id: FREDENHAGEN1999182
  issn: 0021-9045
  issue: 2
  issued: 1999
  page: 182-201
  title: On the construction of optimal monotone cubic spline
    interpolations
  type: article-journal
  url: "https://www.sciencedirect.com/science/article/pii/S0021904598932476"
  volume: 96
- abstract: Interpolation is the art of reading between the lines of a
    mathematical table. It can be used to express nonelementary
    functions approximately in terms of the four basic arithmetic
    operations, thus making them accessible to computer evaluation.
  author:
  - literal: Rutishauser, H.
  container-title: Lectures on numerical mathematics
  doi: 10.1007/978-1-4612-3468-5_6
  editor:
  - literal: Gutknecht, M.
  id: Rutishauser1990
  isbn: 978-1-4612-3468-5
  issued: 1990
  page: 128-174
  publisher: Birkhäuser Boston
  publisher-place: Boston, MA
  title: Interpolation
  type: chapter
  url: "https://doi.org/10.1007/978-1-4612-3468-5_6"
- abstract: Experiments usually produce a discrete set of data points.
    If additional data points are needed, for instance, to draw a
    continuous curve or to change the sampling frequency of audio or
    video signals, interpolation methods are necessary. But
    interpolation is also helpful to develop more sophisticated
    numerical methods for the calculation of numerical derivatives or
    integrals. Polynomial interpolation is discussed in large detail
    together with its drawbacks. The methods by Lagrange and Newton are
    discussed, as well as the Neville method, which allow efficient
    determination and evaluation of the interpolating polynomial. For
    interpolation over a larger range, larger number of data spline
    interpolation is very useful which does not show the oscillatory
    behavior characteristic of polynomial interpolation. In a computer
    experiment both these approaches are compared. Multivariate
    interpolation is a necessary tool to process multidimensional data
    sets, for instance, for image processing. A computer experiment
    compares bilinear interpolation and bicubic spline interpolation.
  author:
  - literal: Scherer, P. O.J.
  container-title: "Computational physics: Simulation of classical and
    quantum systems"
  doi: 10.1007/978-3-642-13990-1_2
  id: Scherer2010
  isbn: 978-3-642-13990-1
  issued: 2010
  page: 15-27
  publisher: Springer
  publisher-place: Berlin, Heidelberg
  title: Interpolation
  type: chapter
  url: "https://doi.org/10.1007/978-3-642-13990-1_2"
- abstract: Newton's interpolation is a classical polynomial
    interpolation approach and plays a significant role in numerical
    analysis and image processing. The interpolation function of most
    classical approaches is unique to the given data. In this paper,
    univariate and bivariate parameterized Newton-type polynomial
    interpolation methods are introduced. In order to express the
    divided differences tables neatly, the multiplicity of the points
    can be adjusted by introducing new parameters. Our new polynomial
    interpolation can be constructed only based on divided differences
    with one or multiple parameters which satisfy the interpolation
    conditions. We discuss the interpolation algorithm, theorem, dual
    interpolation, and information matrix algorithm. Since the proposed
    novel interpolation functions are parametric, they are not unique to
    the interpolation data. Therefore, its value in the interpolant
    region can be adjusted under unaltered interpolant data through the
    parameter values. Our parameterized Newton-type polynomial
    interpolating functions have a simple and explicit mathematical
    representation, and the proposed algorithms are simple and easy to
    calculate. Various numerical examples are given to demonstrate the
    efficiency of our method.
  author:
  - literal: Zou, L., Song, L., Wang, X., Weise, T., Chen, Y., & Zhang,
      C.
  container-title: Mathematical Problems in Engineering
  doi: 10.1155/2020/9020541
  id: "https://doi.org/10.1155/2020/9020541"
  issue: 1
  issued: 2020
  page: 9020541
  title: A new approach to newton-type polynomial interpolation with
    parameters
  type: article-journal
  url: "https://onlinelibrary.wiley.com/doi/abs/10.1155/2020/9020541"
  volume: 2020
- abstract: Summary This chapter presents the information of
    interpolation and approximation for solving problems of mathematical
    analysis. It contains exercises and solutions that present an
    introduction to key concepts, a calculus review, and an updated
    primer on Lagrange interpolation, Newton interpolation and divided
    differences, interpolation error, Muller's method and inverse
    quadratic interpolation, Hermite interpolation, piecewise polynomial
    interpolation, Splines, tension Splines, and least squares concepts
    in approximation. The chapter features new and updated material
    reflecting new trends and applications in numerical methods and
    analysis. It is the perfect for upper-level undergraduate students
    in mathematics, science, and engineering courses, as well as for
    courses in the social sciences, medicine, and business with
    numerical methods and analysis components.
  author:
  - literal: Epperson, J. F.
  chapter-number: 4
  container-title: An introduction to numerical methods and analysis
  doi: 10.1002/9781119604570.ch4
  id: "doi:10.1002/9781119604570.ch4"
  isbn: 9781119604570
  issued: 2021
  keyword: divided differences, Hermite interpolation, interpolation
    error, inverse quadratic interpolation, Lagrange interpolation,
    Muller's method, Newton interpolation, piecewise polynomial
    interpolation, tension Splines
  page: 101-148
  publisher: John Wiley & Sons, Ltd
  title: Interpolation and approximation
  type: chapter
  url: "https://onlinelibrary.wiley.com/doi/abs/10.1002/9781119604570.ch4"
- abstract: The Newton interpolation approach is developed for
    approximation of linear functionals. It is shown that in numerical
    interpolation and numerical differentiation, the Newton
    interpolation approach is more efficient than solving the
    Vandermonde systems.
  author:
  - literal: Tsao, N.-K.
  container-title: Numerische Mathematik
  doi: 10.1007/BF01389317
  id: tsao1977
  issue: 1
  issued: 1977
  title: Newton interpolation is efficient for approximation of linear
    functionals
  type: article-journal
  volume: 29
- author:
  - literal: Saff, E. B., & Snider, A. D.
  doi: 10.1007/978-3-031-97222-5
  edition: 2
  id: saff2025
  issued: 2025
  publisher: Springer
  publisher-place: Cham
  title: "Matrix fundamentals: From equation solving to signal
    processing"
  title-short: Matrix fundamentals
  type: book
- author:
  - literal: Gentle, J. E.
  collection-title: Springer texts in statistics
  doi: 10.1007/978-3-031-42144-0
  edition: 3
  id: gentle2024
  issued: 2024
  publisher: Springer
  publisher-place: Cham
  title: "Matrix algebra: Theory, computations and applications in
    statistics"
  title-short: Matrix algebra
  type: book
- abstract: In Chapter 1 we used matrices and vectors as simple storage
    devices. In this chapter matrices and vectors take on a life of
    their own. We develop the arithmetic of matrices and vectors. Much
    of what we do is motivated by a desire to extend the ideas of
    ordinary arithmetic to matrices.
  author:
  - literal: Shores, T. S.
  container-title: Applied linear algebra and matrix analysis
  doi: 10.1007/978-3-319-74748-4_2
  id: Shores2018
  isbn: 978-3-319-74748-4
  issued: 2018
  page: 65-180
  publisher: Springer International Publishing
  publisher-place: Cham
  title: MATRIX ALGEBRA
  type: chapter
  url: "https://doi.org/10.1007/978-3-319-74748-4_2"
- abstract: "Wir betrachten das Problem, zu einer invertierbaren Matrix
    \\$\\$A \\\\in \\\\mathbb {R}\\^{n\\\\times
    n}\\$\\$A∈Rn`\\texttimes`{=latex}nund einem Vektor \\$\\$b \\\\in \\\\mathbb
    {R}\\^n\\$\\$b∈Rneinen Vektor \\$\\$x \\\\in \\\\mathbb {R}\\^n\\$\\$x∈Rnmit
    \\$\\$A \\\\, x = b\\$\\$Ax=bzu bestimmen; kurz: Wir lösen das lineare
    Gleichungssystem \\$\\$A x = b\\$\\$Ax=b. Formal erhält man die Lösung
    durch \\$\\$x = A\\^{-1} b\\$\\$x=A-1b. Aber die Berechnung von
    \\$\\$A\\^{-1}\\$\\$A-1ist bei einer großen Matrix A aufwendig. Die
    Cramer'sche Regel (siehe Rezept in Abschn. 12.3) ist aus numerischer
    Sicht zur Berechnung der Lösung x ungeeignet. Tatsächlich liefert
    das Gauß'sche Eliminationsverfahren, das wir auch in Kap. 9 zur
    händischen Lösung eines LGS empfohlen haben, eine Zerlegung der
    Koeffizientenmatrix A, mit deren Hilfe es möglich ist, ein
    Gleichungssystem der Form \\$\\$A \\\\, x = b\\$\\$Ax=bmit invertierbarem
    A zu lösen. Diese sogenannte \\$\\$L\\\\, R\\$\\$LR-Zerlegung ist zudem
    numerisch gutartig. Gleichungssysteme mit bis zu etwa 10000 Zeilen
    und Unbekannten lassen sich auf diese Weise vorteilhaft lösen. Für
    größere Gleichungssysteme sind iterative Lösungsverfahren zu
    bevorzugen (siehe Kap. 71)."
  author:
  - literal: Karpfinger, C.
  container-title: "Höhere mathematik in rezepten: Begriffe, sätze und
    zahlreiche beispiele in kurzen lerneinheiten"
  doi: 10.1007/978-3-662-63305-2_11
  id: Karpfinger2022a
  isbn: 978-3-662-63305-2
  issued: 2022
  page: 107-117
  publisher: Springer
  publisher-place: Berlin, Heidelberg
  title: L r-zerlegung einer matrix
  type: chapter
  url: "https://doi.org/10.1007/978-3-662-63305-2_11"
- abstract: "We have already used matrices to solve systems of linear
    equations: Matrices have been a helpful tool here to represent
    linear systems of equations economically and clearly. Matrices also
    serve as a tool in other, manifold ways. This is one reason to
    consider matrices in their own right, and to clearly illustrate and
    practice all kinds of manipulations that are possible with them: We
    will add, multiply, multiply, exponentiate, transpose, and invert
    matrices. But everything in order."
  author:
  - literal: Karpfinger, C.
  container-title: "Calculus and linear algebra in recipes: Terms,
    phrases and numerous examples in short learning units"
  doi: 10.1007/978-3-662-65458-3_10
  id: Karpfinger2022b
  isbn: 978-3-662-65458-3
  issued: 2022
  page: 87-100
  publisher: Springer
  publisher-place: Berlin, Heidelberg
  title: Calculating with matrices
  type: chapter
  url: "https://doi.org/10.1007/978-3-662-65458-3_10"
- abstract: "Newton, in notes that he would rather not have seen
    published, described a process for solving simultaneous equations
    that later authors applied specifically to linear equations. This
    method --- which Euler did not recommend, which Legendre called
    \"ordinary,\" and which Gauss called \"common\" --- is now named after
    Gauss: \"Gaussian\" elimination. Gauss's name became associated with
    elimination through the adoption, by professional computers, of a
    specialized notation that Gauss devised for his own least-squares
    calculations. The notation allowed elimination to be viewed as a
    sequence of arithmetic operations that were repeatedly optimized for
    hand computing and eventually were described by matrices.
    Zusammenfassung In Aufzeichnungen, die Newton lieber nicht der
    Veröffentlichung preisgegeben hätte, beschreibt er den Prozess für
    die Lösung von simultanen Gleichungen, den spätere Autoren speziell
    für lineare Gleichungen anwandten. Diese Methode --- welche Euler
    nicht empfahl, welche Legendre \"ordinaire\" nannte, und welche Gauß
    \"gewöhnlich\" nannte --- wird nun nach Gauß benannt: Gaußsches
    Eliminationsverfahren. Die Verbindung des Gaußschen Namens mit
    Elimination wurde dadurch hervorgebracht, dass professionelle
    Rechner eine Notation übernahmen, die Gauß speziell für seine
    eigenen Berechnungen der kleinsten Quadrate ersonnen hatte, welche
    zuließ, das Elimination als eine Sequenz von arithmetischen
    Rechenoperationen betrachtet wurde, die wiederholt für
    Handrechnungen optimisiert wurden und schließlich durch Matrizen
    beschrieben wurden."
  author:
  - literal: Grcar, J. F.
  container-title: Historia Mathematica
  doi: 10.1016/j.hm.2010.06.003
  id: GRCAR2011163
  issn: 0315-0860
  issue: 2
  issued: 2011
  keyword: Algebra before 1800, Gaussian elimination, Human computers,
    Least squares method, Mathematics education
  page: 163-218
  title: How ordinary elimination became gaussian elimination
  type: article-journal
  url: "https://www.sciencedirect.com/science/article/pii/S0315086010000376"
  volume: 38
---

