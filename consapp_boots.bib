@article{Efron1979,
    author = {{Efron, B.}},
    title = {{Bootstrap Methods: Another Look at the Jackknife}},
    volume = {7},
    journal = {The Annals of Statistics},
    number = {1},
    publisher = {Institute of Mathematical Statistics},
    pages = {1--26},
    year = {1979},
    doi = {10.1214/aos/1176344552},
    URL = {https://doi.org/10.1214/aos/117634455}
}
@article{Efron1981,
    author = {{Efron, B.}},
    title = {Nonparametric estimates of standard error: The jackknife, the bootstrap and other methods},
    journal = {Biometrika},
    volume = {68},
    number = {3},
    pages = {589--599},
    year = {1981},
    month = {12},
    abstract = {We discuss several nonparametric methods for attaching a standard error to a point estimate: the jackknife, the bootstrap, half-sampling, subsampling, balanced repeated replications, the infinitesimal jackknife, influence function techniques and the delta method. The last three methods are shown to be identical. All the methods derive from the same basic idea, which is also the idea underlying the common parametric methods. Extended numerical comparisons are made for the special case of the correlation coefficient.},
    issn = {0006-3444},
    doi = {10.1093/biomet/68.3.589},
    url = {https://doi.org/10.1093/biomet/68.3.589}
}
@book{Efron1982,
    author = {{Efron, B.}},
    title = {The Jackknife, the Bootstrap and Other Resampling Plans},
    publisher = {{SIAM, Society for Industrial and Applied Mathematics}},
    year = {1982},
    doi = {10.1137/1.9781611970319},
    address = {Philadelphia},
    series   = {CBMS-NSF Regional Conference Series in Applied Mathematics, Monograph 38},
    URL = {https://epubs.siam.org/doi/abs/10.1137/1.9781611970319}
}
@Inbook{Wilcox2001,
author={{Wilcox, R. R.}},
title="The Bootstrap",
bookTitle="Fundamentals of Modern Statistical Methods: Substantially Improving Power and Accuracy",
year="2001",
publisher="Springer",
address="New York, NY",
pages="93--115",
abstract="When testing hypotheses (or computing confidence intervals) with the one-sample Student's T method described in Chapter 5, the central limit theorem tells us that Student's T performs better as the sample size increases. That is, under random sampling the discrepancy between the nominal and actual Type I error probability will go to zero as the sample size goes to infinity. But unfortunately, for reasons outlined in Section 5.3 of Chapter 5, there are realistic situations where about two hundred observations are needed to get satisfactory control over the probability of a Type I error or accurate probability coverage when computing confidence intervals. When comparing the population means of two groups of individuals, using Student's T is known to be unsatisfactory when sample sizes are small or even moderately large. In fact, it might be unsatisfactory no matter how large the sample sizes are because under general conditions it does not converge to the correct answer (Cressie and Whitford, 1986). Switching to the test statistic W given by Equation 5.3, the central limit theorem now applies under general conditions, so using W means we will converge to the correct answer as the sample sizes increase, but in some cases we again need very large sample sizes to get accurate results. (There are simple methods for improving the performance of W using what are called estimated degrees of freedom, but the improvement remains highly unsatisfactory for a wide range of situations.) Consequently, there is interest in finding methods that beat our reliance on the central limit theorem as it applies to these techniques. That is, we would like to find a method that converges to the correct answer more quickly as the sample sizes get large, and such a method is described here.",
isbn="978-1-4757-3522-2",
doi="10.1007/978-1-4757-3522-2_6",
url="https://doi.org/10.1007/978-1-4757-3522-2_6"
}
@article{politis2003,
author={{Politis, D. N.}}, 
title ={The Impact of Bootstrap Methods on Time Series Analysis},
journal={Statistical Science},
volume={18},
number ={2},
pages ={219--230},
year ={2003},
doi={10.1214/ss/1063994977}
}
@Inbook{Kenett2022,
author={{Kenett, R., Zacks, S., & Gedeck, P.}},
title="Statistical Inference and Bootstrapping",
bookTitle="Modern Statistics: A Computer-Based Approach with Python",
year="2022",
publisher="Springer International Publishing",
address="Cham",
pages="139--223",
abstract="In this chapter we introduce basic concepts and methods of statistical inference. The focus is on estimating the parameters of statistical distributions and testing hypotheses about them. Problems of testing if certain distributions fit observed data are also considered.",
isbn="978-3-031-07566-7",
doi="10.1007/978-3-031-07566-7_3",
url="https://doi.org/10.1007/978-3-031-07566-7_3"
}
@Inbook{Zuev2026,
author={{Zuev, K. M.}},
title="The Bootstrap Method",
bookTitle="Fundamentals of Statistical Inference: Foundations of Data Analysis",
year="2026",
publisher="Springer Nature Switzerland",
address="Cham",
pages="115--129",
abstract="In this chapter, we will learn how to estimate the standard error of an estimate and how to construct confidence intervals for a parameter of interest. Both problems can be solved by the bootstrap method, which was inspired by the jackknife. The bootstrap, introduced in 1979 by Bradley Efron, is a general simulation-based method for measuring the uncertainty of estimates, in particular, for estimating their standard errors and constructing confidence intervals. Its beauty lies in its simplicity and universality: the bootstrap is fully automatic, requires no theoretical calculations, and is always available.",
isbn="978-3-032-03848-7",
doi="10.1007/978-3-032-03848-7_6",
url="https://doi.org/10.1007/978-3-032-03848-7_6"
}
@Article{math13182913,
AUTHOR = {{Zheng, Y., & Fan, H.}},
TITLE = {Fast Cluster Bootstrap Methods for Spatial Error Models},
JOURNAL = {Mathematics},
VOLUME = {13},
YEAR = {2025},
NUMBER = {18},
ARTICLE-NUMBER = {2913},
URL = {https://www.mdpi.com/2227-7390/13/18/2913},
ISSN = {2227-7390},
ABSTRACT = {Typically, the traditional bootstrap methods for parameter inference of spatial error models suffer from high computational costs, so this study proposes fast cluster bootstrap methods for spatial error models to deal with the dilemma. The key idea is to calculate the sufficient statistics for each cluster before performing the bootstrap loop of the spatial error model, and based on these sufficient statistics, all quantities needed for bootstrap inference can be computed. Furthermore, this study performed Monte Carlo simulations, and the result reveals that compared with traditional bootstrap methods, our proposed methods can reduce the computational cost substantially and improve the reliability for obtaining the bootstrap test statistics and confidence intervals of the parameters for spatial error models.},
DOI = {10.3390/math13182913}
}
@article{eidous2025,
author = {{Eidous, O.}},
year = {2025},
month = {09},
journal={{ResearchGate}},
pages = {},
title = {Does the Bootstrap Method Effectively Evaluate Estimators?},
doi = {10.13140/RG.2.2.12238.11846}
}
@ARTICLE{647042,
  author={{Politis, D. N.}},
  journal={IEEE Signal Processing Magazine}, 
  title={Computer-intensive methods in statistical analysis}, 
  year={1998},
  volume={15},
  number={1},
  pages={39--55},
  keywords={Statistical analysis;Sampling methods;Statistical distributions;Gaussian distribution;Shape;Density functional theory;Statistics},
  doi={10.1109/79.647042}
}
@article{KHOSRAVI2021100781,
title = {Application of bootstrap re-sampling method in statistical measurement of sustainability},
journal = {Socio-Economic Planning Sciences},
volume = {75},
pages = {100781},
year = {2021},
note = {Decision-Making for Environmental Sustainability},
issn = {0038-0121},
doi = {10.1016/j.seps.2020.100781},
url = {https://www.sciencedirect.com/science/article/pii/S0038012119303416},
author = {{Khosravi, F., Izbirak,  G., & Shavarani, S. M.}},
keywords = {Sustainability, Bootstrap Re-Sampling, Statistical performance measurement, Enablers, Barriers},
abstract = {Sustainability is of essential interest for many organizations and is defined as the ability to maintain existing resources at a certain rate or level when encountered with barriers. Factors affecting sustainability are categorized as enablers (capacities) and barriers (challenges) that have positive and negative effects on sustainability, respectively. To evaluate the status of sustainability, organizations need a measurement method to account for all the aspects of the sustainability classified into social, economic, and environmental tiers. Previously many researchers have provided indexes and measure specific to the studied field, which is not applicable to other areas. Furthermore, the proposed methods fail to cover all the aspects of sustainability. This study investigates a statistical method to measure the sustainability and the application of the bootstrap re-sampling method in order to overcome the problem with normality assumption when the sample size is not large enough and thus develop a more realistic stochastic model. The Bootstrap re-sampling method enables the unbiased estimation of population parameters such as mean and standard deviation. The proposed method is evaluated by comparing its results with those found in the literature.}
}
@incollection{HOROWITZ20013159,
title = {Chapter 52 - The Bootstrap},
editor = {{Heckman, J. J., & Leamer, E.}},
series = {Handbook of Econometrics},
publisher = {Elsevier},
volume = {5},
pages = {3159--3228},
year = {2001},
issn = {1573-4412},
doi = {10.1016/S1573-4412(01)05005-X},
url = {https://www.sciencedirect.com/science/article/pii/S157344120105005X},
author = {Joel L. Horowitz},
keywords = {JEL classification:, C12, C13, C15},
abstract = {The bootstrap is a method for estimating the distribution of an estimator or test statistic by resampling one’s data or a model estimated from the data. Under conditions that hold in a wide variety of econometric applications, the bootstrap provides approximations to distributions of statistics, coverage probabilities of confidence intervals, and rejection probabilities of hypothesis tests that are more accurate than the approximations of first-order asymptotic distribution theory. The reductions in the differences between true and nominal coverage or rejection probabilities can be very large. The bootstrap is a practical technique that is ready for use in applications. This chapter explains and illustrates the usefulness and limitations of the bootstrap in contexts of interest in econometrics. The chapter outlines the theory of the bootstrap, provides numerical illustrations of its performance, and gives simple instructions on how to implement the bootstrap in applications. The presentation is informal and expository. Its aim is to provide an intuitive understanding of how the bootstrap works and a feeling for its practical value in econometrics.}
}
@article{5d7fe90b-50e5-3e2c-9890-dc7b7f71d323,
 ISSN = {08834237},
 URL = {http://www.jstor.org/stable/3182845},
 abstract = {The contemporary development of bootstrap methods, from the time of Efron's early articles to the present day, is well documented and widely appreciated. Likewise, the relationship of bootstrap techniques to certain early work on permutation testing, the jackknife and cross-validation is well understood. Less known, however, are the connections of the bootstrap to research on survey sampling for spatial data in the first half of the last century or to work from the 1940s to the 1970s on subsampling and resampling. In a selective way, some of these early linkages will be explored, giving emphasis to developments with which the statistics community tends to be less familiar. Particular attention will be paid to the work of P. C. Mahalanobis, whose development in the 1930s and 1940s of moving-block sampling methods for spatial data has a range of interesting features, and to contributions of other scientists who, during the next 40 years, developed half-sampling, subsampling and resampling methods.},
 author = {{Hall, P.}},
 journal = {Statistical Science},
 number = {2},
 pages = {158--167},
 publisher = {Institute of Mathematical Statistics},
 title = {A Short Prehistory of the Bootstrap},
 urldate = {2026-01-14},
 volume = {18},
 year = {2003}
}
@article{71a9795f-441b-3377-aa30-ddc5824ffbf2,
 ISSN = {13697412, 14679868},
 URL = {http://www.jstor.org/stable/24774569},
 abstract = {The bootstrap provides a simple and powerful means of assessing the quality of estimators. However, in settings involving large data sets—which are increasingly prevalent—the calculation of bootstrap-based quantities can be prohibitively demanding computationally. Although variants such as subsampling and the m out of n bootstrap can be used in principle to reduce the cost of bootstrap computations, these methods are generally not robust to specification of tuning parameters (such as the number of subsampled data points), and they often require knowledge of the estimator's convergence rate, in contrast with the bootstrap. As an alternative, we introduce the 'bag of little bootstraps' (BLB), which is a new procedure which incorporates features of both the bootstrap and subsampling to yield a robust, computationally efficient means of assessing the quality of estimators. The BLB is well suited to modern parallel and distributed computing architectures and furthermore retains the generic applicability and statistical efficiency of the bootstrap. We demonstrate the BLB's favourable statistical performance via a theoretical analysis elucidating the procedure's properties, as well as a simulation study comparing the BLB with the bootstrap, the m out of n bootstrap and subsampling. In addition, we present results from a large-scale distributed implementation of the BLB demonstrating its computational superiority on massive data, a method for adaptively selecting the BLB's tuning parameters, an empirical study applying the BLB to several real data sets and an extension of the BLB to time series data.},
 author = {{Kleiner, A., Talwalkar, A., Sarkar, P., & Jordan, M. I.}},
 journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
 number = {4},
 pages = {795--816},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {A scalable bootstrap for massive data},
 urldate = {2026-01-14},
 volume = {76},
 year = {2014}
}
@article{10.2307/2348962,
    author = {{Pewsey, A.}},
    title = {Exploring the Limits of Bootstrap},
    journal = {Journal of the Royal Statistical Society Series D: The Statistician},
    volume = {43},
    number = {1},
    pages = {215--216},
    year = {2018},
    month = {12},
    issn = {2515-7884},
    doi = {10.2307/2348962},
    url = {https://doi.org/10.2307/2348962},
    eprint = {https://academic.oup.com/jrsssd/article-pdf/43/1/215/49929729/jrsssd_43_1_215a.pdf},
}
@article{e841cec6-d2b9-36dd-bee3-92abf3c9e224,
 ISSN = {13684221, 1368423X},
 URL = {http://www.jstor.org/stable/23114968},
 abstract = {Consistency of the bootstrap second moments does not usually follow from the proofs of consistency of the distribution of the bootstrap. Here it is shown that the convergence of the bootstrap distribution to a normal variate implicitly defines a consistent estimator for the asymptotic second moments. The estimator is based on the L-estimation of the scale parameter of arbitrary linear combinations of the bootstrap sequence and uses Classical Minimum Distance techniques to impose the positive semi-definiteness restrictions.},
 author = {{Machado, J. A. F., & Parente, P.}},
 journal = {The Econometrics Journal},
 number = {1},
 pages = {70--78},
 publisher = {[Royal Economic Society, Wiley]},
 title = {Bootstrap estimation of covariance matrices via the percentile method},
 urldate = {2026-01-14},
 volume = {8},
 year = {2005}
}
@article{ee45c30f-1813-36a2-b2a9-57ffa08fcc80,
 ISSN = {07492170},
 URL = {http://www.jstor.org/stable/4356107},
 abstract = {We propose a unifying principle which identifies a very broad class of hypotheses and statistics for which a suitable application of the n out of n bootstrap yields asymptotically correct critical values and power for contiguous alternatives. We also show that this attractive principle can fail in situations which the m out of n bootstrap can deal with (Bickel, Götze and van Zwet, 1997) (BGvZ). We formalize the m out of n bootstrap theory for testing and show that under mild conditions, it provides correct significance level, asymptotic power under contiguous alternatives, and consistency. We conclude with simulation results supporting the asymptotics.},
 author = {{Bickel, P. J., & Ren, J.-J.}},
 journal = {Lecture Notes-Monograph Series},
 pages = {91--112},
 publisher = {Institute of Mathematical Statistics},
 title = {The Bootstrap in Hypothesis Testing},
 urldate = {2026-01-14},
 volume = {36},
 year = {2001}
}
@article{Baíllo2025,
author={{Baíllo, A., & Cárcamo, J.}},
year = {2025},
title = {Bootstrap tests for almost goodness-of-fit},
journal= {Statistics and Computing},
pages = {10},
volume= {36},
number = {1},
abstract= {We introduce the almost goodness-of-fit test, a procedure to assess whether a (parametric) model provides a good representation of the probability distribution generating the observed sample. Specifically, given a distribution function F and a parametric family $$\mathcal {G}=\{ G(\varvec{\theta }): \varvec{\theta } \in \Theta \}$$, we consider the testing problem $$ H_0: \Vert F - G(\varvec{\theta }_F) \Vert _p \ge \epsilon \quad \text {vs} \quad H_1: \Vert F - G(\varvec{\theta }_F) \Vert _p < \epsilon , $$H0:‖F-G(θF)‖p≥ϵvsH1:‖F-G(θF)‖p<ϵ,where $$\epsilon >0$$is a margin of error and $$G(\varvec{\theta }_F)$$denotes a representative of F within the parametric class. The approximate model is determined via an M-estimator of the parameters. The methodology also quantifies the percentage improvement of the proposed model relative to a non-informative (constant) benchmark. The test statistic is the $$\textrm{L}^p$$-distance between the empirical distribution function and that of the estimated model. We present two consistent, easy-to-implement, and flexible bootstrap schemes to carry out the test. The performance of the proposal is illustrated through simulation studies and analysis and real-data applications.},
doi={10.1007/s11222-025-10762-z}
}
@article{Liu2025,
author={{Liu, X. S.}},
year = {2025},
title = {Bootstrap power calculation: a flexible alternative to conventional power analysis for prospective and replication studies},
journal= {Behaviormetrika},
abstract= {Bootstrapping offers a flexible approach to estimating statistical power, when planning a new study based on a previous one. In this article, we explore both parametric and non-parametric bootstrap power calculations and demonstrate how to incorporate uncertainty about effect size in bootstrap power analysis. We use real examples to illustrate bootstrap power calculations in independent t-test and ANCOVA. Finally, we discuss the broader implications of bootstrap power calculation for a variety of research designs.},
doi={10.1007/s41237-025-00283-4}
}






